[
  {
    "objectID": "cheatsheets.html",
    "href": "cheatsheets.html",
    "title": "Cheat Sheets",
    "section": "",
    "text": "Cheat sheets are your friends, use them at all times.\n\nrstudio-IDE-cheatsheet.pdf\nrmarkdown-cheatsheet.pdf\nbase-r-cheatsheet.pdf\ndplyr-cheatsheet.pdf\nggplot2-cheatsheet-2.1.pdf\ndata-import-cheatsheet.pdf\nlubridate-cheatsheet.pdf\nshiny-cheatsheet.pdf\ncommand-line-cheatsheet.pdf\nstringr-cheatsheet.pdf",
    "crumbs": [
      "Cheatsheets"
    ]
  },
  {
    "objectID": "contributions.html",
    "href": "contributions.html",
    "title": "Contributions",
    "section": "",
    "text": "Lecture notes taken, and kindly shared, by students:\n\nLec-2, Fri Aug-30, Vectors 1 (by Ajay Sharma).\nLec-3, Wed Sep-4, Vectors 2 (by Ajay Sharma).",
    "crumbs": [
      "Contributions"
    ]
  },
  {
    "objectID": "demos/demo-lec6-lists.html",
    "href": "demos/demo-lec6-lists.html",
    "title": "Lec-6: Lists",
    "section": "",
    "text": "Data set example used in past lectures:\n\n\n\nname\nheight (cm)\nforce\n\n\n\n\nLeia\n150\nTrue\n\n\nLuke\n175\nTrue\n\n\nHan\n185\nFalse\n\n\n\nReminder (from last lecture): creating a vector for every row will result in coercion.\n\n# coercion\nind1 = c(\"Leia\", 150, TRUE)\nind1\n\n[1] \"Leia\" \"150\"  \"TRUE\"\n\n\nWhat kind of object can we use to store the values without having coercion?"
  },
  {
    "objectID": "demos/demo-lec6-lists.html#examples-of-simple-lists",
    "href": "demos/demo-lec6-lists.html#examples-of-simple-lists",
    "title": "Lec-6: Lists",
    "section": "Examples of “simple” lists",
    "text": "Examples of “simple” lists\n\n# naming elements in a list\nlis3 = list('a' = \"Leia\", 'b' = 150, 'c' = TRUE)\nlis3\n\n$a\n[1] \"Leia\"\n\n$b\n[1] 150\n\n$c\n[1] TRUE\n\n\n\n# naming elements in a list\nlis4 = list(x = \"Leia\", y = 150, z = TRUE)\nlis4\n\n$x\n[1] \"Leia\"\n\n$y\n[1] 150\n\n$z\n[1] TRUE\n\n\n\n# naming elements in a list\nlis5 = list(\"Luke\", 175, TRUE)\n\nnames(lis5) = c('A', 'B', 'C')\nlis5\n\n$A\n[1] \"Luke\"\n\n$B\n[1] 175\n\n$C\n[1] TRUE"
  },
  {
    "objectID": "demos/demo-lec6-lists.html#no-vectorization-in-lists",
    "href": "demos/demo-lec6-lists.html#no-vectorization-in-lists",
    "title": "Lec-6: Lists",
    "section": "No vectorization in lists",
    "text": "No vectorization in lists\n\n# example of vectorization\nsqrt(c(2, 4, 6, 8))\n\n[1] 1.414214 2.000000 2.449490 2.828427\n\n\n\n# what about sqrt() applied to a list?\nsqrt(list(2, 4, 6, 8))\n\nError in sqrt(list(2, 4, 6, 8)): non-numeric argument to mathematical function"
  },
  {
    "objectID": "demos/demo-lec6-lists.html#lists-can-contain-any-type-of-objects",
    "href": "demos/demo-lec6-lists.html#lists-can-contain-any-type-of-objects",
    "title": "Lec-6: Lists",
    "section": "Lists can contain any type of object(s)",
    "text": "Lists can contain any type of object(s)\nLists as the most generic type of data object in R: they can contain any kind of object such as vectors, factors, matrices, arrays, and even other lists.\n\nlis6 = list(\n  c(2, 4, 6), # vector\n  matrix(9:1, nrow = 3, ncol = 3), # matrix\n  list(TRUE, FALSE) # list\n)\n\nlis6\n\n[[1]]\n[1] 2 4 6\n\n[[2]]\n     [,1] [,2] [,3]\n[1,]    9    6    3\n[2,]    8    5    2\n[3,]    7    4    1\n\n[[3]]\n[[3]][[1]]\n[1] TRUE\n\n[[3]][[2]]\n[1] FALSE\n\n\n\nlis7 = list(\n  'first' = c(2, 4, 6), # vector\n  'second' = matrix(9:1, nrow = 3, ncol = 3), # matrix\n  'third' = list('true' = TRUE, 'false' = FALSE) # list\n)\nlis7\n\n$first\n[1] 2 4 6\n\n$second\n     [,1] [,2] [,3]\n[1,]    9    6    3\n[2,]    8    5    2\n[3,]    7    4    1\n\n$third\n$third$true\n[1] TRUE\n\n$third$false\n[1] FALSE"
  },
  {
    "objectID": "demos/demo-lec6-lists.html#adding-removing-elements-from-a-list",
    "href": "demos/demo-lec6-lists.html#adding-removing-elements-from-a-list",
    "title": "Lec-6: Lists",
    "section": "Adding & Removing elements from a list",
    "text": "Adding & Removing elements from a list\n\n# adding an element\nlis3$d = \"new\"\nlis3\n\n$a\n[1] \"Leia\"\n\n$b\n[1] 150\n\n$c\n[1] TRUE\n\n$d\n[1] \"new\"\n\n# removing an element\nlis3$d = NULL\nlis3\n\n$a\n[1] \"Leia\"\n\n$b\n[1] 150\n\n$c\n[1] TRUE"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html",
    "href": "demos/demo-lec5-matrices.html",
    "title": "Lec-5: Matrices",
    "section": "",
    "text": "Data set example from a few lectures ago:\n\n\n\nname\nheight (cm)\nforce\n\n\n\n\nLeia\n150\nTrue\n\n\nLuke\n175\nTrue\n\n\nHan\n185\nFalse\n\n\n\nAs you know, we can store this data in R, using vectors, one vector per column:\n\n# character (string) vector\nname = c(\"Leia\", \"Luke\", \"Han\")\n\n# double or real (float)\nheight = c(150, 175, 185)\n\n# logical (boolean)\nforce = c(TRUE, TRUE, FALSE)\n\n\n\n\nind1 = c(\"Leia\", 150, TRUE)\nind2 = c(\"Luke\", 175, TRUE)\nind3 = c(\"Han\", 185, FALSE)\n\nind1\n\n[1] \"Leia\" \"150\"  \"TRUE\"\n\nind2\n\n[1] \"Luke\" \"175\"  \"TRUE\"\n\nind3\n\n[1] \"Han\"   \"185\"   \"FALSE\"\n\n\nThe issue in this case is that R applies its coercion rules, and we end up with three vectors that may not be the most adequate to work with."
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#idea-what-about-using-one-vector-per-row",
    "href": "demos/demo-lec5-matrices.html#idea-what-about-using-one-vector-per-row",
    "title": "Lec-5: Matrices",
    "section": "",
    "text": "ind1 = c(\"Leia\", 150, TRUE)\nind2 = c(\"Luke\", 175, TRUE)\nind3 = c(\"Han\", 185, FALSE)\n\nind1\n\n[1] \"Leia\" \"150\"  \"TRUE\"\n\nind2\n\n[1] \"Luke\" \"175\"  \"TRUE\"\n\nind3\n\n[1] \"Han\"   \"185\"   \"FALSE\"\n\n\nThe issue in this case is that R applies its coercion rules, and we end up with three vectors that may not be the most adequate to work with."
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#matrix-by-binding-rows",
    "href": "demos/demo-lec5-matrices.html#matrix-by-binding-rows",
    "title": "Lec-5: Matrices",
    "section": "Matrix by binding rows",
    "text": "Matrix by binding rows\n\n# let's store this data in a matrix\nleia = c(150, 55)\nluke = c(175, 77)\nhan = c(185, 82)\n\n# rbind(): row bind\nmat1 = rbind(leia, luke, han)\nclass(mat1)\n\n[1] \"matrix\" \"array\" \n\n# give names to columns\ncolnames(mat1) = c(\"height\", \"weight\")\nmat1\n\n     height weight\nleia    150     55\nluke    175     77\nhan     185     82"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#matrix-by-binding-columns",
    "href": "demos/demo-lec5-matrices.html#matrix-by-binding-columns",
    "title": "Lec-5: Matrices",
    "section": "Matrix by binding columns",
    "text": "Matrix by binding columns\n\n# columns perspective\nheight = c(150, 175, 185)\nweight = c(55, 77, 82)\n\n# cbind(): column bind\nmat2 = cbind(height, weight)\nclass(mat2)\n\n[1] \"matrix\" \"array\" \n\n# give names to rows\nrownames(mat2) = c(\"leia\", \"luke\", \"han\")\nmat2\n\n     height weight\nleia    150     55\nluke    175     77\nhan     185     82"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#matrix-from-scratch",
    "href": "demos/demo-lec5-matrices.html#matrix-from-scratch",
    "title": "Lec-5: Matrices",
    "section": "Matrix from scratch",
    "text": "Matrix from scratch\nLet’s bring back the 3x2 data table.\n\n\n\n\nHeight (cm)\nWeight (kg)\n\n\n\n\nLeia\n150\n55\n\n\nLuke\n175\n77\n\n\nHan\n185\n82\n\n\n\nWe can store this data in a matrix by utilizing the function matrix(). Here’s how to that:\n\n# an R matrix is stored column-major\nmat3 = matrix(\n  data = c(150, 175, 185, 55, 77, 82),\n  nrow = 3, \n  ncol = 2)\n\nmat3\n\n     [,1] [,2]\n[1,]  150   55\n[2,]  175   77\n[3,]  185   82\n\n\nHere’s another way to create the same matrix, but this time by passing the input vector (from the row’s perspective) and the argument byrow = TRUE\n\n# an R matrix is stored column-major\nmat4 = matrix(\n  data = c(150, 55, 175, 77, 185, 82),\n  nrow = 3, \n  ncol = 2,\n  byrow = TRUE)\n\nmat4\n\n     [,1] [,2]\n[1,]  150   55\n[2,]  175   77\n[3,]  185   82\n\n\nIs mat4 still stored in column-major format? Let’s ask R to temporarily reveal its structure:\n\n# reveal column major format\nas.vector(mat4)\n\n[1] 150 175 185  55  77  82"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#auxiliary-matrix-functions",
    "href": "demos/demo-lec5-matrices.html#auxiliary-matrix-functions",
    "title": "Lec-5: Matrices",
    "section": "Auxiliary Matrix Functions",
    "text": "Auxiliary Matrix Functions\n\n# total number of cells in matrix\nlength(mat4)\n\n[1] 6\n\n# number of rows and columns\ndim(mat4)\n\n[1] 3 2\n\n# number of rows\nnrow(mat4)\n\n[1] 3\n\n# number of columns\nncol(mat4)\n\n[1] 2"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#numeric-subsetting",
    "href": "demos/demo-lec5-matrices.html#numeric-subsetting",
    "title": "Lec-5: Matrices",
    "section": "Numeric Subsetting",
    "text": "Numeric Subsetting\n\n# 1st cell: row-1, col-1\nmat1[1,1]\n\n[1] 150\n\n# row-2, col-2\nmat1[2,2]\n\n[1] 77\n\n# reshufle\nmat1[3:1, 2:1]\n\n     weight height\nhan      82    185\nluke     77    175\nleia     55    150\n\n# row-1, exclude 2nd column\nmat1[1, -2]\n\n[1] 150\n\n# 1st column\nmat1[ ,1]\n\nleia luke  han \n 150  175  185 \n\n# 2nd column\nmat1[ ,2]\n\nleia luke  han \n  55   77   82 \n\n# 2nd row\nmat1[2, ]\n\nheight weight \n   175     77 \n\n# \nmat1[c(2, 3, 2, 3, 2, 3), ]\n\n     height weight\nluke    175     77\nhan     185     82\nluke    175     77\nhan     185     82\nluke    175     77\nhan     185     82"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#logical-subsetting",
    "href": "demos/demo-lec5-matrices.html#logical-subsetting",
    "title": "Lec-5: Matrices",
    "section": "Logical Subsetting",
    "text": "Logical Subsetting\n\n# subset individuals with height &gt; 170\nmat1[mat1[, 1] &gt; 170, ]\n\n     height weight\nluke    175     77\nhan     185     82\n\n# subsetting only the 2nd column (R returns a vector)\nmat1[ ,c(FALSE, TRUE), drop = FALSE]\n\n     weight\nleia     55\nluke     77\nhan      82\n\n# subsetting only the 2nd column (R returns a column)\n# (we tell R to NOT drop the 2nd dimension)\nmat1[ ,c(FALSE, TRUE), drop = FALSE]\n\n     weight\nleia     55\nluke     77\nhan      82"
  },
  {
    "objectID": "demos/demo-lec5-matrices.html#character-subsetting",
    "href": "demos/demo-lec5-matrices.html#character-subsetting",
    "title": "Lec-5: Matrices",
    "section": "Character* Subsetting",
    "text": "Character* Subsetting\nIf the rows and/or columns of a matrix have names, then we can use them for subsetting purposes:\n\nmat1\n\n     height weight\nleia    150     55\nluke    175     77\nhan     185     82\n\n\n\nmat1[c(\"luke\", \"leia\"), ]\n\n     height weight\nluke    175     77\nleia    150     55\n\n\n\nmat1[ ,c(\"height\", \"height\", \"height\")]\n\n     height height height\nleia    150    150    150\nluke    175    175    175\nhan     185    185    185\n\n\n\nmat1[c(\"luke\", \"leia\"), c(\"height\", \"height\", \"weight\")]\n\n     height height weight\nluke    175    175     77\nleia    150    150     55"
  },
  {
    "objectID": "practice/practice-objs2-vector-subsetting.html",
    "href": "practice/practice-objs2-vector-subsetting.html",
    "title": "Practice: Vectors (part 2)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nWork with vectors of different data types\nCreate vectors of numeric sequences\nUnderstand the concept of atomic vectors\nLearn how to subset and slice R vectors"
  },
  {
    "objectID": "practice/practice-objs2-vector-subsetting.html#columns-into-vectors",
    "href": "practice/practice-objs2-vector-subsetting.html#columns-into-vectors",
    "title": "Practice: Vectors (part 2)",
    "section": "1.1 Columns into vectors",
    "text": "1.1 Columns into vectors\nBecause we are interested in working with the above five columns from a vectors perspective, we need to “break apart” the table dat into five vectors:\n\n# creating 5 vectors (from columns in dat)\nname = dat$name\n\nheight = dat$height\n\nmass = dat$mass\n\nsex = dat$sex\n\nhomeworld = dat$homeworld\n\nUse the function typeof() to see the data type of each of the above vectors.\n\n\nShow answer\ntypeof(name)\ntypeof(height)\ntypeof(mass)\ntypeof(sex)\ntypeof(homeworld)"
  },
  {
    "objectID": "practice/practice-objs2-vector-subsetting.html#your-turn-subsetting-vectors",
    "href": "practice/practice-objs2-vector-subsetting.html#your-turn-subsetting-vectors",
    "title": "Practice: Vectors (part 2)",
    "section": "1.2 Your turn: subsetting vectors",
    "text": "1.2 Your turn: subsetting vectors\nThe code below is one way to create a vector four by selecting the first four elements in name:\n\nfour = head(name, n = 4)\n\nSingle brackets [ ] are used to subset (i.e. subscript, split, slice) vectors. Without running the code, try to guess the output of the following commands, and then run them to check your guess:\n\nnumber one: four[1]\nan index of zero: four[0]?\na negative index: four[-1]?\nvarious negative indices: four[-c(1,2,3)]?\nan index greater than the length of the vector: four[5]?\nrepeated indices: four[c(1,2,2,3,3,3)]?\n\nOften, you will need to generate vectors of numeric sequences, like the first five elements 1:5, or from the first till the last element 1:length(name). R provides the colon operator :, and the functions seq(), and rep() to create various types of sequences."
  },
  {
    "objectID": "practice/practice-objs2-vector-subsetting.html#your-turn-sequences-and-repetitions",
    "href": "practice/practice-objs2-vector-subsetting.html#your-turn-sequences-and-repetitions",
    "title": "Practice: Vectors (part 2)",
    "section": "1.3 Your turn: sequences and repetitions",
    "text": "1.3 Your turn: sequences and repetitions\nFigure out how to use seq(), rep(), rev(), and bracket notation, to extract:\n\nall the even elements in name (i.e. extract positions 2, 4, 6, etc)\n\n\n\nShow answer\n# all the even elements in name\nname[seq(from = 2, to = length(name), by = 2)]\n\n\n\nall the odd elements in height (i.e. extract positions 1, 3, 5, etc)\n\n\n\nShow answer\n# all the odd elements in height\nheight[seq(from = 1, to = length(height), by = 2)]\n\n\n\nall multiples of 5 (e.g. 5, 10, 15, etc) of sex\n\n\n\nShow answer\n# all multiples of 5 (e.g. 5, 10, 15, etc) of sex\nsex[seq(from = 5, to = length(sex), by = 5)]\n\n\n\nelements in positions 10, 20, 30, 40, etc of mass\n\n\n\nShow answer\n# elements in positions 10, 20, 30, 40, etc of mass\nmass[seq(from = 10, to = length(mass), by = 10)]\n\n\n\nall the even elements in name but this time in reverse order\n\n\n\nShow answer\n# all the even elements in name but this time in reverse order\nrev(name[seq(from = 2, to = length(name), by = 2)])"
  },
  {
    "objectID": "practice/practice-objs2-vector-subsetting.html#your-turn-logical-subsetting",
    "href": "practice/practice-objs2-vector-subsetting.html#your-turn-logical-subsetting",
    "title": "Practice: Vectors (part 2)",
    "section": "2.1 Your turn: logical subsetting",
    "text": "2.1 Your turn: logical subsetting\nWrite commands, using bracket notation, to answer the following questions (you may need to use is.na(), min(), max(), which(), which.min(), which.max()):\n\nname of individuals from homeworld Naboo\n\n\n\nShow answer\n# name of individuals from homeworld Naboo\nname[homeworld == \"Naboo\"]\n\n\n\nname of individuals from homeworlds Naboo or Corellia; hint: the OR operator | is your friend.\n\n\n\nShow answer\n# name of individuals from Naboo or Corellia\nname[homeworld == \"Naboo\" | homeworld == \"Corellia\"]\n\n\n\nname of female individuals\n\n\n\nShow answer\n# name of female individuals\nname[sex == \"female\"]\n\n\n\nnumber (i.e. count) of male individuals; hint: the sum() function is your friend.\n\n\n\nShow answer\n# number of male individuals\nsum(sex == \"male\")\n\n\n\nname of individuals with largest mass; hint: the which.max() function is your friend.\n\n\n\nShow answer\n# name of individuals with largest mass\nname[which.max(mass)]\n\n\n\nlargest height of all females; hint: the max() function is your friend.\n\n\n\nShow answer\n# largest height of all females\nmax(height[sex == \"female\"])\n\n\n\nname of individual(s) with height equal to the median height; hint: the median() function is your friend.\n\n\n\nShow answer\n# name of individual(s) with height equal to the median height\nname[height == median(height)]\n\n\n\nname of individual(s) with height of at most 180, AND mass of at least 120; hint: the logical AND operator & is your friend.\n\n\n\nShow answer\n# name of individual(s) with height of at most 180, and mass of at least 120 \nname[height &lt;= 180 & mass &gt;= 120]"
  },
  {
    "objectID": "practice/practice-tidy4-readr-intro.html",
    "href": "practice/practice-tidy4-readr-intro.html",
    "title": "Practice: Importing tables with readr",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nGet to know various options to import data tables in R\nPractice using reading tables functions from package \"utils\"\nPractice using reading tables functions from package \"readr\""
  },
  {
    "objectID": "practice/practice-tidy4-readr-intro.html#data-files",
    "href": "practice/practice-tidy4-readr-intro.html#data-files",
    "title": "Practice: Importing tables with readr",
    "section": "1.1 Data Files",
    "text": "1.1 Data Files\nThis module has a companion folder that contains the text files listed below (see bCourses, Files/ tab, folder data/, subfolder importing-tables/):\n\nstarwarstoy.csv: this is a typical CSV file\nstarwarstoy2.csv: this is a typical CSV file\nstarwarsfwf.txt: this is a fixed width format (fwf) file\nstarwarstoy2.txt: this is a text file with both metadata and data\n\nThe following exercises will allow you to practice importing data into a tabular object (e.g. data.frame, tibble) using base \"utils\" functions read.table() and friends, as well as functions from package \"readr\"."
  },
  {
    "objectID": "practice/practice-tidy4-readr-intro.html#how-do-you-import-this-data-in-r",
    "href": "practice/practice-tidy4-readr-intro.html#how-do-you-import-this-data-in-r",
    "title": "Practice: Importing tables with readr",
    "section": "2.1 How do you import this data in R?",
    "text": "2.1 How do you import this data in R?\nR has a set of built-in functions for importing a great variety of data files. For sake of convenience, we are going to describe importing tools from the \"tidyverse\" package \"readr\".\n\n2.1.1 Quick & Dirty Import\nAssuming the file starwarstoy.csv is in your working directory, one quick-and-dirty way to import it in R is with the function read_csv(), as shown below:\n\n# quick-and-dirty import\ndat = read_csv(file = \"starwarstoy.csv\")\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): name, gender\ndbl (2): height, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nNotice the message provided by read_csv(). It detected that the input file uses \",\" as the field delimiter. Likewise, it has made an educated guess for the data-types of the columns: name and gender have been encoded as character, whereas height and weight have been encoded as double.\nOnce the data has been imported, you can use dat like any other object. It is important to notice that the output of \"readr\" functions is a tibble\n\ndat\n\n# A tibble: 4 × 4\n  name           gender height weight\n  &lt;chr&gt;          &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Luke Skywalker male     1.72     77\n2 Leia Skywalker female   1.5      49\n3 Han Solo       male     1.8      80\n4 Obi-Wan Kenobi male     1.82     77\n\n\n\n\n2.1.2 A More Formal Import\nA more formal way to import the file with read_csv() is to specify not just the name of the input file, but also the data-type of each column. The latter specification can be given with the argument col_types and the auxiliary function cols().\nThe arguments passed to cols() involve pairs of column names and their types. In turn, data types are specified with parsing functions such as col_logical(), col_character(), col_integer(), col_double(), etc.\n\n# more formal import\ndat = read_csv(\n  file = \"starwarstoy.csv\", \n  col_types = cols(\n    name = col_character(),\n    gender = col_character(),\n    height = col_double(),\n    weight = col_double()\n  ))\n\n\n\n2.1.3 Yet Another Import\nAn alternative way to specify the data-types of the columns is to use one-letter abbreviations instead of the parsing functions, for example (but not limited to):\n\n\"l\": logical\n\"i\": integer\n\"d\": double\n\"c\": character\n\nHere’s how to use abbreviations for the data-types:\n\n# abbreviations for column data-types\ndat = read_csv(\n  file = \"starwarstoy.csv\", \n  col_types = cols(\n    name = \"c\",\n    gender = \"c\",\n    height = \"d\",\n    weight = \"d\"\n  ))\n\nBut wait, there’s more! You can write a more compact command without the use of the auxiliary cols() function. All you have to do is pass a string with the abbreviations to the argument col_types. For example, the command below passes the string \"ccdd\" to col_types:\n\n# more compact command\ndat = read_csv(\n  file = \"starwarstoy.csv\", \n  col_types = \"ccdd\")\n\nThe way the string \"ccdd\" works is fairly simple: the first c is for the first column, the next c is for the second column, and so on and so forth."
  },
  {
    "objectID": "practice/practice-tidy4-readr-intro.html#your-turn-importing-starwarstoy2.csv",
    "href": "practice/practice-tidy4-readr-intro.html#your-turn-importing-starwarstoy2.csv",
    "title": "Practice: Importing tables with readr",
    "section": "2.2 Your Turn: importing starwarstoy2.csv",
    "text": "2.2 Your Turn: importing starwarstoy2.csv\nThe file starwarstoy2.csv has the following content:\nname,gender,height,weight,jedi,species,weapon\n\"Luke Skywalker\",male,1.72,77,jedi,human,lightsaber\n\"Leia Skywalker\",female,1.5,49,no_jedi,human,blaster\n\"Obi-Wan Kenobi\",male,1.82,77,jedi,human,lightsaber\n\"Han Solo\",male,1.8,80,no_jedi,human,blaster\n\"R2-D2\",male,0.96,32,no_jedi,droid,unarmed\n\"C-3PO\",male,1.67,75,no_jedi,droid,unarmed\n\"Yoda\",male,0.66,17,jedi,yoda,lightsaber\n\"Chewbacca\",male,2.28,112,no_jedi,wookiee,bowcaster\nUse read_csv() to import this CSV file. Make sure to specify reasonable data types for each of the columns. Try to do this using at least 2 different options for the col_types argument.\n\n\nShow answer\n# somewhat abbreviated\ndat2 = read_csv(\n  file = \"starwarstoy.csv\", \n  col_types = cols(\n    name = \"c\",\n    gender = \"c\",\n    height = \"d\",\n    weight = \"i\",\n    jedi = \"c\",\n    species = \"c\",\n    weapon = \"c\"\n  ))\n\n\n# super abbreviated\ndat2 = read_csv(\n  file = \"starwarstoy.csv\", \n  col_types = \"ccdiccc\")"
  },
  {
    "objectID": "practice/practice-tidy4-readr-intro.html#your-turn-fixed-width-format",
    "href": "practice/practice-tidy4-readr-intro.html#your-turn-fixed-width-format",
    "title": "Practice: Importing tables with readr",
    "section": "2.3 Your Turn: Fixed Width Format",
    "text": "2.3 Your Turn: Fixed Width Format\nThe file starwarsfwf.txt has the following content:\n            name gender height weight\n\"Luke Skywalker\"   male   1.72     77\n\"Leia Skywalker\" female    1.5     49\n\"Han Solo\"         male    1.8     80\n\"Obi-Wan Kenobi\"   male   1.82     77\nSee the documentation of the \"readr\" function read_fwf(), and use this function to import the data in starwarsfwf.txt.\nOne suggestion to complete this operation is to specify arguments:\n\nname of the file\ncolumn positions and names—argument col_positions—via the function fwf_widths()\nskip the first line—because column names are being already specified via fwf_widths()\n\n\n\nShow answer\nfwf = read_fwf(\n  file = \"starwarsfwf.txt\",\n  col_positions = fwf_widths(\n    widths = c(16, 7, 7, 7), \n    col_names = c('name', 'gender', 'height', 'weight')),\n  skip = 1)"
  },
  {
    "objectID": "practice/practice-tidy4-readr-intro.html#your-turn-file-with-metadata",
    "href": "practice/practice-tidy4-readr-intro.html#your-turn-file-with-metadata",
    "title": "Practice: Importing tables with readr",
    "section": "2.4 Your Turn: File with metadata",
    "text": "2.4 Your Turn: File with metadata\nTake a look at the file starwarstoy2.txt.\n# Description: Toy data set of some Star Wars characters\n# Format: Tab separated values\n# height units in meters\n# weight units in kilograms\n\n# column names\nname\ngender\nheight\nweight\njedi\n\n# rows\n\"Luke Skywalker\"    male    1.72    77  TRUE\n\"Leia Skywalker\"    female  1.5 49  FALSE\n\"Obi-Wan Kenobi\"    male    1.82    77  TRUE\n\"Han Solo\"  male    1.8 80  FALSE\nAs you can tell, this file has three sections:\n\nThe first four lines of text have some general information with the description of the file, its format, and units of measurement for height and weight\nThe next section, from line 7 to 11, indicates the names of the columns\nThe last section, from line 14 to 17, have the actual data table\n\nYour goal is to write commands, without hardcoding any values, in order to import the data table (with their corresponding column names). We recommend the following strategy:\n\nuse read_lines() to import the first 11 lines in a character vector,\nfrom the character vector of step (1), extract those elements that correspond to the column names; this will give you a character vector with just the column names,\nuse read_tsv() to import the data values starting at line 14 (i.e. by skipping the first 13 lines), specifying the column names previously extracted in the character vector of step (2); as well as providing sensible values for the col_types argument.\n\n\n\nShow answer\n# step 1\nfirst_lines = read_lines(\"starwarstoy2.txt\", n_max = 11)\n\n# step 2\ncolumn_names = tail(first_lines, 5)\n\n# step 3\nsw2 = read_tsv(\n  file = \"starwarstoy2.txt\", \n  skip = 13, \n  col_names = column_names,\n  col_types = \"ccddl\")"
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html",
    "href": "practice/practice-prog2-functions-ifelse.html",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nCreate functions\nUse conditional statements in your functions\nUse stop() to stop execution of a function when applicable\nUse warning() to provide a warning message when applicable\nInclude comments to document a function\nIn this module you will practice writing simple functions, and some basic examples to make sure that the functions work as expected. In addition to writing the functions, you should also practice documenting your functions. Writing this type of documentation should become second nature."
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html#roxygen-comments",
    "href": "practice/practice-prog2-functions-ifelse.html#roxygen-comments",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "1.1 Roxygen Comments",
    "text": "1.1 Roxygen Comments\n\n\n\n\n\n\nPro Tip\n\n\n\nRoxygen comments are a special style for writing a function’s documentation.\n\n\nFrom time to time, you will encounter code in R that use a special type of comments to define the documentation of a function: so-called roxygen comments. These comments follow a specific syntax, and they are commonly used when writing functions for an R package. Here’s an example:\n\n#' @title area of rectangle\n#' @description calculates the area of a rectangle\n#' @param len length of the rectangle (numeric)\n#' @param wid width of the rectangle (numeric)\n#' @return computed area\nrect_area &lt;- function(len = 1, wid = 1) {\n  if (len &lt; 0) {\n    stop(\"len must be positive\")\n  }\n  if (wid &lt; 0) {\n    stop(\"wid must be positive\")\n  }\n  area &lt;- len * wid\n  return(area)\n}\n\nOnce the function has been created, we can test it with a couple of basic examples:\n\n# default\nrect_area()\n\n[1] 1\n\n# len=2, wid=3\nrect_area(len = 2, wid = 3)\n\n[1] 6\n\n# bad len\nrect_area(len = -2, wid = 3)\n\nError in rect_area(len = -2, wid = 3): len must be positive\n\n# bad wid\nrect_area(len = 2, wid = -3)\n\nError in rect_area(len = 2, wid = -3): wid must be positive"
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html#your-turn-circle_area-version-1",
    "href": "practice/practice-prog2-functions-ifelse.html#your-turn-circle_area-version-1",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "2.1 Your Turn: circle_area() version 1",
    "text": "2.1 Your Turn: circle_area() version 1\nWrite a function circle_area() that calculates the area of a circle.\n\nThis function must take one argument radius.\nGive radius a default value of 1.\nInclude comments to document your function! You can use regular comments, or if you feel brave enough try using roxygen comments.\n\n\n\nShow answer\n#' @title area of circle\n#' @description computes the area of a circle of given radius\n#' @param radius numeric value\n#' @return area\ncircle_area &lt;- function(radius = 1) {\n  pi * radius^2\n}\n\n\nTest your function with:\n\nno specified arguments: i.e. circle_area();\nwith radius = 3\n\n\n# default (radius 1)\ncircle_area()\n\n[1] 3.141593\n\n# radius 3\ncircle_area(radius = 3)\n\n[1] 28.27433"
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html#your-turn-circle_area-version-2",
    "href": "practice/practice-prog2-functions-ifelse.html#your-turn-circle_area-version-2",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "2.2 Your Turn: circle_area() version 2",
    "text": "2.2 Your Turn: circle_area() version 2\nModify your circle_area() function in order to include a stop() statement. If radius is negative, then the function should stop with a meaningful error message, perhaps something like: \"radius cannot be negative\".\n\n\nShow answer\n#' @title area of circle\n#' @description computes the area of a circle of given radius\n#' @param radius numeric value\n#' @return area\ncircle_area &lt;- function(radius = 1) {\n  if (radius &lt; 0) {\n    stop('radius cannot be negative')\n  }\n  pi * radius^2\n}\n\n\nTest your modified circle_area() with radius = -2; the function should return a stop message:\n\n# bad radius\ncircle_area(radius = -2)\n\nError in circle_area(radius = -2): radius cannot be negative"
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html#your-turn-cylinder_area-function",
    "href": "practice/practice-prog2-functions-ifelse.html#your-turn-cylinder_area-function",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "3.1 Your Turn: cylinder_area() function",
    "text": "3.1 Your Turn: cylinder_area() function\nWrite a function cylinder_area(), that calls circle_area(), to compute the area of a cylinder.\n\nThis function must take two arguments: radius and height,\nGive both arguments a default value of 1.\nThe function should stop if any of radius or height are negative. Since you are calling circle_area(), you already have a stop() statement for a negative radius.\nInclude documentation comments.\n\n\n\nShow answer\n#' @title area of cylinder\n#' @description computes the area of a cylinder\n#' @param radius numeric value\n#' @param height numeric value\n#' @return area\ncylinder_area &lt;- function(radius = 1, height = 1) {\n  if (height &lt; 0) {\n    stop('height must be positive')\n  }\n  lateral_area &lt;- 2 * pi * radius * height\n  base_areas &lt;- 2 * circle_area(radius)\n  lateral_area + base_areas\n}\n\n\nFor instance:\n\n# default (radius 1, height 1)\ncylinder_area()\n\n[1] 12.56637\n\n# radius 2, height 3\ncylinder_area(radius = 2, height = 3)\n\n[1] 62.83185\n\n\nThese should return a meaningful error message:\n\n# bad radius\ncylinder_area(radius = -2, height = 1)\n\nError in circle_area(radius): radius cannot be negative\n\n# bad height\ncylinder_area(radius = 2, height = -1)\n\nError in cylinder_area(radius = 2, height = -1): height must be positive"
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html#your-turn-is_even-function",
    "href": "practice/practice-prog2-functions-ifelse.html#your-turn-is_even-function",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "4.1 Your Turn: is_even() function",
    "text": "4.1 Your Turn: is_even() function\nWrite a function is_even() that determines whether a number is even (i.e. multiple of 2).\n\nIf the input number is even, the output should be TRUE.\nIf the input number is odd, the output should be FALSE.\nIf the input is not a number, the output should be NA\nInclude documentation comments.\n\n\n\nShow answer\n#' @title is even\n#' @description test if a given number is even\n#' @param x numeric value\n#' @return whether the input is even\nis_even &lt;- function(x) {\n  if (is.numeric(x)) {\n    return(x %% 2 == 0)\n  } else {\n    return(NA)\n  }\n}\n\n\nTest your function:\n\n# even number\nis_even(10)\n\n[1] TRUE\n\n# odd number\nis_even(33)\n\n[1] FALSE\n\n# not a number\nis_even('a')\n\n[1] NA"
  },
  {
    "objectID": "practice/practice-prog2-functions-ifelse.html#your-turn-is_odd-function",
    "href": "practice/practice-prog2-functions-ifelse.html#your-turn-is_odd-function",
    "title": "Practice: Functions and if-else statements (part 2)",
    "section": "4.2 Your Turn: is_odd() function",
    "text": "4.2 Your Turn: is_odd() function\nUse your function is_even() to write a function is_odd() that determines if a number is odd (i.e. not a multiple of 2).\n\nIf a number is odd, the output should be TRUE;\nIf a number is even the output should be FALSE;\nIf the input is not a number the output should be NA\nInclude documentation comments.\n\n\n\nShow answer\n#' @title is odd\n#' @description test if a given number is odd\n#' @param x numeric value\n#' @return whether the input is odd\nis_odd &lt;- function(x) {\n  !is_even(x)\n}\n\n\nTest is_odd() with the following cases:\n\n# odd number\nis_odd(1)\n\n[1] TRUE\n\n# even number\nis_odd(4)\n\n[1] FALSE\n\n# not a number\nis_odd('a')\n\n[1] NA"
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html",
    "href": "practice/practice-objs1-vector-basics.html",
    "title": "Practice: Vectors (part 1)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nWork with vectors of different data types\nUnderstand the concept of coercion\nUnderstand the concept of vectorization\nUnderstand recycling rules in R"
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html#combine-function-c",
    "href": "practice/practice-objs1-vector-basics.html#combine-function-c",
    "title": "Practice: Vectors (part 1)",
    "section": "2.1 Combine function c()",
    "text": "2.1 Combine function c()\nThe most common way to create an R vector is with the combine function c(). Here’s an example:\n\njovians = c(\"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\")\njovians\n\n[1] \"Jupiter\" \"Saturn\"  \"Uranus\"  \"Neptune\"\n\n\n\n2.1.1 Your Turn\n\nCreate a character vector planets with the names of the Terrestrial planets.\n\n\n\nShow answer\nplanets = c(\"Mercury\", \"Venus\", \"Earth\", \"Mars\")\n\n\n\nUse the combine function c() to make vectors gravity and daylength for the Terrestrial planets.\n\n\n\nShow answer\ngravity = c(3.7, 8.9, 9.8, 3.7)\n\ndaylength = c(4222.6, 2802, 24, 24.7)\n\n\n\n\n2.1.2 Integer vectors\nThe creation of the temperature vector seems to be straightforward:\n\ntemp &lt;- c(167, 464, 15, -65)\ntemp\n\n[1] 167 464  15 -65\n\n\nBut there is a catch. The issue is that the way temp was created is as a vector of type \"double\" instead of type \"integer\" as required:\n\ntypeof(temp)\n\n[1] \"double\"\n\n\nSo how do you create integer vectors in R? You have to use a special notation for integer numbers. Here’s an example:\n\nints = c(2L, 4L, 6L)\nints\n\n[1] 2 4 6\n\n\nNotice how we append an upper case L at the end of every numeric value. This is how you tell R to store such numbers as integers.\n\n\n2.1.3 Your Turn\n\nUse the combine function to create integer vectors temp and moons for the Terrestrial planets. Inspect their data types, with typeof(), to confirm that they are integer vectors.\n\n\n\nShow answer\ntemp = c(167L, 464L, 15L, -65L)\n\nmoons = c(0L, 0L, 1L, 2L)\n\n\n\nUse the combine function to create a logical vector (logical values are TRUE and FALSE) for the variable haswater.\n\n\n\nShow answer\nhaswater = c(FALSE, FALSE, TRUE, FALSE)"
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html#your-turn-2",
    "href": "practice/practice-objs1-vector-basics.html#your-turn-2",
    "title": "Practice: Vectors (part 1)",
    "section": "3.1 Your Turn",
    "text": "3.1 Your Turn\nInspect the data type of the following combination of vectors:\n\ncombine planets with gravity\n\n\n\nShow answer\ntypeof(c(planets, gravity))\n\n\n\ncombine planets with temp\n\n\n\nShow answer\ntypeof(c(planets, temp))\n\n\n\ncombine planets with haswater\n\n\n\nShow answer\ntypeof(c(planets, haswater))\n\n\n\ngravity with daylength\n\n\n\nShow answer\ntypeof(c(gravity, daylength))\n\n\n\ncombine gravity with temp\n\n\n\nShow answer\ntypeof(c(gravity, temp))\n\n\n\ncombine temp with moons\n\n\n\nShow answer\ntypeof(c(temp, moons))\n\n\n\ncombine temp with haswater\n\n\n\nShow answer\ntypeof(c(temp, haswater))\n\n\nCan you see a pattern?"
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html#vectorization-example",
    "href": "practice/practice-objs1-vector-basics.html#vectorization-example",
    "title": "Practice: Vectors (part 1)",
    "section": "4.1 Vectorization Example",
    "text": "4.1 Vectorization Example\nHere’s an example. Let’s bring back the integer vector ints, and suppose that we want to obtain the square root of all its elements. One option to do this is by taking the square root of each element in ints, one by one—separately—using the sqrt() function:\n\nsqrt(ints[1])\n\n[1] 1.414214\n\nsqrt(ints[2])\n\n[1] 2\n\nsqrt(ints[3])\n\n[1] 2.44949\n\n\nWe haven’t talked about this yet, but notice how you refer to the elements in a vector by indicating their position: using square brackets [ ] with a numeric index for the position of the element you want to operate on.\nNow, instead of having to repeat the same command three times, we can use the function sqrt() in a single call because it is a vectorized function. This means that sqrt() can compute the square root of all the elements in a vector simultaneously:\n\nsqrt(ints)\n\n[1] 1.414214 2.000000 2.449490\n\n\nLikewise, pretty much all arithmetic operators (addition, subtraction, multiplication, division, power, etc) are vectorized. For instance, say we want to add c(1,2,3) to ints, here’s how to do it with vectorized code:\n\nints + c(1, 2, 3)\n\n[1] 3 6 9"
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html#your-turn-3",
    "href": "practice/practice-objs1-vector-basics.html#your-turn-3",
    "title": "Practice: Vectors (part 1)",
    "section": "4.2 Your Turn",
    "text": "4.2 Your Turn\n\nRefer to the vector gravity and create a new vector gravity_log by taking the logarithm, with log(), of the values in gravity\n\n\n\nShow answer\ngravity_log = log(gravity)\n\n\n\nRefer to the vectors moons and haswater. Try adding them and see what happens. What is R doing in this case?\n\n\n\nShow answer\nmoons + haswater\n\n\n\nRefer to the vectors moons and haswater. Try subtracting them, e.g.  moons - haswater, and see what happens. What is R doing in this case?\n\n\n\nShow answer\nmoons - haswater"
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html#recycling-example",
    "href": "practice/practice-objs1-vector-basics.html#recycling-example",
    "title": "Practice: Vectors (part 1)",
    "section": "5.1 Recycling Example",
    "text": "5.1 Recycling Example\nConsider the vectors ints and values which, by the way, are of different length:\n\nints\n\n[1] 2 4 6\n\nvalues\n\n[1]  2  4  6  8 10\n\n\nWhat if we try to add ints and values? Is this possible?\n\nints + values\n\nWarning in ints + values: longer object length is not a multiple of shorter\nobject length\n\n\n[1]  4  8 12 10 14\n\n\nYes, you can add two numeric vectors of different lengths such as ints plus values. Notice though that R gives a warning message along the lines of\n\nlonger object length is not a multiple of shorter object length\n\nThis message tells you that the length of the longer vector, values, is not a multiple of the length of the shorter vector ints.\nWhen computing ints + values, R is basically recycling or repeating some of the numbers in ints to match the length of values. To be more precise, here is what R is adding:\n2L + 2 = 4\n4L + 4 = 6\n6L + 6 = 12\n2L + 8 = 10\n4L + 10 = 14\nAll the integer numbers come from ints whereas all the double numbers come from values."
  },
  {
    "objectID": "practice/practice-objs1-vector-basics.html#your-turn-4",
    "href": "practice/practice-objs1-vector-basics.html#your-turn-4",
    "title": "Practice: Vectors (part 1)",
    "section": "5.2 Your Turn",
    "text": "5.2 Your Turn\n\nRefer to the vector daylength (measured in hours) and create a new vector dayminutes in which the units are expressed in minutes instead of hours.\n\n\n\nShow answer\ndayminutes = daylength * 60\n\n\n\nRefer to the vector temp (measured in Celsius degrees) and create a new vector temp2 in which the units are expressed in Fahrenheit degrees. The conversion factor from Celsius to Fahrenheit is:\n\n\\[\n(1^{\\circ}C × 9/5) + 32 = 33.8^{\\circ}F\n\\]\n\n\nShow answer\ntemp2 = (temp * 9/5) + 32\n\n\n\nUse the power operator ^ to raise ints to the values of moons: e.g. ints^moons. If you get a warning, why is so? What is R doing behind this operation?\n\n\n\nShow answer\n# R gives a warning because the longer vector \"moons\" is not a\n# multiple of the shorter vector \"ints\""
  },
  {
    "objectID": "practice/practice-tidy1-ggplot-intro.html",
    "href": "practice/practice-tidy1-ggplot-intro.html",
    "title": "Practice: Graphics with ggplot2 (part 1)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nDefine a function that takes arguments\nReturn a value from a function\nTest a function\nSet default values for function arguments\nThe content of this module is an adapted excerpt from Winston Chang’s R Graphics Cookbook. Specifically, see Appendix A: Understanding ggplot2."
  },
  {
    "objectID": "practice/practice-tidy1-ggplot-intro.html#storing-a-ggplot-object",
    "href": "practice/practice-tidy1-ggplot-intro.html#storing-a-ggplot-object",
    "title": "Practice: Graphics with ggplot2 (part 1)",
    "section": "4.1 Storing a ggplot object",
    "text": "4.1 Storing a ggplot object\nIf you are going to reuse some of these components, you can store them in variables. We can save the ggplot object in an object called gg, and then add geom_point() to it.\n\ngg = ggplot(econ_chem, aes(x = Economics, y = Chemistry)) \n\ngg + geom_point()"
  },
  {
    "objectID": "practice/practice-tidy1-ggplot-intro.html#more-mappings",
    "href": "practice/practice-tidy1-ggplot-intro.html#more-mappings",
    "title": "Practice: Graphics with ggplot2 (part 1)",
    "section": "4.2 More Mappings",
    "text": "4.2 More Mappings\nWe can also map the variable Country to the color of the points, by putting aes() inside the call to geom_point(), and specifying color = Country\n\ngg + geom_point(aes(color = Country))\n\n\n\n\n\n\n\n\nThis doesn’t alter the default aesthetic mappings that we defined previously, inside of ggplot(...). What it does is add an aesthetic mapping for this particular geom, geom_point(). If we added other geoms, this mapping would not apply to them."
  },
  {
    "objectID": "practice/practice-tidy1-ggplot-intro.html#setting-values",
    "href": "practice/practice-tidy1-ggplot-intro.html#setting-values",
    "title": "Practice: Graphics with ggplot2 (part 1)",
    "section": "4.3 Setting Values",
    "text": "4.3 Setting Values\nContrast this aesthetic mapping with aesthetic setting. This time, we won’t use aes(); we’ll just set the value of color directly to \"red\". And we’ll also increase the size of the dots by setting size:\n\ngg + geom_point(color = \"red\", size = 3)"
  },
  {
    "objectID": "practice/practice-tidy1-ggplot-intro.html#customizing-scales",
    "href": "practice/practice-tidy1-ggplot-intro.html#customizing-scales",
    "title": "Practice: Graphics with ggplot2 (part 1)",
    "section": "4.4 Customizing Scales",
    "text": "4.4 Customizing Scales\nWe can also modify the scales; that is, the mappings from data to visual attributes. Here, we’ll change the \\(x\\) scale so that it has a larger range:\n\ngg + geom_point() + scale_x_continuous(limits = c(0, 60))\n\n\n\n\n\n\n\n\n\nIf we go back to the example with the color = Country mapping, we can also modify the color scale and customize them with our own values:\n\ngg + \n  geom_point(aes(color = Country)) +\n  scale_color_manual(values = c(\"blue\", \"orange\", \"cyan\", \"magenta\"))"
  },
  {
    "objectID": "practice/practice-prog4-loops.html",
    "href": "practice/practice-prog4-loops.html",
    "title": "Practice: Loops",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nGet familiar with the syntax of a for loop\nWrite simple for loops"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#counting-as-with-vectorized-code",
    "href": "practice/practice-prog4-loops.html#counting-as-with-vectorized-code",
    "title": "Practice: Loops",
    "section": "2.1 Counting a’s with vectorized code",
    "text": "2.1 Counting a’s with vectorized code\nSay we are interested in counting the number of letters \"a\". This can be easily done in R with some vectorized code:\n\nsum(letrs == 'a')\n\n[1] 5\n\n\nFor learning purposes, we are going to ask you to forget about vectorization for a moment. And instead let’s see how to use loops."
  },
  {
    "objectID": "practice/practice-prog4-loops.html#counting-as-with-a-for-loop",
    "href": "practice/practice-prog4-loops.html#counting-as-with-a-for-loop",
    "title": "Practice: Loops",
    "section": "2.2 Counting a’s with a for loop",
    "text": "2.2 Counting a’s with a for loop\nAlternatively, we can also write a for loop that iterates through each element of letrs, testing whether we have an \"a\", and if yes, the count increases by one.\n\n# start at count zero\ncount_a = 0\n\nfor (pos in 1:length(letrs)) {\n  # increase count if letter is an 'a'\n  if (letrs[pos] == 'a') {\n    count_a = count_a + 1\n  }\n}\n\ncount_a\n\n[1] 5"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#counting-x-y-and-z-with-a-for-loop",
    "href": "practice/practice-prog4-loops.html#counting-x-y-and-z-with-a-for-loop",
    "title": "Practice: Loops",
    "section": "2.3 Counting x, y and z with a for loop",
    "text": "2.3 Counting x, y and z with a for loop\nSay we are interested in counting the number of x, y and z letters, using a for loop. Here’s one possibility:\n\n# start at count zero\ncount_xyz = 0\n\nfor (pos in 1:length(letrs)) {\n  # increase count if letter is x, y, or z\n  if (letrs[pos] %in% c('x', 'y', 'z')) {\n    count_xyz = count_xyz + 1\n  }\n}\n\ncount_xyz\n\n[1] 12"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#stopping-a-loop-with-break",
    "href": "practice/practice-prog4-loops.html#stopping-a-loop-with-break",
    "title": "Practice: Loops",
    "section": "2.4 Stopping a loop with break",
    "text": "2.4 Stopping a loop with break\nSay we are interested in counting the number of x, y and z letters, using a for loop, but this time, we only want to count until we get the fifth occurrence.\n\n# start at count zero\ncount_xyz = 0\n\nfor (pos in 1:length(letrs)) {\n  # increase count if letter is x, y, or z\n  if (letrs[pos] %in% c('x', 'y', 'z')) {\n    count_xyz = count_xyz + 1\n  }\n  # break loop if count gets to fifth occurrence\n  if (count_xyz == 5) {\n    break\n  }\n}\n\ncount_xyz\n\n[1] 5\n\n\nNotice the use of the break statement to decide whether the loop should stop from iterating."
  },
  {
    "objectID": "practice/practice-prog4-loops.html#number-of-letters-different-from-b",
    "href": "practice/practice-prog4-loops.html#number-of-letters-different-from-b",
    "title": "Practice: Loops",
    "section": "3.1 Number of letters different from \"b\"",
    "text": "3.1 Number of letters different from \"b\"\nConsider the vector letrs defined in the previous section. Write a for loop in order to count the number of letters different from \"b\"\n\n\nShow answer\n# start count at zero\ncount_not_b = 0\n\nfor (pos in 1:length(letrs)) {\n  # increase count if letter is not a 'b'\n  if (letrs[pos] != 'b') {\n    count_not_b = count_not_b + 1\n  }\n}\n\ncount_not_b"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#number-of-f-or-w-in-even-positions",
    "href": "practice/practice-prog4-loops.html#number-of-f-or-w-in-even-positions",
    "title": "Practice: Loops",
    "section": "3.2 Number of \"f\" or \"w\" in even positions",
    "text": "3.2 Number of \"f\" or \"w\" in even positions\nConsider the vector letrs. Write a for loop in order to count the number of letters equal to f or w that are in even positions (e.g.  2, 4, …, 100). Hint: the function seq() is your friend.\n\n\nShow answer\n# start count at zero\ncount_fw = 0\n\nfor (pos in seq(2, 100, by = 2)) {\n  # increase count if letter is 'f' or 'w'\n  if (letrs[pos] == 'f' | letrs[pos] == 'w') {\n    count_fw = count_fw + 1\n  }\n}\n\ncount_fw"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#counting-vowels",
    "href": "practice/practice-prog4-loops.html#counting-vowels",
    "title": "Practice: Loops",
    "section": "3.3 Counting vowels",
    "text": "3.3 Counting vowels\nConsider the vector letrs. Write a for loop in order to count the number of vowels, until reaching exactly 15 vowels. How many iterations were necessary to obtain 15 vowels?\n\n\nShow answer\n# start count at zero\ncount_vowels = 0\n\nfor (pos in 1:length(letrs)) {\n  # increase count if letter is a vowel\n  if (letrs[pos] %in% c('a', 'e', 'i', 'o', 'u')) {\n    count_vowels = count_vowels + 1\n  }\n  if (count_vowels == 15) {\n    break\n  }\n}\n\n# number of iterations\npos"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#arithmetic-series",
    "href": "practice/practice-prog4-loops.html#arithmetic-series",
    "title": "Practice: Loops",
    "section": "4.1 Arithmetic Series",
    "text": "4.1 Arithmetic Series\nConsider the following arithmetic series\n\\[\na_n = a_1 + (n-1)d\n\\]\nWrite a for loop to compute this series when \\(a_1 = 3\\), and \\(d = 3\\). For instance: \\(3 + 6 + 12 + 24 + \\dots\\). Test your code with different values for \\(n\\). Does the series converge as \\(n\\) increase?\n\n\nShow answer\n# inputs\na1 = 3\nd = 3\nnum = 10\n\n# outputs\nseries = rep(0, num)\nsum_series = 0\n\n# iterations\nfor (n in 1:num) {\n  an = a1 + (n-1)*d\n  series[n] = an\n  sum_series = sum_series + an\n}\n\n# series does not converge as 'n' increases"
  },
  {
    "objectID": "practice/practice-prog4-loops.html#geometric-sequence",
    "href": "practice/practice-prog4-loops.html#geometric-sequence",
    "title": "Practice: Loops",
    "section": "4.2 Geometric Sequence",
    "text": "4.2 Geometric Sequence\nA sequence such as \\(3, 6, 12, 24, 48\\) is an example of a geometric sequence. In this type of sequence, the \\(n\\)-th term is obtained as:\n\\[\na_n = a_1 \\times r^{n-1}\n\\]\nwhere: \\(a_1\\) is the first term, \\(r\\) is the common ratio, and \\(n\\) is the number of terms.\nWrite a for loop to compute the sum of the first \\(n\\) terms of: \\(3 + 6 + 12 + 24 + \\dots\\). Test your code with different values for \\(n\\). Does the series converge as \\(n\\) increase?\n\n\nShow answer\n# inputs\na1 = 3\nr = 2\n\n# outputs\nsumm = 0\n\nfor (n in 1:10) {\n  an = a1 * r^(n-1)\n  summ = summ + an\n}\n\n# series does not converge as 'n' increases"
  },
  {
    "objectID": "practice/practice-objs4-matrices.html",
    "href": "practice/practice-objs4-matrices.html",
    "title": "Practice: Matrices",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nCreate Matrices with matrix()\nCreate Matrices with cbind() and rbind()\nSubset (subscript) matrices with brackets mat[row,col]"
  },
  {
    "objectID": "practice/practice-objs4-matrices.html#argument-byrow",
    "href": "practice/practice-objs4-matrices.html#argument-byrow",
    "title": "Practice: Matrices",
    "section": "1.1 Argument byrow",
    "text": "1.1 Argument byrow\nThe matrix() function comes with the byrow argument that allows you to arrange values by-row instead of by-column; here’s an example:\n\n# example 2\nm3 &lt;- matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE)\nm3\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\n\nKeep in mind that m3 is still stored column-major. You can confirm this by asking R to vectorize m3\n\nas.vector(m3)\n\n[1] 1 4 2 5 3 6"
  },
  {
    "objectID": "practice/practice-objs4-matrices.html#another-matrix-example",
    "href": "practice/practice-objs4-matrices.html#another-matrix-example",
    "title": "Practice: Matrices",
    "section": "1.2 Another matrix() example",
    "text": "1.2 Another matrix() example\nHow do you create the following matrix?\n\n\n     [,1]       [,2]     \n[1,] \"Harry\"    \"Potter\" \n[2,] \"Ron\"      \"Weasley\"\n[3,] \"Hermione\" \"Granger\"\n\n\nHere’s one way to create the preceding matrix:\n\n# vector of names\nhp &lt;- c(\"Harry\", \"Ron\", \"Hermione\",\n        \"Potter\", \"Weasley\", \"Granger\")\n\n# matrix filled up by rows\nmatrix(hp, nrow = 3)\n\n     [,1]       [,2]     \n[1,] \"Harry\"    \"Potter\" \n[2,] \"Ron\"      \"Weasley\"\n[3,] \"Hermione\" \"Granger\"\n\n\nHere’s another way to create the same matrix:\n\n# vector of names\nhp &lt;- c(\"Harry\", \"Potter\", \"Ron\", \"Weasley\", \n        \"Hermione\", \"Granger\")\n\n# matrix filled up by rows\nmatrix(hp, nrow = 3, byrow = TRUE)\n\n     [,1]       [,2]     \n[1,] \"Harry\"    \"Potter\" \n[2,] \"Ron\"      \"Weasley\"\n[3,] \"Hermione\" \"Granger\""
  },
  {
    "objectID": "practice/practice-objs4-matrices.html#dimensions-and-names",
    "href": "practice/practice-objs4-matrices.html#dimensions-and-names",
    "title": "Practice: Matrices",
    "section": "1.3 Dimensions and Names",
    "text": "1.3 Dimensions and Names\nMatrices have:\n\nlength(): number of cells\ntypeof(): data type (recall that matrices are atomic)\ndim(): dimensions; number of rows and columns\n\nnrow(): number of rows\nncol(): number of columns\n\n\nWe also have functions that let you set/get the names for either the rows or the columns (or both) of a matrix:\n\nrownames()\ncolnames()\ndimnames()\n\n\n# rownames\nset.seed(123)\nA &lt;- matrix(runif(12), nrow = 3, ncol = 4)\nrownames(A) &lt;- paste0(\"row\", 1:nrow(A))\nA\n\n          [,1]      [,2]      [,3]      [,4]\nrow1 0.2875775 0.8830174 0.5281055 0.4566147\nrow2 0.7883051 0.9404673 0.8924190 0.9568333\nrow3 0.4089769 0.0455565 0.5514350 0.4533342\n\nrownames(A)\n\n[1] \"row1\" \"row2\" \"row3\"\n\n\n\nset.seed(123)\nB &lt;- matrix(runif(12), nrow = 3, ncol = 4)\ncolnames(B) &lt;- paste0(\"col\", 1:ncol(B))\nB\n\n          col1      col2      col3      col4\n[1,] 0.2875775 0.8830174 0.5281055 0.4566147\n[2,] 0.7883051 0.9404673 0.8924190 0.9568333\n[3,] 0.4089769 0.0455565 0.5514350 0.4533342\n\ncolnames(B)\n\n[1] \"col1\" \"col2\" \"col3\" \"col4\"\n\n\n\nset.seed(123)\nC &lt;- matrix(runif(12), nrow = 3, ncol = 4)\nrownames(C) &lt;- paste0(\"row\", 1:nrow(C))\ncolnames(C) &lt;- paste0(\"col\", 1:ncol(C))\nC\n\n          col1      col2      col3      col4\nrow1 0.2875775 0.8830174 0.5281055 0.4566147\nrow2 0.7883051 0.9404673 0.8924190 0.9568333\nrow3 0.4089769 0.0455565 0.5514350 0.4533342\n\ndimnames(C)\n\n[[1]]\n[1] \"row1\" \"row2\" \"row3\"\n\n[[2]]\n[1] \"col1\" \"col2\" \"col3\" \"col4\""
  },
  {
    "objectID": "practice/practice-objs4-matrices.html#recycling-in-matrices",
    "href": "practice/practice-objs4-matrices.html#recycling-in-matrices",
    "title": "Practice: Matrices",
    "section": "1.4 Recycling in matrices",
    "text": "1.4 Recycling in matrices\nRecycling rules also apply to matrices, for example:\n\nx &lt;- letters[1:4]\nX &lt;- matrix(x, nrow = 4, ncol = 3)\nX\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"a\"  \"a\" \n[2,] \"b\"  \"b\"  \"b\" \n[3,] \"c\"  \"c\"  \"c\" \n[4,] \"d\"  \"d\"  \"d\" \n\n\nHere are more recycling examples:\n\n# \"empty\" matrices\nmat_chr &lt;- matrix(\"\", nrow = 4, ncol = 3)\n\nmat_num &lt;- matrix(0, nrow = 4, ncol = 3)\n\nmat_lgl &lt;- matrix(NA, nrow = 4, ncol = 3)"
  },
  {
    "objectID": "practice/practice-objs4-matrices.html#row-and-column-binding",
    "href": "practice/practice-objs4-matrices.html#row-and-column-binding",
    "title": "Practice: Matrices",
    "section": "1.5 Row and Column binding",
    "text": "1.5 Row and Column binding\nAnother way to form matrices is by joining or binding either vectors or matrices by rows—with rbind()—or by columns—with cbind(). For example:\n\na &lt;- c(2, 4, 6)\nb &lt;- c(1, 3, 5)\n\n\n# column bind\ncbind(a, b)\n\n     a b\n[1,] 2 1\n[2,] 4 3\n[3,] 6 5\n\n\n\ncbind(m3, b)\n\nWarning in cbind(m3, b): number of rows of result is not a multiple of vector\nlength (arg 2)\n\n\n           b\n[1,] 1 2 3 1\n[2,] 4 5 6 3\n\n\n\n# row bind\nrbind(b, a)\n\n  [,1] [,2] [,3]\nb    1    3    5\na    2    4    6\n\n\n\nrbind(m2, a)\n\nWarning in rbind(m2, a): number of columns of result is not a multiple of\nvector length (arg 2)\n\n\n  [,1] [,2]\n     1    4\n     2    5\n     3    6\na    2    4"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\nThis work is licensed under CC BY-NC-SA 4.0\n\n\n\nShare: copy and redistribute the material in any medium or format.\nAdapt: remix, transform, and build upon the material.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\n\n\n\n\n\nAttribution: You must give appropriate credit , provide a link to the license, and indicate if changes were made . You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNonCommercial: You may not use the material for commercial purposes.\nShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\nNo additional restrictions: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n\nFor more information, see CC BY-NC-SA 4.0"
  },
  {
    "objectID": "license.html#cc-by-nc-sa-4.0",
    "href": "license.html#cc-by-nc-sa-4.0",
    "title": "License",
    "section": "",
    "text": "Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\nThis work is licensed under CC BY-NC-SA 4.0\n\n\n\nShare: copy and redistribute the material in any medium or format.\nAdapt: remix, transform, and build upon the material.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\n\n\n\n\n\nAttribution: You must give appropriate credit , provide a link to the license, and indicate if changes were made . You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nNonCommercial: You may not use the material for commercial purposes.\nShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\nNo additional restrictions: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.\n\nFor more information, see CC BY-NC-SA 4.0"
  },
  {
    "objectID": "staff.html",
    "href": "staff.html",
    "title": "Staff",
    "section": "",
    "text": "Append @berkeley.edu to all email addresses.\nOffice hours are subject to change.\nYou can attend OH of any staff member.\n\n\n\nInstructor: Gaston Sanchez gastonsanchez Office hours:  - Fri 4:20pm-5:20pm, Evans 309\n\n\nGSI: Calvin Carter calv2n Office hours: - Tue 11am-1pm, Evans 426 - Fri 3pm-5pm, Evans 426\n\n\nGSI: Huong Vu huong_vu Office hours:  - Tue 2pm-4pm, Evans 426 - Wed 2pm-4pm, Evans 426\n\n\nGSI: Dylan Webb dylancw Office hours:  - Mon 2pm-4pm, Evans 426 - Fri 9am-11am on Zoom\n\n\nTutor: David Sun davidzhongyisun Office hours:  - Wed 3:15pm-6:45pm, Evans 340 - Thr 12:15pm-1:45pm, Evans 426\n\n\nTutor: Ari Hadjiyianni hadjiyianni Office hours:  - Mon 2pm-4pm, Evans 434 - Wed 2pm-4pm, Evans 332 - Thr 2pm-3pm, Evans 426 - Fri 2pm-4pm, Evans 434",
    "crumbs": [
      "Staff"
    ]
  },
  {
    "objectID": "units/unit6.html",
    "href": "units/unit6.html",
    "title": "6) Tables and Tidyverse-2",
    "section": "",
    "text": "This week we continue with another fundamental tidyverse package \"dplyr\". Simply put, dplyr comes with functions that allow you to manipulate data-tables (e.g. data-frames, and other 2-dimensional objects) using a modern and syntactic way.",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit6.html#lecture",
    "href": "units/unit6.html#lecture",
    "title": "6) Tables and Tidyverse-2",
    "section": "",
    "text": "This week we continue with another fundamental tidyverse package \"dplyr\". Simply put, dplyr comes with functions that allow you to manipulate data-tables (e.g. data-frames, and other 2-dimensional objects) using a modern and syntactic way.",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit6.html#reading",
    "href": "units/unit6.html#reading",
    "title": "6) Tables and Tidyverse-2",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 5 to 10 of “R Tidy Hurricanes”:\n\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/2-02-intro-dplyr.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/2-03-intro-pipes.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/3-01-storms-year.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/3-02-storms-1975.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/3-03-amy-1975.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/3-04-summary-1975.html",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit6.html#lab",
    "href": "units/unit6.html#lab",
    "title": "6) Tables and Tidyverse-2",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nYou will get to practice common manipulation operations of data-tables using a modern and syntactic way following the data plying framework provided by the R package dplyr.\nAlso, we are going to review various aspects that have to do with reading in (i.e. importing) tables in R.",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit6.html#objectives",
    "href": "units/unit6.html#objectives",
    "title": "6) Tables and Tidyverse-2",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\nPerform basic manipulations on data tables with “dplyr” functions:\n\nSelect rows with slice(), and filter()\nSelect columns with select()\nTransform columns with mutate()\nArrange rows with arrange()\nGroup data with group_by()\nSummarize data with summarize()",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit6.html#shiny-friday",
    "href": "units/unit6.html#shiny-friday",
    "title": "6) Tables and Tidyverse-2",
    "section": "🔆 Shiny Friday",
    "text": "🔆 Shiny Friday\nThe shiny app for this week uses the mtcars data set to visualize the top-n cars given a selected variable.\n\nmtcars-topn-barchart: produces a simple barchart—via \"ggplot2\"—to visualize the top-n cars given a selected variable. In addition to the plot, it also displays a table with the top-n cars. More important, this app uses a so-called reactive conductor element. https://github.com/data133/shiny/tree/main/mtcars-topn-barchart",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit6.html#assignments",
    "href": "units/unit6.html#assignments",
    "title": "6) Tables and Tidyverse-2",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nHW4 due this 10/04\nHW5 released on 10/05, due 10/11",
    "crumbs": [
      "Units",
      "6) Tables and Tidyverse-2"
    ]
  },
  {
    "objectID": "units/unit5.html",
    "href": "units/unit5.html",
    "title": "5) Tables and Tidyverse-1",
    "section": "",
    "text": "One of the main parts of the course involves working with tabular data, which is the most ubiquitous format in which data is handled. And even if the raw data is not in tabular format, sooner or later, you’ll be dealing with data in tabular format in most Data Analysis Projects.\nThe good news is that there are many tools (e.g. packages & functions) in R to work with tables. Due to time constraints, we will focus only on 2 approaches:\n\nThe “classic” approach which is based on data.frames, the dedicated data object in R to handle tabular data.\nThe “tidyverse” approach which is based on tibbles (a modern data.frame), and provides a rich ecosystem of packages chiefly designed for working with tables.\n\nWe start this week by looking at some important details about data frames, and how to manipulate them from a “classic” approach in R.\nWe are also going to get our feet wet making graphics with the Tidyverse package \"ggplot2\". In particular you’ll learn about the Grammar of Graphics and its central idea: a graphic involves mapping data to geometric objects and their visual attributes. This is the underlying framework behind the mechanics and core functions available in “ggplot2” for creating simple graphics:\n\nBegin your graphic specification with ggplot()\nIndicate where the data comes from\nEstablish which variables are going to be mapped into visual attributes: aes()\nDecide what kind of geometric object(s) will be used to display data; e.g. geom_point()\nOptional: do you need to use facets?\nOptional: do you need to explicitly use one or more statistical transformations?\nOptional: do you need to explicitly set a non-default system of coordinates?\nOptional: do you need to explicitly use a non-default theme of graphical elements?",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit5.html#lecture",
    "href": "units/unit5.html#lecture",
    "title": "5) Tables and Tidyverse-1",
    "section": "",
    "text": "One of the main parts of the course involves working with tabular data, which is the most ubiquitous format in which data is handled. And even if the raw data is not in tabular format, sooner or later, you’ll be dealing with data in tabular format in most Data Analysis Projects.\nThe good news is that there are many tools (e.g. packages & functions) in R to work with tables. Due to time constraints, we will focus only on 2 approaches:\n\nThe “classic” approach which is based on data.frames, the dedicated data object in R to handle tabular data.\nThe “tidyverse” approach which is based on tibbles (a modern data.frame), and provides a rich ecosystem of packages chiefly designed for working with tables.\n\nWe start this week by looking at some important details about data frames, and how to manipulate them from a “classic” approach in R.\nWe are also going to get our feet wet making graphics with the Tidyverse package \"ggplot2\". In particular you’ll learn about the Grammar of Graphics and its central idea: a graphic involves mapping data to geometric objects and their visual attributes. This is the underlying framework behind the mechanics and core functions available in “ggplot2” for creating simple graphics:\n\nBegin your graphic specification with ggplot()\nIndicate where the data comes from\nEstablish which variables are going to be mapped into visual attributes: aes()\nDecide what kind of geometric object(s) will be used to display data; e.g. geom_point()\nOptional: do you need to use facets?\nOptional: do you need to explicitly use one or more statistical transformations?\nOptional: do you need to explicitly set a non-default system of coordinates?\nOptional: do you need to explicitly use a non-default theme of graphical elements?",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit5.html#reading",
    "href": "units/unit5.html#reading",
    "title": "5) Tables and Tidyverse-1",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapter 9 of “R Coding Basics”:\n\nhttps://www.gastonsanchez.com/R-coding-basics/4-02-data-frames.html\n\nRead chapters 2 and 4 of “R Tidy Hurricanes”:\n\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/1-02-about-hurricanes.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/2-01-intro-ggplot.html",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit5.html#lab",
    "href": "units/unit5.html#lab",
    "title": "5) Tables and Tidyverse-1",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nYou will get introduced to the ggplot2 system for making graphics when data is in tabular format. You will also begin your shiny journey by adapting the default Old Faithful app so that it produces the histogram using \"ggplot2\" functions.",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit5.html#objectives",
    "href": "units/unit5.html#objectives",
    "title": "5) Tables and Tidyverse-1",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\nAt the end of this week you will be able to:\n\nExplain how can you manipulate a data frame as a 2-dimensional object\nExplain how to use the dollar $ operator with a data frame\nProvide a simple example for creating a data frame\nGet a first contact with \"ggplot2\"\nDescribe the purpose of the aesthetic mapping function aes()\nDescribe the notion of “layers” and how to use them for making a graphic using “ggplot2”",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit5.html#shiny-friday",
    "href": "units/unit5.html#shiny-friday",
    "title": "5) Tables and Tidyverse-1",
    "section": "🔆 Shiny Friday",
    "text": "🔆 Shiny Friday\nThe shiny app for this week involves data from NBA players, visualizing some univariate plots with ggplot2.\nWe have two versions:\n\nnba-histograms1-basic: histograms of NBA players’ data, includes a select input to choose the variable to visualize, and a slider input to determine the number of bins in the histogram.  https://github.com/data133/shiny/tree/main/nba-histograms1-basic\nnba-histograms2-facets: same as app1 but this one also includes another select input to decide whether the histograms should be split into facets by either team or player’s position.  https://github.com/data133/shiny/tree/main/nba-histograms2-facets",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit5.html#assignments",
    "href": "units/unit5.html#assignments",
    "title": "5) Tables and Tidyverse-1",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nHW3 due this 9/27\nHW4 released on 9/28, due 10/04",
    "crumbs": [
      "Units",
      "5) Tables and Tidyverse-1"
    ]
  },
  {
    "objectID": "units/unit1.html",
    "href": "units/unit1.html",
    "title": "1) Intro",
    "section": "",
    "text": "Welcome to Stat 133. Our first meeting is on Wednesday Aug-28 where we begin with the usual review of the course policies, logistics, overall expectations, topics in a nutshell, etc. As for Friday Aug-30, we start with an introduction to R vectors which are the most basic kind of data structure in R.",
    "crumbs": [
      "Units",
      "1) Intro"
    ]
  },
  {
    "objectID": "units/unit1.html#lecture",
    "href": "units/unit1.html#lecture",
    "title": "1) Intro",
    "section": "",
    "text": "Welcome to Stat 133. Our first meeting is on Wednesday Aug-28 where we begin with the usual review of the course policies, logistics, overall expectations, topics in a nutshell, etc. As for Friday Aug-30, we start with an introduction to R vectors which are the most basic kind of data structure in R.",
    "crumbs": [
      "Units",
      "1) Intro"
    ]
  },
  {
    "objectID": "units/unit1.html#lab",
    "href": "units/unit1.html#lab",
    "title": "1) Intro",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nGetting started with R and RStudio: first, we want to make sure everybody has installed both programs; and then we will provide an introductory review of RStudio’s workspace, as well as a brief intro to Quarto notebooks.\nBTW: there’s nothing to submit this week.",
    "crumbs": [
      "Units",
      "1) Intro"
    ]
  },
  {
    "objectID": "units/unit1.html#activities",
    "href": "units/unit1.html#activities",
    "title": "1) Intro",
    "section": "🔔 Activities",
    "text": "🔔 Activities\nIf you haven’t yet, please spend some time outside class to review the following documentation:\n\nsyllabus\ncommunication via email\nsome frequently asked questions\nfive things you need to know to pass this class\nintroduction survey (google form)",
    "crumbs": [
      "Units",
      "1) Intro"
    ]
  },
  {
    "objectID": "units/unit1.html#install-r-rstudio",
    "href": "units/unit1.html#install-r-rstudio",
    "title": "1) Intro",
    "section": "📢 Install R & RStudio",
    "text": "📢 Install R & RStudio\nFor those of you that don’t have either R or RStudio, download and install these programs (both are free, and they are available for Mac, Windows, and Linux computers)\n\nInstall R\nInstall RStudio (Desktop free version)",
    "crumbs": [
      "Units",
      "1) Intro"
    ]
  },
  {
    "objectID": "units/unit2.html",
    "href": "units/unit2.html",
    "title": "2) R Vectors",
    "section": "",
    "text": "This week we describe data types and their implementation as vectors in R (the most fundamental data object in R). As you’ll see, R is—to a large extent—a vector-based language. Pretty much all other data objects are derived from vectors. We’ll focus on important concepts like:\n\nmain data types (“atomic types” in R): logical, integer, real (or double), and character.\ncreation of vectors: various ways and functions to create vectors.\nimplicit coercion rules: what R does when you combine values of different data types.\nvectorization: when R applies calculations or operations to all the elements of a vector (element-wise).\nrecycling: what R does when you perform a calculation with vectors of different length.\nsubsetting (aka subscripting, subindexing, indexing): the use of single/double brackets to subset (i.e. subscript, index) elements of a vector.",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit2.html#lecture",
    "href": "units/unit2.html#lecture",
    "title": "2) R Vectors",
    "section": "",
    "text": "This week we describe data types and their implementation as vectors in R (the most fundamental data object in R). As you’ll see, R is—to a large extent—a vector-based language. Pretty much all other data objects are derived from vectors. We’ll focus on important concepts like:\n\nmain data types (“atomic types” in R): logical, integer, real (or double), and character.\ncreation of vectors: various ways and functions to create vectors.\nimplicit coercion rules: what R does when you combine values of different data types.\nvectorization: when R applies calculations or operations to all the elements of a vector (element-wise).\nrecycling: what R does when you perform a calculation with vectors of different length.\nsubsetting (aka subscripting, subindexing, indexing): the use of single/double brackets to subset (i.e. subscript, index) elements of a vector.",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit2.html#reading",
    "href": "units/unit2.html#reading",
    "title": "2) R Vectors",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead the following chapters that form Part I of “R Coding Basics”:\n\nhttps://www.gastonsanchez.com/R-coding-basics/1-01-vectors-intro.html\nhttps://www.gastonsanchez.com/R-coding-basics/1-02-vectors-properties.html\nhttps://www.gastonsanchez.com/R-coding-basics/1-03-vectors-creation.html\nhttps://www.gastonsanchez.com/R-coding-basics/1-04-vectors-concepts.html",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit2.html#lab",
    "href": "units/unit2.html#lab",
    "title": "2) R Vectors",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nYou’ll practice creating and manipulating vectors in R, and learning about the concepts described above.",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit2.html#objectives",
    "href": "units/unit2.html#objectives",
    "title": "2) R Vectors",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\nAt the end of this week you will be able to:\n\nDescribe the four common data types in R, and give examples for them\nExplain why R vectors are said to be atomic objects\nDescribe and give an example of the implicit coercion rules\nDescribe and give an example of vectorized code\nDescribe and give an example of the recycling rule\nDescribe and give an example of subsetting (indexing) vectors",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit2.html#shiny-friday",
    "href": "units/unit2.html#shiny-friday",
    "title": "2) R Vectors",
    "section": "🔆 Shiny Friday",
    "text": "🔆 Shiny Friday\nShiny is an open source R package (developed by Posit) that lets you build web applications using R (and RStudio). BTW: If you’ve never seen a shiny app, you can find dozens of examples in a gallery curated by Posit: https://shiny.posit.co/r/gallery/\nDuring the first half of the semester (starting on Sep-6), every Friday lecture I will use a shiny example, describing various aspects about its structure, and reviewing some of its key details. Every week we’ll go over a different shiny app, increasing the level of complexity, but also making it more interactive and richer.\nOur first shiny app involves the app that comes by default in RStudio called Old Faithful. This app is based on the famous geyser Old Faithful located in Yellowstone National Park. In particular, the app uses R’s built-in data set \"faithful\" which contains two variables:\n\neruptions: is the time (in min) of an eruption\nwaiting: is the waiting time (in min) to next eruption\n\nThe app is a very basic app that displays a histogram of the waiting times.\nhttps://github.com/data133/shiny/tree/main/old-faithful1-default",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit2.html#activities",
    "href": "units/unit2.html#activities",
    "title": "2) R Vectors",
    "section": "🔔 Activities",
    "text": "🔔 Activities\nHW1 instructions will be released at the end of this week (due 9/07).",
    "crumbs": [
      "Units",
      "2) R Vectors"
    ]
  },
  {
    "objectID": "units/unit8.html",
    "href": "units/unit8.html",
    "title": "8) Regular Expressions",
    "section": "",
    "text": "Why should you learn about character string manipulation and working with text data? Well, because a considerable amount of information and data is precisely in the form of text. And sooner or later (I would say sooner than later) you will have to deal with some kind of string manipulation for your data analysis. So it’s better to be prepared for such tasks and know how to perform them inside the R environment.\nTo unleash the power of string manipulation, we need to take things to the next level and learn about Regular Expressions or regex for short. Namely, regex allows us to describe a certain amount of text called “patterns”. The name “Regular Expression” does not say much. However, regular expressions are all about text.\nRegular expression patterns consist of a combination of alphanumeric characters as well as special characters. A regex pattern can be as simple as a single character, or it can be formed by several characters with a more complex structure. In all cases we construct regular expressions much in the same form in which we construct arithmetic expressions, by using various operators to combine smaller expressions.",
    "crumbs": [
      "Units",
      "8) Regular Expressions"
    ]
  },
  {
    "objectID": "units/unit8.html#lecture",
    "href": "units/unit8.html#lecture",
    "title": "8) Regular Expressions",
    "section": "",
    "text": "Why should you learn about character string manipulation and working with text data? Well, because a considerable amount of information and data is precisely in the form of text. And sooner or later (I would say sooner than later) you will have to deal with some kind of string manipulation for your data analysis. So it’s better to be prepared for such tasks and know how to perform them inside the R environment.\nTo unleash the power of string manipulation, we need to take things to the next level and learn about Regular Expressions or regex for short. Namely, regex allows us to describe a certain amount of text called “patterns”. The name “Regular Expression” does not say much. However, regular expressions are all about text.\nRegular expression patterns consist of a combination of alphanumeric characters as well as special characters. A regex pattern can be as simple as a single character, or it can be formed by several characters with a more complex structure. In all cases we construct regular expressions much in the same form in which we construct arithmetic expressions, by using various operators to combine smaller expressions.",
    "crumbs": [
      "Units",
      "8) Regular Expressions"
    ]
  },
  {
    "objectID": "units/unit8.html#reading",
    "href": "units/unit8.html#reading",
    "title": "8) Regular Expressions",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 13 and 14 of “R for Strings”:\n\nhttps://www.gastonsanchez.com/R-for-strings/08-regex-intro.html\nhttps://www.gastonsanchez.com/R-for-strings/09-regex-charsets.html\nhttps://www.gastonsanchez.com/R-for-strings/10-regex-anchors.html\nhttps://www.gastonsanchez.com/R-for-strings/11-regex-quantifiers.html",
    "crumbs": [
      "Units",
      "8) Regular Expressions"
    ]
  },
  {
    "objectID": "units/unit8.html#lab",
    "href": "units/unit8.html#lab",
    "title": "8) Regular Expressions",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nThis week you’ll learn how to perform regex operations.",
    "crumbs": [
      "Units",
      "8) Regular Expressions"
    ]
  },
  {
    "objectID": "units/unit8.html#objectives",
    "href": "units/unit8.html#objectives",
    "title": "8) Regular Expressions",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nBeing able to describe what a regular expression is\nExplain what a literal character is\nExplain what a metacharacter is\nGive an example of the wildcard metacharacter “.” (dot)\nGive an example of how to escape a metacharacter\nExplain what a character set is\nExplain what a character range is\nExplain what a POSIX character class is",
    "crumbs": [
      "Units",
      "8) Regular Expressions"
    ]
  },
  {
    "objectID": "units/unit8.html#assignments",
    "href": "units/unit8.html#assignments",
    "title": "8) Regular Expressions",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nHW6 due this 10/18\nShiny App1 released on 10/19, due 11/01",
    "crumbs": [
      "Units",
      "8) Regular Expressions"
    ]
  },
  {
    "objectID": "units/unit13.html",
    "href": "units/unit13.html",
    "title": "13) Web Tech 1",
    "section": "",
    "text": "In this last part of the course we look at so-called web technologies for computing with data. To be more specific, we’ll focus on tools that have to do with getting data from the Web.\nThe Web is full of information and sources of data. As it turns out, we can use a wide array of approaches to get data from the Web. For instance, we can simply scrape data from human-readable webpages. Likewise, we can also utilize application programming interfaces (APIs) to request some data sets. Interestingly, the data may come in some XML dialect, the most common one being HTML. But it can also come in a JSON document or some other self-describing format. Consequently, you need to be prepared to deal with data from the Web.",
    "crumbs": [
      "Units",
      "13) Web Tech 1"
    ]
  },
  {
    "objectID": "units/unit13.html#lecture",
    "href": "units/unit13.html#lecture",
    "title": "13) Web Tech 1",
    "section": "",
    "text": "In this last part of the course we look at so-called web technologies for computing with data. To be more specific, we’ll focus on tools that have to do with getting data from the Web.\nThe Web is full of information and sources of data. As it turns out, we can use a wide array of approaches to get data from the Web. For instance, we can simply scrape data from human-readable webpages. Likewise, we can also utilize application programming interfaces (APIs) to request some data sets. Interestingly, the data may come in some XML dialect, the most common one being HTML. But it can also come in a JSON document or some other self-describing format. Consequently, you need to be prepared to deal with data from the Web.",
    "crumbs": [
      "Units",
      "13) Web Tech 1"
    ]
  },
  {
    "objectID": "units/unit13.html#reading",
    "href": "units/unit13.html#reading",
    "title": "13) Web Tech 1",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead the following chapters from “R Web Technologies”:\n\nhttps://www.gastonsanchez.com/R-web-technologies/json.html\nhttps://www.gastonsanchez.com/R-web-technologies/xml.html\nhttps://www.gastonsanchez.com/R-web-technologies/parsing-xml.html\nhttps://www.gastonsanchez.com/R-web-technologies/xpath.html",
    "crumbs": [
      "Units",
      "13) Web Tech 1"
    ]
  },
  {
    "objectID": "units/unit13.html#lab",
    "href": "units/unit13.html#lab",
    "title": "13) Web Tech 1",
    "section": "🔬 Lab",
    "text": "🔬 Lab\n\nPractice with a basic API to get some data.",
    "crumbs": [
      "Units",
      "13) Web Tech 1"
    ]
  },
  {
    "objectID": "units/unit13.html#objectives",
    "href": "units/unit13.html#objectives",
    "title": "13) Web Tech 1",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nDescribe what an API is.\nUnderstand JSON sytnax\n\ndata types\njson arrays\njson objects",
    "crumbs": [
      "Units",
      "13) Web Tech 1"
    ]
  },
  {
    "objectID": "units/unit13.html#assignments",
    "href": "units/unit13.html#assignments",
    "title": "13) Web Tech 1",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nStart working on your App3, due on 12/06",
    "crumbs": [
      "Units",
      "13) Web Tech 1"
    ]
  },
  {
    "objectID": "units/unit10.html",
    "href": "units/unit10.html",
    "title": "10) Text Mining 2",
    "section": "",
    "text": "One popular topic in text mining involves Sentiment Analysis (aka Sentiment Scoring). Simply put, sentiment analysis is the process of extracting an author’s emotional intent from text. At first glance, sentiment analysis may appear easy. But as we will see, this type of analysis is tricky to do well. There are various emotional frameworks that can be used for sentiment analysis. We will cover a simple approach that implies stating whether a document is positive, negative, or neutral. This is referred to as the polarity of a document.",
    "crumbs": [
      "Units",
      "10) Text Mining 2"
    ]
  },
  {
    "objectID": "units/unit10.html#lecture",
    "href": "units/unit10.html#lecture",
    "title": "10) Text Mining 2",
    "section": "",
    "text": "One popular topic in text mining involves Sentiment Analysis (aka Sentiment Scoring). Simply put, sentiment analysis is the process of extracting an author’s emotional intent from text. At first glance, sentiment analysis may appear easy. But as we will see, this type of analysis is tricky to do well. There are various emotional frameworks that can be used for sentiment analysis. We will cover a simple approach that implies stating whether a document is positive, negative, or neutral. This is referred to as the polarity of a document.",
    "crumbs": [
      "Units",
      "10) Text Mining 2"
    ]
  },
  {
    "objectID": "units/unit10.html#reading",
    "href": "units/unit10.html#reading",
    "title": "10) Text Mining 2",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 1, 2 and 4 of “Text Mining with R” (by Julia Silge and David Robinson):\n\nhttps://www.tidytextmining.com/sentiment",
    "crumbs": [
      "Units",
      "10) Text Mining 2"
    ]
  },
  {
    "objectID": "units/unit10.html#lab",
    "href": "units/unit10.html#lab",
    "title": "10) Text Mining 2",
    "section": "🔬 Lab",
    "text": "🔬 Lab\n\nGetting started with the \"tidytext\" package.",
    "crumbs": [
      "Units",
      "10) Text Mining 2"
    ]
  },
  {
    "objectID": "units/unit10.html#objectives",
    "href": "units/unit10.html#objectives",
    "title": "10) Text Mining 2",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nDefine sentiment analysis.\nDescribe a basic polarity scoring algorithm.\nCompute basic sentiments (positive, negative, neutral) of a text.",
    "crumbs": [
      "Units",
      "10) Text Mining 2"
    ]
  },
  {
    "objectID": "units/unit10.html#assignments",
    "href": "units/unit10.html#assignments",
    "title": "10) Text Mining 2",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nShiny App1, due 11/01\nShiny App2 released on 11/02, due 11/14",
    "crumbs": [
      "Units",
      "10) Text Mining 2"
    ]
  },
  {
    "objectID": "units/macros.html",
    "href": "units/macros.html",
    "title": "",
    "section": "",
    "text": "\\[\n\\newcommand{\\trans}{^\\mathsf{T}}\n\\newcommand{\\eps}{\\epsilon}\n\\]"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#required-packages",
    "href": "docs/choropleth/us-elections-slides1.html#required-packages",
    "title": "US Presidential Elections 2020",
    "section": "Required Packages",
    "text": "Required Packages\nThe content in these slides depend on the following packages:\n\nlibrary(tidyverse)      # data wrangling and graphics\n\nlibrary(sf)             # for working with geospatial vector-data\n\nlibrary(rnaturalearth)  # maps data (e.g. US States)\n\nlibrary(maps)           # maps data (e.g. US Counties)\n\nlibrary(plotly)         # interactive plots"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#about",
    "href": "docs/choropleth/us-elections-slides1.html#about",
    "title": "US Presidential Elections 2020",
    "section": "About",
    "text": "About\nVisualizing US Presidential Elections (2020)"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#data-from-mit-election-lab",
    "href": "docs/choropleth/us-elections-slides1.html#data-from-mit-election-lab",
    "title": "US Presidential Elections 2020",
    "section": "Data from MIT Election Lab",
    "text": "Data from MIT Election Lab\n\nhttp://electionlab.mit.edu/"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#county-presidential-election-2000-2020",
    "href": "docs/choropleth/us-elections-slides1.html#county-presidential-election-2000-2020",
    "title": "US Presidential Elections 2020",
    "section": "County Presidential Election (2000-2020)",
    "text": "County Presidential Election (2000-2020)\n\nhttps://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#citation-data-source",
    "href": "docs/choropleth/us-elections-slides1.html#citation-data-source",
    "title": "US Presidential Elections 2020",
    "section": "Citation: Data Source",
    "text": "Citation: Data Source\nData: County Presidential Election Returns 2000-2020\nSource: MIT Election Data + Science Lab\nhttps://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ\nMIT Election Data and Science Lab, 2018, “County Presidential Election Returns 2000-2020”, https://doi.org/10.7910/DVN/VOQCHQ, Harvard Dataverse, V11, UNF:6:HaZ8GWG8D2abLleXN3uEig== [fileUNF]\nLicense: Public Domain CC0 1.0"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#data-available-in-csv-format",
    "href": "docs/choropleth/us-elections-slides1.html#data-available-in-csv-format",
    "title": "US Presidential Elections 2020",
    "section": "Data Available in CSV format",
    "text": "Data Available in CSV format"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#us-presidential-election-2000-2020-data",
    "href": "docs/choropleth/us-elections-slides1.html#us-presidential-election-2000-2020-data",
    "title": "US Presidential Elections 2020",
    "section": "US Presidential Election 2000-2020 Data",
    "text": "US Presidential Election 2000-2020 Data\nCSV file available in bCourses (see Files/data)\n\ndat = read_csv(\n  file = \"countypres_2000-2020.csv\", \n  col_types = c(\"icccccccdddc\")) |&gt;\n  mutate(\n    state = tolower(state),\n    county_name = tolower(county_name)\n  )"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#us-presidential-election-2000-2020-data-1",
    "href": "docs/choropleth/us-elections-slides1.html#us-presidential-election-2000-2020-data-1",
    "title": "US Presidential Elections 2020",
    "section": "US Presidential Election 2000-2020 Data",
    "text": "US Presidential Election 2000-2020 Data\n\n# first 6 columns\ndat |&gt; select(1:6) |&gt; slice_head(n = 8)\n\n# A tibble: 8 × 6\n   year state   state_po county_name county_fips office      \n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;       \n1  2000 alabama AL       autauga     01001       US PRESIDENT\n2  2000 alabama AL       autauga     01001       US PRESIDENT\n3  2000 alabama AL       autauga     01001       US PRESIDENT\n4  2000 alabama AL       autauga     01001       US PRESIDENT\n5  2000 alabama AL       baldwin     01003       US PRESIDENT\n6  2000 alabama AL       baldwin     01003       US PRESIDENT\n7  2000 alabama AL       baldwin     01003       US PRESIDENT\n8  2000 alabama AL       baldwin     01003       US PRESIDENT"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#us-presidential-election-2000-2020-data-contd",
    "href": "docs/choropleth/us-elections-slides1.html#us-presidential-election-2000-2020-data-contd",
    "title": "US Presidential Elections 2020",
    "section": "US Presidential Election 2000-2020 Data (cont’d)",
    "text": "US Presidential Election 2000-2020 Data (cont’d)\n\n# last 6 columns\ndat |&gt; select(7:12) |&gt; slice_head(n = 10)\n\n# A tibble: 10 × 6\n   candidate      party      candidatevotes totalvotes  version mode \n   &lt;chr&gt;          &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;\n 1 AL GORE        DEMOCRAT             4942      17208 20220315 TOTAL\n 2 GEORGE W. BUSH REPUBLICAN          11993      17208 20220315 TOTAL\n 3 RALPH NADER    GREEN                 160      17208 20220315 TOTAL\n 4 OTHER          OTHER                 113      17208 20220315 TOTAL\n 5 AL GORE        DEMOCRAT            13997      56480 20220315 TOTAL\n 6 GEORGE W. BUSH REPUBLICAN          40872      56480 20220315 TOTAL\n 7 RALPH NADER    GREEN                1033      56480 20220315 TOTAL\n 8 OTHER          OTHER                 578      56480 20220315 TOTAL\n 9 AL GORE        DEMOCRAT             5188      10395 20220315 TOTAL\n10 GEORGE W. BUSH REPUBLICAN           5096      10395 20220315 TOTAL"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#presidential-election",
    "href": "docs/choropleth/us-elections-slides1.html#presidential-election",
    "title": "US Presidential Elections 2020",
    "section": "2020 Presidential Election",
    "text": "2020 Presidential Election\nLet’s focus on the 2020 Presidential Election\n\ndat2020 = filter(dat, year == 2020)\n\ndat2020 |&gt; distinct(candidate)\n\n# A tibble: 4 × 1\n  candidate        \n  &lt;chr&gt;            \n1 JOSEPH R BIDEN JR\n2 OTHER            \n3 DONALD J TRUMP   \n4 JO JORGENSEN"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#presidential-election-california-results",
    "href": "docs/choropleth/us-elections-slides1.html#presidential-election-california-results",
    "title": "US Presidential Elections 2020",
    "section": "2020 Presidential Election, California Results",
    "text": "2020 Presidential Election, California Results\n\ndat2020 |&gt; \n  filter(state == \"california\") |&gt;\n  select(county_name, candidate:totalvotes) |&gt;\n  slice_head(n = 5)\n\n# A tibble: 5 × 5\n  county_name candidate         party       candidatevotes totalvotes\n  &lt;chr&gt;       &lt;chr&gt;             &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;\n1 alameda     JOSEPH R BIDEN JR DEMOCRAT            617659     770070\n2 alameda     OTHER             GREEN                 4664     770070\n3 alameda     JO JORGENSEN      LIBERTARIAN           6295     770070\n4 alameda     OTHER             OTHER                 5143     770070\n5 alameda     DONALD J TRUMP    REPUBLICAN          136309     770070"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#expressing-votes-relative-to-total-in-county",
    "href": "docs/choropleth/us-elections-slides1.html#expressing-votes-relative-to-total-in-county",
    "title": "US Presidential Elections 2020",
    "section": "Expressing votes relative to total in county",
    "text": "Expressing votes relative to total in county\nLet’s add a column propvotes to get the proportion of votes that each candidate obtained in every county:\npropvotes = candidatevotes / totalvotes\n\nvotes_california = dat |&gt;\n  filter(state == \"california\" & year == 2020) |&gt;\n  mutate(propvotes = round(candidatevotes / totalvotes, 2)) |&gt;\n  select(county_name, candidate, propvotes, candidatevotes)"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#analysis-of-california",
    "href": "docs/choropleth/us-elections-slides1.html#analysis-of-california",
    "title": "US Presidential Elections 2020",
    "section": "Analysis of California",
    "text": "Analysis of California\nNumber of votes that each candidate received in each of the counties in California\n\nvotes_california |&gt; \n  group_by(county_name, candidate) |&gt;\n  summarise(sum_votes = sum(candidatevotes))\n\n# A tibble: 232 × 3\n# Groups:   county_name [58]\n   county_name candidate         sum_votes\n   &lt;chr&gt;       &lt;chr&gt;                 &lt;dbl&gt;\n 1 alameda     DONALD J TRUMP       136309\n 2 alameda     JO JORGENSEN           6295\n 3 alameda     JOSEPH R BIDEN JR    617659\n 4 alameda     OTHER                  9807\n 5 alpine      DONALD J TRUMP          244\n 6 alpine      JO JORGENSEN             15\n 7 alpine      JOSEPH R BIDEN JR       476\n 8 alpine      OTHER                     6\n 9 amador      DONALD J TRUMP        13585\n10 amador      JO JORGENSEN            349\n# ℹ 222 more rows"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-us-contiguous-states",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-us-contiguous-states",
    "title": "US Presidential Elections 2020",
    "section": "Map of US (contiguous states)",
    "text": "Map of US (contiguous states)\nWe’ve seen how to plot a map of US\n\n# map data (as \"sf\" object)\nus_states_sf = ne_states(\n  country = \"United States of America\", \n  returnclass = \"sf\")\n\nggplot(data = us_states_sf) +\n  geom_sf() +\n  coord_sf(xlim = c(-125, -60), ylim = c(20, 55)) +\n  theme_minimal()"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-us-contiguous-states-1",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-us-contiguous-states-1",
    "title": "US Presidential Elections 2020",
    "section": "Map of US (contiguous states)",
    "text": "Map of US (contiguous states)"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-us-counties",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-us-counties",
    "title": "US Presidential Elections 2020",
    "section": "Map of US Counties",
    "text": "Map of US Counties\n\"rnaturalearth\" does not come with a built-in map data of US Counties. But we can use the \"county\" map-data from the package \"maps\".\nTo be consistent with the way we handle vector data, we convert the \"county\" map object into an \"sf\" object with st_as_sf().\n\nus_counties_sf = st_as_sf(maps::map(\"county\", plot = FALSE, fill = TRUE))\n\nggplot(data = us_counties_sf) +\n  geom_sf() +\n  coord_sf(xlim = c(-125, -60), ylim = c(20, 55)) +\n  theme_minimal()"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-us-counties-1",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-us-counties-1",
    "title": "US Presidential Elections 2020",
    "section": "Map of US Counties",
    "text": "Map of US Counties"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-data-of-california-counties",
    "href": "docs/choropleth/us-elections-slides1.html#map-data-of-california-counties",
    "title": "US Presidential Elections 2020",
    "section": "Map Data of California Counties",
    "text": "Map Data of California Counties\n\nWe have map-data of US states: us_states_sf\nWe have map-data of US counties: us_counties_sf\nIt would be nice to have map-data of California Counties.\n\nHow do get map-data of California Counties? This requires a bit of string matching via str_detect():\n\n# matching \"california\" in ID column\ncal_counties_sf = us_counties_sf |&gt;\n  filter(str_detect(ID, \"^california\"))"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-california-counties-1",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-california-counties-1",
    "title": "US Presidential Elections 2020",
    "section": "Map of California Counties",
    "text": "Map of California Counties\nWith filtered counties of California cal_counties_sf, we can make a map:\n\nggplot(data = cal_counties_sf) +\n  geom_sf() +\n  theme_minimal()"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-california-counties-2",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-california-counties-2",
    "title": "US Presidential Elections 2020",
    "section": "Map of California Counties",
    "text": "Map of California Counties"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#whats-in-cal_counties_sf",
    "href": "docs/choropleth/us-elections-slides1.html#whats-in-cal_counties_sf",
    "title": "US Presidential Elections 2020",
    "section": "What’s in cal_counties_sf?",
    "text": "What’s in cal_counties_sf?\n\ncal_counties_sf |&gt; slice_head(n = 10)\n\nSimple feature collection with 10 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -124.2344 ymin: 35.90154 xmax: -118.3502 ymax: 42.00927\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                        ID                           geom\n1       california,alameda MULTIPOLYGON (((-121.4785 3...\n2        california,alpine MULTIPOLYGON (((-120.0748 3...\n3        california,amador MULTIPOLYGON (((-120.0748 3...\n4         california,butte MULTIPOLYGON (((-121.6217 3...\n5     california,calaveras MULTIPOLYGON (((-120.069 38...\n6        california,colusa MULTIPOLYGON (((-121.8223 3...\n7  california,contra costa MULTIPOLYGON (((-121.5702 3...\n8     california,del norte MULTIPOLYGON (((-123.6844 4...\n9     california,el dorado MULTIPOLYGON (((-121.1519 3...\n10       california,fresno MULTIPOLYGON (((-120.6821 3..."
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#adding-column-of-county-name",
    "href": "docs/choropleth/us-elections-slides1.html#adding-column-of-county-name",
    "title": "US Presidential Elections 2020",
    "section": "Adding Column of County Name",
    "text": "Adding Column of County Name\nFor sake of convenience, we need to add a column county to the map-data cal_counties_sf (so that we have the name of the county)\n\ncal_counties_sf = cal_counties_sf |&gt;\n  mutate(county = str_remove(ID, \"california,\"))\n\nhead(cal_counties_sf$county)\n\n[1] \"alameda\"   \"alpine\"    \"amador\"    \"butte\"     \"calaveras\" \"colusa\"   \n\n\n\n\n\nView equivalent code\ncal_counties_sf$county = str_remove(\n  cal_counties_sf$ID,\n  \"california,\"\n)"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#what-relevant-data-do-we-have-so-far",
    "href": "docs/choropleth/us-elections-slides1.html#what-relevant-data-do-we-have-so-far",
    "title": "US Presidential Elections 2020",
    "section": "What relevant data do we have so far?",
    "text": "What relevant data do we have so far?\n\n2020 votes-data from California: votes_california\nMap-data of California counties: cal_counties_sf\n\nWe need to join these data sets in order to combine the votes information with the map-data."
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#joining-map-data-with-elections-data",
    "href": "docs/choropleth/us-elections-slides1.html#joining-map-data-with-elections-data",
    "title": "US Presidential Elections 2020",
    "section": "Joining map-data with elections-data",
    "text": "Joining map-data with elections-data\nJoin California map-data with votes-data, via inner_join()\n\n# data cal_counties_sf has column 'county'\n# data votes_california has column 'county_name'\ncal_votes_map = inner_join(\n  cal_counties_sf,\n  votes_california, \n  by = c(\"county\" = \"county_name\"))"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#joining-map-data-with-elections-data-1",
    "href": "docs/choropleth/us-elections-slides1.html#joining-map-data-with-elections-data-1",
    "title": "US Presidential Elections 2020",
    "section": "Joining map-data with elections-data",
    "text": "Joining map-data with elections-data\n\ncal_votes_map |&gt; slice_head(n = 8)\n\nSimple feature collection with 8 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -122.2749 ymin: 37.45998 xmax: -119.5362 ymax: 38.90956\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                  ID  county         candidate propvotes candidatevotes\n1 california,alameda alameda JOSEPH R BIDEN JR      0.80         617659\n2 california,alameda alameda             OTHER      0.01           4664\n3 california,alameda alameda      JO JORGENSEN      0.01           6295\n4 california,alameda alameda             OTHER      0.01           5143\n5 california,alameda alameda    DONALD J TRUMP      0.18         136309\n6  california,alpine  alpine JOSEPH R BIDEN JR      0.64            476\n7  california,alpine  alpine             OTHER      0.01              4\n8  california,alpine  alpine      JO JORGENSEN      0.02             15\n                            geom\n1 MULTIPOLYGON (((-121.4785 3...\n2 MULTIPOLYGON (((-121.4785 3...\n3 MULTIPOLYGON (((-121.4785 3...\n4 MULTIPOLYGON (((-121.4785 3...\n5 MULTIPOLYGON (((-121.4785 3...\n6 MULTIPOLYGON (((-120.0748 3...\n7 MULTIPOLYGON (((-120.0748 3...\n8 MULTIPOLYGON (((-120.0748 3..."
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#mapping-votes-facet-by-candidate",
    "href": "docs/choropleth/us-elections-slides1.html#mapping-votes-facet-by-candidate",
    "title": "US Presidential Elections 2020",
    "section": "Mapping Votes (facet by candidate)",
    "text": "Mapping Votes (facet by candidate)\n\n\nView code\nggplot(cal_votes_map) +\n  geom_sf(aes(fill = propvotes)) +\n  scale_fill_gradient(low = \"#FFF7F5\", high = \"#FF0000\") +\n  facet_wrap(~ candidate) +\n  theme_void()"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#looking-for-an-alternative-color-scheme",
    "href": "docs/choropleth/us-elections-slides1.html#looking-for-an-alternative-color-scheme",
    "title": "US Presidential Elections 2020",
    "section": "Looking for an alternative color scheme",
    "text": "Looking for an alternative color scheme\nWe can use a Viridis Color palette.\nhttps://ggplot2.tidyverse.org/reference/scale_viridis.html\n\nThe function scale_fill_viridis_c() allows us to choose a continuous scale.\nIts argument direction = -1 gives a reversing order (from yellow to dark blue)."
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#mapping-votes-5th-attempt",
    "href": "docs/choropleth/us-elections-slides1.html#mapping-votes-5th-attempt",
    "title": "US Presidential Elections 2020",
    "section": "Mapping Votes (5th attempt)",
    "text": "Mapping Votes (5th attempt)\n\n\nView code\n# Viridis Color\nggplot(cal_votes_map) +\n  geom_sf(aes(fill = propvotes)) +\n  scale_fill_viridis_c(name = \"Prop. of Votes\", direction = -1) +\n  facet_wrap(~ candidate) +\n  theme_void()"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-of-joe-bidens-votes",
    "href": "docs/choropleth/us-elections-slides1.html#map-of-joe-bidens-votes",
    "title": "US Presidential Elections 2020",
    "section": "Map of Joe Biden’s votes",
    "text": "Map of Joe Biden’s votes\n\n\nView code\ncal_votes_map |&gt;\n  filter(candidate == \"JOSEPH R BIDEN JR\") |&gt;\nggplot() +\n  geom_sf(aes(fill = propvotes)) +\n  scale_fill_viridis_c(name = \"Prop. of Votes\", direction = -1) +\n  theme_void() +\n  labs(title = \"Joe Biden's Proportion of Votes\")"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#joe-bidens-votes-top-5-counties",
    "href": "docs/choropleth/us-elections-slides1.html#joe-bidens-votes-top-5-counties",
    "title": "US Presidential Elections 2020",
    "section": "Joe Biden’s votes: top-5 counties",
    "text": "Joe Biden’s votes: top-5 counties\n\nvotes_california |&gt;\n  filter(candidate == \"JOSEPH R BIDEN JR\") |&gt;\n  arrange(desc(propvotes)) |&gt;\n  slice_head(n = 5)\n\n# A tibble: 5 × 4\n  county_name   candidate         propvotes candidatevotes\n  &lt;chr&gt;         &lt;chr&gt;                 &lt;dbl&gt;          &lt;dbl&gt;\n1 san francisco JOSEPH R BIDEN JR      0.85         378156\n2 marin         JOSEPH R BIDEN JR      0.82         128288\n3 alameda       JOSEPH R BIDEN JR      0.8          617659\n4 santa cruz    JOSEPH R BIDEN JR      0.79         114246\n5 san mateo     JOSEPH R BIDEN JR      0.78         291496"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#joe-bidens-votes-bottom-5-counties",
    "href": "docs/choropleth/us-elections-slides1.html#joe-bidens-votes-bottom-5-counties",
    "title": "US Presidential Elections 2020",
    "section": "Joe Biden’s votes: bottom-5 counties",
    "text": "Joe Biden’s votes: bottom-5 counties\n\nvotes_california |&gt;\n  filter(candidate == \"JOSEPH R BIDEN JR\") |&gt;\n  arrange(propvotes) |&gt;\n  slice_head(n = 5)\n\n# A tibble: 5 × 4\n  county_name candidate         propvotes candidatevotes\n  &lt;chr&gt;       &lt;chr&gt;                 &lt;dbl&gt;          &lt;dbl&gt;\n1 lassen      JOSEPH R BIDEN JR      0.23           2799\n2 modoc       JOSEPH R BIDEN JR      0.26           1150\n3 tehama      JOSEPH R BIDEN JR      0.31           8911\n4 shasta      JOSEPH R BIDEN JR      0.32          30000\n5 glenn       JOSEPH R BIDEN JR      0.35           3995"
  },
  {
    "objectID": "docs/choropleth/us-elections-slides1.html#map-with-ggplotly",
    "href": "docs/choropleth/us-elections-slides1.html#map-with-ggplotly",
    "title": "US Presidential Elections 2020",
    "section": "Map with ggplotly()",
    "text": "Map with ggplotly()\n\n\nView code\njoe_biden = cal_votes_map |&gt;\n  filter(candidate == \"JOSEPH R BIDEN JR\")\n\njoe_biden_map = ggplot(data = joe_biden, aes(label = county)) +\n  geom_sf(aes(fill = propvotes)) +\n  scale_fill_viridis_c(name = \"Prop. of Votes\", direction = -1) +\n  theme_void() +\n  labs(title = \"Joe Biden's Proportion of Votes\")\n\nggplotly(joe_biden_map)\n\n\n\n\n\n\n\n\n\nReturn to Home Page"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#about",
    "href": "docs/maps-storms/storms-slides3.html#about",
    "title": "North Atlantic Storms",
    "section": "About",
    "text": "About\nUsing the storms data, I want to show you a variety of examples for displaying maps, for doing more data manipulation, and for obtaining more data visualizations."
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#required-packages",
    "href": "docs/maps-storms/storms-slides3.html#required-packages",
    "title": "North Atlantic Storms",
    "section": "Required Packages",
    "text": "Required Packages\nThe content in these slides depend on the following packages1:\n\nlibrary(tidyverse)      # data wrangling and graphics\n\nlibrary(lubridate)      # for working with dates-times data\n\nlibrary(sf)             # for working with geospatial vector-data\n\nlibrary(rnaturalearth)  # maps data\n\nlibrary(gganimate)      # animations for ggplot\n\nlibrary(plotly)         # web interactive plots\n\nyou may also need \"gifski\" or \"magick\" for \"gganimate\""
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#recap-visualizing-storms-trajectories",
    "href": "docs/maps-storms/storms-slides3.html#recap-visualizing-storms-trajectories",
    "title": "North Atlantic Storms",
    "section": "Recap: Visualizing storms trajectories",
    "text": "Recap: Visualizing storms trajectories\nTo visualize the trajectories of storms, we’ve discussed one simple approach based on:\n\nUse map data from \"rnaturalearth\"\nSpecifically, import map data as objects of class \"sf\"\nMake maps with:\n\n# one option\nggplot(map_data) + geom_sf() + geom_...(storms, aes(long, lat)) + etc\n\n\n# another option\nggplot() + geom_sf(map_data) + geom_...(storms, aes(long, lat)) + etc"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#recap-example",
    "href": "docs/maps-storms/storms-slides3.html#recap-example",
    "title": "North Atlantic Storms",
    "section": "Recap: example",
    "text": "Recap: example\n\n# filtered storms\nstorms75 = filter(storms, year == 1975)\n\n# map data (as \"sf\" object)\nmap_world = ne_countries(returnclass = \"sf\")\n\n# map with storms trajectories\nggplot(data = map_world) +\n  geom_sf(color = \"gray60\") +\n  coord_sf(xlim = c(-110, 0), \n           ylim = c(10, 60)) +\n  geom_point(data = storms75,\n             aes(x = long, y = lat, color = name)) +\n  theme_minimal() + \n  theme(legend.position = \"none\") +\n  labs(title = \"North Atlantic Storms, 1975\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#recap-example-1",
    "href": "docs/maps-storms/storms-slides3.html#recap-example-1",
    "title": "North Atlantic Storms",
    "section": "Recap: example",
    "text": "Recap: example"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year",
    "href": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year",
    "title": "North Atlantic Storms",
    "section": "Exploration: Number of Storms per Year",
    "text": "Exploration: Number of Storms per Year\n\n# not exactly the counts we're looking for\nstorm_counts = storms |&gt;\n  count(year, name)\n\nstorm_counts\n\n# A tibble: 655 × 3\n    year name         n\n   &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;\n 1  1975 Amy         31\n 2  1975 Blanche     20\n 3  1975 Caroline    33\n 4  1975 Doris       29\n 5  1975 Eloise      46\n 6  1975 Faye        19\n 7  1975 Gladys      46\n 8  1975 Hallie      14\n 9  1976 Belle       18\n10  1976 Candice     11\n# ℹ 645 more rows"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year-1",
    "href": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year-1",
    "title": "North Atlantic Storms",
    "section": "Exploration: Number of Storms per Year",
    "text": "Exploration: Number of Storms per Year\n\n# these are the counts we want\nstorm_count_per_year = storms |&gt;\n  count(year, name) |&gt; \n  count(year, name = \"count\")\n\nstorm_count_per_year\n\n# A tibble: 48 × 2\n    year count\n   &lt;dbl&gt; &lt;int&gt;\n 1  1975     8\n 2  1976     7\n 3  1977     6\n 4  1978    11\n 5  1979     8\n 6  1980    11\n 7  1981    11\n 8  1982     5\n 9  1983     4\n10  1984    12\n# ℹ 38 more rows"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year-2",
    "href": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year-2",
    "title": "North Atlantic Storms",
    "section": "Exploration: Number of Storms per Year",
    "text": "Exploration: Number of Storms per Year\n\n\nView Code\nstorm_count_per_year |&gt;\n  ggplot(aes(x = year, y = count)) +\n  geom_col() +\n  theme_minimal() +\n  labs(title = \"Number of Storms per Year (1975 - 2021)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year-3",
    "href": "docs/maps-storms/storms-slides3.html#exploration-number-of-storms-per-year-3",
    "title": "North Atlantic Storms",
    "section": "Exploration: Number of Storms per Year",
    "text": "Exploration: Number of Storms per Year\n\n\nView Code\nstorm_count_per_year |&gt;\n  ggplot(aes(x = year, y = count)) +\n  geom_col(fill = \"gray70\") +\n  geom_smooth(se = FALSE, color = \"red\") +\n  theme_minimal() +\n  labs(title = \"Number of Storms per Year (1975 - 2021)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-maximum-wind-for-each-storm",
    "href": "docs/maps-storms/storms-slides3.html#exploration-maximum-wind-for-each-storm",
    "title": "North Atlantic Storms",
    "section": "Exploration: Maximum Wind for each Storm",
    "text": "Exploration: Maximum Wind for each Storm\n\n# add `wind_max` column\nmax_wind_storms = storms |&gt;\n  group_by(year, name) |&gt;\n  summarise(\n    wind_max = max(wind),\n    .groups = \"drop\")\n\nslice_head(max_wind_storms, n = 10)\n\n# A tibble: 10 × 3\n    year name     wind_max\n   &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt;\n 1  1975 Amy            60\n 2  1975 Blanche        75\n 3  1975 Caroline      100\n 4  1975 Doris          95\n 5  1975 Eloise        110\n 6  1975 Faye           90\n 7  1975 Gladys        120\n 8  1975 Hallie         45\n 9  1976 Belle         105\n10  1976 Candice        80"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-adding-wind-scale-with-case_when",
    "href": "docs/maps-storms/storms-slides3.html#exploration-adding-wind-scale-with-case_when",
    "title": "North Atlantic Storms",
    "section": "Exploration: adding wind-scale with case_when()",
    "text": "Exploration: adding wind-scale with case_when()\n\n# adding a wind-scale column\nstorms_status = max_wind_storms |&gt;\n  mutate(wind_scale = case_when(\n      wind_max &lt;= 33 ~ -1L,\n      wind_max &lt;= 63 ~ 0L,\n      wind_max &lt;= 82 ~ 1L,\n      wind_max &lt;= 95 ~ 2L,\n      wind_max &lt;= 112 ~ 3L,\n      wind_max &lt;= 136 ~ 4L,\n      wind_max &gt;= 137 ~ 5L\n    )\n  )\n\nslice_head(storms_status, n = 10)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-adding-wind-scale",
    "href": "docs/maps-storms/storms-slides3.html#exploration-adding-wind-scale",
    "title": "North Atlantic Storms",
    "section": "Exploration: adding wind-scale",
    "text": "Exploration: adding wind-scale\n\n\n# A tibble: 10 × 4\n    year name     wind_max wind_scale\n   &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt;      &lt;int&gt;\n 1  1975 Amy            60          0\n 2  1975 Blanche        75          1\n 3  1975 Caroline      100          3\n 4  1975 Doris          95          2\n 5  1975 Eloise        110          3\n 6  1975 Faye           90          2\n 7  1975 Gladys        120          4\n 8  1975 Hallie         45          0\n 9  1976 Belle         105          3\n10  1976 Candice        80          1"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-type-of-storms-over-time",
    "href": "docs/maps-storms/storms-slides3.html#exploration-type-of-storms-over-time",
    "title": "North Atlantic Storms",
    "section": "Exploration: type of storms over time",
    "text": "Exploration: type of storms over time\n\n\nView Code\nstorms_status |&gt;\n  count(year, wind_scale) |&gt;\nggplot() +\n  geom_col(aes(x = year, y = n, fill = factor(wind_scale))) +\n  labs(title = \"Number of Storms per Year, and Status\",\n       y = \"Count\") +\n  theme_minimal()"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#exploration-type-of-storms-over-time-1",
    "href": "docs/maps-storms/storms-slides3.html#exploration-type-of-storms-over-time-1",
    "title": "North Atlantic Storms",
    "section": "Exploration: type of storms over time",
    "text": "Exploration: type of storms over time\n\n\nView Code\nstorms_status = storms_status |&gt;\n  mutate(wind_scale = ordered(wind_scale))\n\nstorms_status |&gt;\n  count(year, wind_scale) |&gt;\nggplot() +\n  geom_col(aes(x = year, y = n, fill = wind_scale)) +\n  facet_wrap(~ wind_scale, scales = \"free_y\") +\n  labs(title = \"Number of Storms Over Time, and Status\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"none\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#animation-example-2020-hurricane-season",
    "href": "docs/maps-storms/storms-slides3.html#animation-example-2020-hurricane-season",
    "title": "North Atlantic Storms",
    "section": "Animation example: 2020 Hurricane Season",
    "text": "Animation example: 2020 Hurricane Season"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#animations-with-gganimate",
    "href": "docs/maps-storms/storms-slides3.html#animations-with-gganimate",
    "title": "North Atlantic Storms",
    "section": "Animations with gganimate",
    "text": "Animations with gganimate\n\n\"gganimate\" extends the grammar of graphics as implemented by \"ggplot2\" to include the description of animation.\nIt provides a range of new grammar classes that can be added to the plot object in order to customize how it should change with time.\nI will show you just one example."
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#ggplot-gganimate",
    "href": "docs/maps-storms/storms-slides3.html#ggplot-gganimate",
    "title": "North Atlantic Storms",
    "section": "ggplot + gganimate",
    "text": "ggplot + gganimate\n\nAs usual, start your graphic with ggplot()\nAdd layers with graphical primitives, i.e. geoms\nOptionally, add formatting specification(s)\nAdd animation specification(s)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#start-with-ggplot",
    "href": "docs/maps-storms/storms-slides3.html#start-with-ggplot",
    "title": "North Atlantic Storms",
    "section": "Start with ggplot",
    "text": "Start with ggplot\n\nstorms2020 = filter(storms, year == 2020)\n\nmap_world = ne_countries(returnclass = \"sf\")\n\nmap_storms2020 = ggplot(data = map_world) +\n  geom_sf() +\n  geom_point(data = storms2020, \n             aes(x = long, y = lat, color = name, size = wind), \n             alpha = 0.9) +\n  coord_sf(xlim = c(-110, 0), ylim = c(5, 60)) +\n  theme_minimal() + \n  theme(legend.position = \"none\")\n\nmap_storms2020"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#start-with-ggplot-1",
    "href": "docs/maps-storms/storms-slides3.html#start-with-ggplot-1",
    "title": "North Atlantic Storms",
    "section": "Start with ggplot",
    "text": "Start with ggplot"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#for-convenience-we-add-a-datetime-column",
    "href": "docs/maps-storms/storms-slides3.html#for-convenience-we-add-a-datetime-column",
    "title": "North Atlantic Storms",
    "section": "For convenience, we add a datetime column",
    "text": "For convenience, we add a datetime column\n\nWe create a date column by joining year, month, and day\nWe also create a time column by joining hour with \"00:00\"\nAnd then we create a datetime column using the ymd_hms() function from package \"lubridate\"\n\n\n\nstorms2020 = storms |&gt;\n  filter(year == 2020) |&gt;\n  mutate(date = paste0(year, \"-\", month, \"-\", day),\n         time = paste0(hour, \":00:00\"),\n         datetime = ymd_hms(paste(date, time)))"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#adding-transitions",
    "href": "docs/maps-storms/storms-slides3.html#adding-transitions",
    "title": "North Atlantic Storms",
    "section": "Adding transitions",
    "text": "Adding transitions\n\nanim2020 = ggplot(data = map_world) +\n  geom_sf() +\n  geom_point(data = storms2020, \n             aes(x = long, y = lat, color = name, size = wind), \n             alpha = 0.9) +\n  coord_sf(xlim = c(-110, 0), ylim = c(5, 60)) +\n  theme_minimal() + \n  theme(legend.position = \"none\") +\n  labs(title = 'Date: {frame_time}', x = '', y = '') + \n  transition_time(datetime) +\n  shadow_wake(wake_length = 0.7) +\n  ease_aes('linear')"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#optional-saving-animation-in-gif-file",
    "href": "docs/maps-storms/storms-slides3.html#optional-saving-animation-in-gif-file",
    "title": "North Atlantic Storms",
    "section": "Optional: saving animation in gif file",
    "text": "Optional: saving animation in gif file\n\nanim_save(\n  filename = \"hurricane-season-2020.gif\", \n  animation = anim2020,\n  nframes = 200, \n  fps = 10)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#plotly-interactive-graphics-with-ggplotly",
    "href": "docs/maps-storms/storms-slides3.html#plotly-interactive-graphics-with-ggplotly",
    "title": "North Atlantic Storms",
    "section": "Plotly Interactive graphics with ggplotly()",
    "text": "Plotly Interactive graphics with ggplotly()\n\nAs you know, you can take a ggplot object and feed it to ggplotly()\nggplotly() converts the graphic to a plotly object\nInterestingly, you can also make animated views with \"plotly\""
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#animation-with-plotly",
    "href": "docs/maps-storms/storms-slides3.html#animation-with-plotly",
    "title": "North Atlantic Storms",
    "section": "Animation with \"plotly\"",
    "text": "Animation with \"plotly\"\nIn the ggplot command, include a frame aesthetic to indicate the variable that will be used to produce the animation frames. For example: frame=year\n\nstorms2020 = filter(storms, year %in% 2000:2020)\n\nmap_world = ne_countries(returnclass = \"sf\")\n\n# messy ggplot\nggmess = ggplot(data = map_world) +\n  geom_sf(color = \"gray60\") +\n  coord_sf(xlim = c(-110, 0), ylim = c(10, 60)) +\n  geom_path(data = storms2020, \n             aes(x = long, y = lat, group = name, frame = year), \n             color = \"#1726FF\", alpha = 0.8) +\n  theme_minimal() + \n  theme(legend.position = \"none\")\n\nThen, pass the ggplot object to ggplotly()"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#animated-view",
    "href": "docs/maps-storms/storms-slides3.html#animated-view",
    "title": "North Atlantic Storms",
    "section": "Animated view",
    "text": "Animated view\n\n\nView Code\nggplotly(ggmess) |&gt;\n  animation_opts(frame = 1200, transition = 0)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides3.html#hurricane-seasons",
    "href": "docs/maps-storms/storms-slides3.html#hurricane-seasons",
    "title": "North Atlantic Storms",
    "section": "Hurricane Seasons",
    "text": "Hurricane Seasons\n https://github.com/data133/shiny/blob/main/mapping-storms1-basic/app.R\n\n\n\nReturn to Home Page"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#data-storms",
    "href": "docs/maps-storms/storms-slides1.html#data-storms",
    "title": "North Atlantic Storms",
    "section": "Data storms",
    "text": "Data storms\n\n\n# A tibble: 19,537 × 13\n   name   year month   day  hour   lat  long status      category  wind pressure\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;int&gt;    &lt;int&gt;\n 1 Amy    1975     6    27     0  27.5 -79   tropical d…       NA    25     1013\n 2 Amy    1975     6    27     6  28.5 -79   tropical d…       NA    25     1013\n 3 Amy    1975     6    27    12  29.5 -79   tropical d…       NA    25     1013\n 4 Amy    1975     6    27    18  30.5 -79   tropical d…       NA    25     1013\n 5 Amy    1975     6    28     0  31.5 -78.8 tropical d…       NA    25     1012\n 6 Amy    1975     6    28     6  32.4 -78.7 tropical d…       NA    25     1012\n 7 Amy    1975     6    28    12  33.3 -78   tropical d…       NA    25     1011\n 8 Amy    1975     6    28    18  34   -77   tropical d…       NA    30     1006\n 9 Amy    1975     6    29     0  34.4 -75.8 tropical s…       NA    35     1004\n10 Amy    1975     6    29     6  34   -74.8 tropical s…       NA    40     1002\n# ℹ 19,527 more rows\n# ℹ 2 more variables: tropicalstorm_force_diameter &lt;int&gt;,\n#   hurricane_force_diameter &lt;int&gt;"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#plot-storms-paths",
    "href": "docs/maps-storms/storms-slides1.html#plot-storms-paths",
    "title": "North Atlantic Storms",
    "section": "Plot storms’ paths",
    "text": "Plot storms’ paths\n\n\nView Plot Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\n  ggplot(aes(x = long, y = lat, group = name)) +\n  geom_point() +\n  labs(title = \"North Atlantic Storms (1975)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#plot-storms-paths-1",
    "href": "docs/maps-storms/storms-slides1.html#plot-storms-paths-1",
    "title": "North Atlantic Storms",
    "section": "Plot storms’ paths",
    "text": "Plot storms’ paths\n\n\nView Plot Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\n  ggplot(aes(x = long, y = lat, group = name)) +\n  geom_point() +\n  geom_path() + \n  labs(title = \"North Atlantic Storms (1975)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#plot-storms-paths-2",
    "href": "docs/maps-storms/storms-slides1.html#plot-storms-paths-2",
    "title": "North Atlantic Storms",
    "section": "Plot storms’ paths",
    "text": "Plot storms’ paths\n\n\nView Plot Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\n  ggplot(aes(x = long, y = lat, group = name, color = name)) +\n  geom_point(size = 1) +\n  geom_path() + \n  labs(title = \"North Atlantic Storms (1975)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#plot-storms-paths-3",
    "href": "docs/maps-storms/storms-slides1.html#plot-storms-paths-3",
    "title": "North Atlantic Storms",
    "section": "Plot storms’ paths",
    "text": "Plot storms’ paths\n\n\nView Plot Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\n  ggplot(aes(x = long, y = lat, group = name, color = name)) +\n  geom_point(size = 1) +\n  geom_path(arrow = arrow(length = unit(0.1, \"inches\"))) + \n  labs(title = \"North Atlantic Storms (1975)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#plot-storms-paths-4",
    "href": "docs/maps-storms/storms-slides1.html#plot-storms-paths-4",
    "title": "North Atlantic Storms",
    "section": "Plot storms’ paths",
    "text": "Plot storms’ paths\n\n\nView Plot Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\n  ggplot(aes(x = long, y = lat, group = name, color = name)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  geom_path(arrow = arrow(length = unit(0.1, \"inches\"))) + \n  facet_wrap(~ month) +\n  labs(title = \"North Atlantic Storms (1975)\") +\n  theme_bw()"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#wouldnt-this-be-nice",
    "href": "docs/maps-storms/storms-slides1.html#wouldnt-this-be-nice",
    "title": "North Atlantic Storms",
    "section": "Wouldn’t this be nice?",
    "text": "Wouldn’t this be nice?"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#what-about-something-like-this",
    "href": "docs/maps-storms/storms-slides1.html#what-about-something-like-this",
    "title": "North Atlantic Storms",
    "section": "What about something like this?",
    "text": "What about something like this?"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#maps-in-r",
    "href": "docs/maps-storms/storms-slides1.html#maps-in-r",
    "title": "North Atlantic Storms",
    "section": "Maps in R",
    "text": "Maps in R\nOur first approach involves packages:\n\n\"tidyverse\" (data wrangling and exploration)\n\"sf\" (simple features)\n\"rnaturalearth\" (maps data)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#main-idea",
    "href": "docs/maps-storms/storms-slides1.html#main-idea",
    "title": "North Atlantic Storms",
    "section": "Main Idea",
    "text": "Main Idea\nAssuming that you have an \"sf\" (simple features) object (i.e. map data), you pass this to ggplot() and use the geom_sf() layer.\n\n# (abstract code)\nggplot() + \n  geom_sf(data = map_object)\n\n\n\nOr also (with more customizing options)\n\n# (abstract code)\nggplot() + \n  geom_sf(data = map_object) +\n  coord_sf(...)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#map-data-from-rnaturalearth",
    "href": "docs/maps-storms/storms-slides1.html#map-data-from-rnaturalearth",
    "title": "North Atlantic Storms",
    "section": "Map Data from \"rnaturalearth\"",
    "text": "Map Data from \"rnaturalearth\"\nExamples:\n\nne_coastline(returnclass = \"sf\")\nne_countries(returnclass = \"sf\")\nne_countries(country = \"mexico\", returnclass = \"sf\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#coast-line-world-map",
    "href": "docs/maps-storms/storms-slides1.html#coast-line-world-map",
    "title": "North Atlantic Storms",
    "section": "Coast Line World Map",
    "text": "Coast Line World Map\n\n\nView Code\nworld_coast = ne_coastline(returnclass = \"sf\")\n\nggplot() + \n  geom_sf(data = world_coast)"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#map-of-a-given-continent-e.g.-north-america",
    "href": "docs/maps-storms/storms-slides1.html#map-of-a-given-continent-e.g.-north-america",
    "title": "North Atlantic Storms",
    "section": "Map of a given continent (e.g. North America)",
    "text": "Map of a given continent (e.g. North America)\n\n\nView Code\nmap_north_america = ne_countries(\n  continent = \"north america\", \n  returnclass = \"sf\")\n\nggplot() + \n  geom_sf(data = map_north_america) +\n  theme(panel.background = element_blank())"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#map-of-a-given-country-e.g.-mexico",
    "href": "docs/maps-storms/storms-slides1.html#map-of-a-given-country-e.g.-mexico",
    "title": "North Atlantic Storms",
    "section": "Map of a given country (e.g. Mexico)",
    "text": "Map of a given country (e.g. Mexico)\n\n\nView Code\nmap_mexico1 = ne_countries(country = \"mexico\", returnclass = \"sf\")\n\nggplot() + \n  geom_sf(data = map_mexico1) +\n  theme(panel.background = element_blank())"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#map-of-a-given-country-with-states-e.g.-mexico",
    "href": "docs/maps-storms/storms-slides1.html#map-of-a-given-country-with-states-e.g.-mexico",
    "title": "North Atlantic Storms",
    "section": "Map of a given country, with states (e.g. Mexico)",
    "text": "Map of a given country, with states (e.g. Mexico)\n\n\nView Code\n# (requires pkg \"rnaturalearthhires\")\n# remotes::install_github(\"ropensci/rnaturalearthhires\")\nmap_mexico2 = ne_states(country = \"mexico\", returnclass = \"sf\")\n\nggplot() + \n  geom_sf(data = map_mexico2) +\n  theme(panel.background = element_blank())"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map",
    "href": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map",
    "title": "North Atlantic Storms",
    "section": "Adding Data to a Map",
    "text": "Adding Data to a Map\n\n# (abstract code)\nggplot() + \n  geom_sf(data = map_object) +\n  geom_...(data = data_table, aes(...))\n\n\n\nOr also:\n\n# (abstract code)\nggplot() + \n  geom_sf(data = map_object) +\n  geom_...(data = data_table, aes(...)) +\n  geom_...(data = data_table, aes(...))"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map-1",
    "href": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map-1",
    "title": "North Atlantic Storms",
    "section": "Adding Data to a Map",
    "text": "Adding Data to a Map\n\n\nView Code\nstorms75 = storms |&gt; filter(year == 1975)\n\nggplot() + \n  geom_sf(data = map_north_america) +\n  geom_point(data = storms75, \n             aes(x = long, y = lat, group = name, color = name)) +\n  theme(panel.background = element_blank()) +\n  labs(title = \"North Atlantic Storms (1975)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map-2",
    "href": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map-2",
    "title": "North Atlantic Storms",
    "section": "Adding Data to a Map",
    "text": "Adding Data to a Map\n\n\nView Code\nstorms75 = storms |&gt; filter(year == 1975)\n\nggplot() + \n  geom_sf(data = map_north_america) +\n  geom_point(data = storms75, size = 0.5,\n             aes(x = long, y = lat, group = name, color = name)) +\n  geom_path(data = storms75, \n             aes(x = long, y = lat, group = name, color = name)) +\n  theme(panel.background = element_blank()) +\n  labs(title = \"North Atlantic Storms (1975)\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map-3",
    "href": "docs/maps-storms/storms-slides1.html#adding-data-to-a-map-3",
    "title": "North Atlantic Storms",
    "section": "Adding Data to a Map",
    "text": "Adding Data to a Map\n\n\nView Code\nstorms75 = storms |&gt; filter(year == 1975)\n\nggplot() +\n  geom_sf(data = world_countries) +\n  coord_sf(xlim = c(-110, 0), ylim = c(5, 65)) +\n  geom_path(data = storms75, \n          aes(x = long, y = lat, group = name, color = name)) +\n  facet_wrap(~ year, nrow = 2) +\n  theme(panel.background = element_blank(),\n        axis.ticks = element_blank(), # hide tick marks\n        axis.text = element_blank()) + # hide degree values of lat & lon\n  labs(title = \"North Atlantic Storms (1975)\",\n       x = \"\", \n       y = \"\")\n\n\n\n\n\n\nReturn to Home Page"
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis2.html",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis2.html",
    "title": "Correspondence Analysis 2",
    "section": "",
    "text": "This is a companion file to the Stat 133 lectures on “Text Mining”. You’ll need the following packages:\n# used packages\nlibrary(tidyverse)    # base tidy data tools\nlibrary(tidytext)     # text mining; gets along with tidyverse\nlibrary(janeaustenr)  # Jane Austen's novels\nlibrary(FactoMineR)   # Multivariate Statistics methods"
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis2.html#jane-austens-novels",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis2.html#jane-austens-novels",
    "title": "Correspondence Analysis 2",
    "section": "1 Jane Austen’s Novels",
    "text": "1 Jane Austen’s Novels\nAs you know, the package \"janeaustenr\" contains the six novels by Jane Austen:\n\nEmma\n\nMansfield Park\n\nNorthanger Abbey\n\nPersuasion\n\nPride and Prejudice\n\nSense and Sensibility\n\nThe text of each novel is available in vector format: e.g. prideprejudice, emma, persuasion. But you can also find the text of all six novels in a single data frame (tibble) by using the function austen_books()\n\nausten_books()"
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis2.html#detecting-associations-with-correspondence-analysis-ca",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis2.html#detecting-associations-with-correspondence-analysis-ca",
    "title": "Correspondence Analysis 2",
    "section": "2 Detecting Associations with Correspondence Analysis (CA)",
    "text": "2 Detecting Associations with Correspondence Analysis (CA)\nSay we are interested in studying the use of punctuation symbols across all Austen’s novels:\n\ncommas: \",\"\nsemicolons: \";\"\ncolons: \":\"\nquotations: '\\\\\"'\napostrophes: \"'\"\nquestion marks: \"?\"\nexclamation symbols: \"!\"\ndashes (pairs): \"--\"\n\nWe can use str_count() to count the frequencies of these types of symbols, and then get the their total sum for each book:\n\ncrosstable = austen_books() |&gt;\n  mutate(\n    commas = str_count(text, \",\"),\n    colons = str_count(text, \":\"),\n    semicolons = str_count(text, \";\"),\n    quotes = str_count(text, '\\\\\"'),\n    apostrophes = str_count(text, \"'\"),\n    questions = str_count(text, \"\\\\?\"),\n    exclamations = str_count(text, \"\\\\!\"),\n    dashes = str_count(text, \"--\")\n  ) |&gt;\n  group_by(book) |&gt;\n  summarise(\n    commas = sum(commas),\n    colons = sum(colons),\n    semis = sum(semicolons),\n    quotes = sum(quotes),\n    aposts = sum(apostrophes),\n    quests = sum(questions),\n    bangs = sum(exclamations),\n    dashes = sum(dashes)\n  )\n\ncrosstable\n\n# A tibble: 6 × 9\n  book                commas colons semis quotes aposts quests bangs dashes\n  &lt;fct&gt;                &lt;int&gt;  &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n1 Sense & Sensibility   9900     66  1572   3084    914    451   561   1178\n2 Pride & Prejudice     9132    132  1538   3531    741    462   499    395\n3 Mansfield Park       12439    339  2260   3292   1135    471   496    413\n4 Emma                 12020    174  2353   4189   1226    621  1063   3100\n5 Northanger Abbey      6085     83  1172   2151    545    392   433    419\n6 Persuasion            7025    130  1320   1565    582    217   318    142\n\n\nThe above table, technically speaking, is an example of a cross-table, also referred to as a 2-way table or a contingency table. The important thing about this table is that it contains counts, which in turn are non-negative numbers.\nFrom a statistical point of view, this table is the result of crossing the categories of 2 qualitative (i.e. categorical) variables:\n\nVariable \\(V_1\\): name of book or novel\nVariable \\(V_2\\): type of punctuation symbol\n\n\n\n\nCross-table from 2 categorical variables\n\n\nWith this kind of table, we could ask questions like:\n\nIs there an association between books and punctuation symbols?\nDo some books tend to have more (or less) of a certain punctuation symbol?\n\nTo answer this kind of questions, we can use a statistical multivariate method known as Correspondence Analysis (CA).\nOriginally, CA was developed to analyze contingency tables in which a sample of observations is described by two nominal variables, but it was rapidly extended to the analysis of any data table with non-negative entries.\nOn a side note, we should mention that CA was often discovered (and rediscovered), and so variations of CA can be found under several different names such as “dual scaling,” “optimal scaling,” “homogeneity analysis,” or “reciprocal averaging.” The multiple identities of correspondence analysis are a consequence of its large number of properties, that answer a lot of apparently different problems."
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis2.html#correspondence-analysis-map",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis2.html#correspondence-analysis-map",
    "title": "Correspondence Analysis 2",
    "section": "3 Correspondence Analysis Map",
    "text": "3 Correspondence Analysis Map\nIn order to explain Correspondence Analysis, and also to simplify some of the computations on the data in crosstable, it’s better if we reformat this object as a matrix:\n\n# cross-table in matrix format\n# (matrix of counts or frequencies)\nX = as.matrix(crosstable[,-1])\nrownames(X) = str_extract(crosstable$book, \"\\\\w+\")\n\nX\n\n           commas colons semis quotes aposts quests bangs dashes\nSense        9900     66  1572   3084    914    451   561   1178\nPride        9132    132  1538   3531    741    462   499    395\nMansfield   12439    339  2260   3292   1135    471   496    413\nEmma        12020    174  2353   4189   1226    621  1063   3100\nNorthanger   6085     83  1172   2151    545    392   433    419\nPersuasion   7025    130  1320   1565    582    217   318    142\n\n\n\n\n\nCross-table from 2 categorical variables\n\n\n\nThe previous row-analysis and column-analysis let us get an idea of how categories in variable \\(V_1\\) seem to be associated with categories in variable \\(V_2\\). While these two analyses provide useful information, we have to carry out them separately. Interestingly, we can use correspondence analysis to perform a similar exploration in a simultaneous way, without having to derive all the different kinds of probabilities and their associated tables.\nTo perform a correspondence analysis we are going to use the CA() function from the package \"FactoMineR\". This function takes a data table or a matrix with non-negative numbers, such our initial matrix X.\n\n3.1 Simultaneous Representation of Rows and Columns\nFrom an exploratory data analysis standpoint, we can use Correspondence Analysis to obtain a “map” (or scatterplot) to visually represent the categories behind the crosstable of frequencies, like in the following graphic:\n\nausten_ca1 = CA(X)\n\n\n\n\n\n\n\n\nBy default, CA() produces its own plot (see figure above). You can turn off this behavior with the argument graph = FALSE\n\n# no default plot\nausten_ca1 = CA(X, graph = FALSE)\n\nIf we want to use ggplot(), we need to do a bit of data manipulation:\n\n# table with row and column coordinates (i.e. factor scores)\nca_dat = data.frame(\n  rbind(austen_ca1$row$coord[ ,1:2], \n        austen_ca1$col$coord[ ,1:2]))\n\n# type of book or symbol\nca_dat$type = c(rep(\"book\", nrow(austen_ca1$row$coord)), \n                rep(\"symbol\", nrow(austen_ca1$col$coord)))\n\n# correspondence analysis scatterplot\nggplot(ca_dat, aes(x = Dim.1, y = Dim.2, color = type)) +\n  geom_hline(yintercept = 0, col = \"gray60\") +\n  geom_vline(xintercept = 0, col = \"gray60\") +\n  geom_point() +\n  geom_text(label = rownames(ca_dat), alpha = 0.8) +\n  scale_x_continuous(limits = c(-0.4, 0.8)) +\n  labs(title = \"Correspondence Analysis map\",\n       x = sprintf(\"Dim-1 (%0.2f%s)\", austen_ca1$eig[1,2], \"%\"),\n       y = sprintf(\"Dim-2 (%0.2f%s)\", austen_ca1$eig[2,2], \"%\"))\n\n\n\n\n\n\n\n\nWhat does CA do?: Without going down the technical rabbit hole behind CA, it can be said that CA transforms a data table into two sets of new variables called factor scores: one set for the rows, and one set for the columns. These factor scores give the best representation of the similarity structure of, respectively, the rows and the columns of the table.\nIn the above map, rows and columns are represented as points whose coordinates are the factor scores and where the dimensions are also called factors, or simply dimensions. Interestingly, the factor scores of the rows and the columns have the same variance and, therefore, the rows and columns can be conveniently represented in one single map.\nHow to Interpret Point Proximity: Because of the way in which the coordinates are obtained to produce the above CA map, we get a nice interpretation of the displayed data. When two row points (or two column points, respectively) are close to each other, this means that these points have similar profiles, and therefore they will be located exactly at the same place.\nWhat about the proximity between row and column points? It turns out that we can comment on the position of a row with respect to the positions of all of the columns but keeping in mind that it is impossible to draw conclusions about the distance between a specific row and a specific column.\nThe first dimension opposes the categories dashes and colons. This opposition on the graph is associated to the book Emma which has the largest proportion of dashes compared to the rest of the books. The table below shows the relative frequencies between a given book and a given symbol. Notice the cell of Emma and dashes, which has the largest proportion. In contrast, colons are more present in Mansfield than in any other book.\nThe book category Sense is extremely close to the origin of the graphic, thus indicating a profile near to the average book profile. Likewise the symbol category commas is the closest to the origin, signaling that this symbol is also close to the use of the average symbol profile."
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis2.html#another-example-of-ca",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis2.html#another-example-of-ca",
    "title": "Correspondence Analysis 2",
    "section": "4 Another example of CA",
    "text": "4 Another example of CA\nLet’s consider another example performing a sentiment analysis and visualizing the results with a correspondence analysis map.\nWe’ll keep using all the books by Jane Austen. As usual, we begin by tokenizing the texts, then we remove stop-words, and after that we merge—via inner_join()—sentiments from Bing’s lexicon:\n\nword_sentims = austen_books() |&gt;\n  unnest_tokens(output = word, input = text) |&gt;\n  anti_join(stop_words, by = \"word\") |&gt;\n  inner_join(sentiments, \n             by = \"word\", \n             relationship = \"many-to-many\") |&gt;\n  count(book, word, name = \"count\", sort = TRUE)\n\nhead(word_sentims, 10)\n\n# A tibble: 10 × 3\n   book                word  count\n   &lt;fct&gt;               &lt;chr&gt; &lt;int&gt;\n 1 Emma                miss    599\n 2 Mansfield Park      miss    432\n 3 Pride & Prejudice   miss    283\n 4 Sense & Sensibility miss    210\n 5 Northanger Abbey    miss    206\n 6 Emma                poor    136\n 7 Emma                happy   125\n 8 Persuasion          miss    125\n 9 Mansfield Park      love    124\n10 Mansfield Park      happy   117\n\n\nNotice that the most frequent word is miss which we know is more likely to refer to a lady or woman instead of the verb “to miss”. Therefore, we are going to remove it from word_sentims\n\nword_sentims = word_sentims |&gt;\n  filter(word != \"miss\")\n\nhead(word_sentims, 10)\n\n# A tibble: 10 × 3\n   book                word     count\n   &lt;fct&gt;               &lt;chr&gt;    &lt;int&gt;\n 1 Emma                poor       136\n 2 Emma                happy      125\n 3 Mansfield Park      love       124\n 4 Mansfield Park      happy      117\n 5 Emma                love       117\n 6 Emma                pleasure   115\n 7 Mansfield Park      pleasure   101\n 8 Sense & Sensibility happy      100\n 9 Emma                doubt       98\n10 Mansfield Park      poor        96\n\n\nThe next step involves identifying, in a somewhat arbitrary way, words that have a “large” count, for example a count greater than or equal to 68:\n\nselected_words = word_sentims |&gt;\n  filter(count &gt;= 68) |&gt;\n  distinct(word) |&gt;\n  pull()\n\nselected_words\n\n[1] \"poor\"      \"happy\"     \"love\"      \"pleasure\"  \"doubt\"     \"happiness\"\n[7] \"comfort\"   \"affection\" \"pretty\"   \n\n\nWith these selected_words, we filter them in from word_sentims to get a subset word_sentims2:\n\nword_sentims2 = word_sentims |&gt;\n  filter(word %in% selected_words)\n\nhead(word_sentims2, 10)\n\n# A tibble: 10 × 3\n   book                word     count\n   &lt;fct&gt;               &lt;chr&gt;    &lt;int&gt;\n 1 Emma                poor       136\n 2 Emma                happy      125\n 3 Mansfield Park      love       124\n 4 Mansfield Park      happy      117\n 5 Emma                love       117\n 6 Emma                pleasure   115\n 7 Mansfield Park      pleasure   101\n 8 Sense & Sensibility happy      100\n 9 Emma                doubt       98\n10 Mansfield Park      poor        96\n\n\nHaving obtained the table word_sentims2, we then proceed to obtain the cross-table between books and the selected words\n\ncrosstable2 = word_sentims2 |&gt;\n  select(book, word, count) |&gt;\n  pivot_wider(\n    names_from = word,\n    values_from = count)\n\ncrosstable2\n\n# A tibble: 6 × 10\n  book        poor happy  love pleasure doubt happiness comfort affection pretty\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;     &lt;int&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n1 Emma         136   125   117      115    98        76      65        50     68\n2 Mansfield…    96   117   124      101    46        86      83        52     56\n3 Sense & S…    71   100    77       67    46        66      63        79     36\n4 Pride & P…    38    83    92       92    37        72      31        58     24\n5 Persuasion    55    64    42       39    26        32      21         9     28\n6 Northange…    28    45    43       48    28        37      29        24     30\n\n\nTo apply correspondence analysis, we convert crosstable into a matrix Y. In case we had entries with missing values, we play safe and artificially replace NA with 0.\n\nY = as.matrix(crosstable2[,-1])\nY[is.na(Y)] = 0\nrownames(Y) = str_extract(crosstable2$book, \"\\\\w+\")\nY\n\n           poor happy love pleasure doubt happiness comfort affection pretty\nEmma        136   125  117      115    98        76      65        50     68\nMansfield    96   117  124      101    46        86      83        52     56\nSense        71   100   77       67    46        66      63        79     36\nPride        38    83   92       92    37        72      31        58     24\nPersuasion   55    64   42       39    26        32      21         9     28\nNorthanger   28    45   43       48    28        37      29        24     30\n\n\nThe last step involves passing Y to CA() to obtain the necessary outputs and produce the correspondence analysis map with ggplot() and friends:\n\n# Correspondence Analysis\nausten_ca2 = CA(Y, graph = FALSE)\n\n# table with row and column coordinates (i.e. factor scores)\nca_dat = data.frame(\n  rbind(austen_ca2$row$coord[ ,1:2], \n        austen_ca2$col$coord[ ,1:2]))\n\n# type of book or word\nca_dat$type = c(rep(\"book\", nrow(austen_ca2$row$coord)), \n                rep(\"word\", nrow(austen_ca2$col$coord)))\n\n# correspondence analysis scatterplot\nggplot(ca_dat, aes(x = Dim.1, y = Dim.2, color = type)) +\n  geom_hline(yintercept = 0, col = \"gray60\") +\n  geom_vline(xintercept = 0, col = \"gray60\") +\n  geom_point() +\n  geom_text(label = rownames(ca_dat), alpha = 0.8) +\n  scale_x_continuous(limits = c(-0.3, 0.4)) +\n  labs(title = \"Correspondence Analysis map\",\n       x = sprintf(\"Dim-1 (%0.2f%s)\", austen_ca2$eig[1,2], \"%\"),\n       y = sprintf(\"Dim-2 (%0.2f%s)\", austen_ca2$eig[2,2], \"%\"))\n\n\n\n\n\n\n\n\n\n4.1 Words with Positive Sentiments\nOut of curiosity, we can perform a similar analysis but this time using only positive words (the same could be done with only negative words).\n\npositive_words = austen_books() |&gt;\n  unnest_tokens(output = word, input = text) |&gt;\n  anti_join(stop_words, by = \"word\") |&gt;\n  count(book, word, name = \"count\") |&gt;\n  inner_join(sentiments, \n             by = \"word\", \n             relationship = \"many-to-many\") |&gt;\n  filter(sentiment == \"positive\") |&gt;\n  arrange(desc(count))\n\nhead(positive_words, 10)\n\n# A tibble: 10 × 4\n   book                word      count sentiment\n   &lt;fct&gt;               &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;    \n 1 Emma                happy       125 positive \n 2 Mansfield Park      love        124 positive \n 3 Mansfield Park      happy       117 positive \n 4 Emma                love        117 positive \n 5 Emma                pleasure    115 positive \n 6 Mansfield Park      pleasure    101 positive \n 7 Sense & Sensibility happy       100 positive \n 8 Pride & Prejudice   love         92 positive \n 9 Pride & Prejudice   pleasure     92 positive \n10 Mansfield Park      happiness    86 positive \n\n\nLike in preceding example, here the idea is to identify common positive words. For instance, we can identify words that have a count greater than 50 (you can choose another threshold):\n\nselected_positive = positive_words |&gt;\n  filter(count &gt;= 50) |&gt;\n  distinct(word) |&gt;\n  pull()\n\nselected_positive\n\n [1] \"happy\"     \"love\"      \"pleasure\"  \"happiness\" \"comfort\"   \"affection\"\n [7] \"pretty\"    \"glad\"      \"perfectly\" \"ready\"     \"kindness\"  \"assure\"   \n[13] \"superior\"  \"fine\"      \"agreeable\" \"satisfied\" \"regard\"   \n\n\nWith these subset of positive words, we filter them in from positive_words and then obtain the cross-table between book categories and positive words:\n\ncrosstable3 = positive_words |&gt;\n  filter(word %in% selected_positive) |&gt;\n  select(book, word, count) |&gt;\n  pivot_wider(\n    names_from = word,\n    values_from = count)\n\ncrosstable3\n\n# A tibble: 6 × 18\n  book   happy  love pleasure happiness comfort affection pretty  glad perfectly\n  &lt;fct&gt;  &lt;int&gt; &lt;int&gt;    &lt;int&gt;     &lt;int&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt; &lt;int&gt;     &lt;int&gt;\n1 Emma     125   117      115        76      65        50     68    50        67\n2 Mansf…   117   124      101        86      83        52     56    67        48\n3 Sense…   100    77       67        66      63        79     36    44        43\n4 Pride…    83    92       92        72      31        58     24    37        47\n5 Persu…    64    42       39        32      21         9     28    33        43\n6 North…    45    43       48        37      29        24     30    32        23\n# ℹ 8 more variables: ready &lt;int&gt;, kindness &lt;int&gt;, assure &lt;int&gt;,\n#   superior &lt;int&gt;, fine &lt;int&gt;, agreeable &lt;int&gt;, satisfied &lt;int&gt;, regard &lt;int&gt;\n\n\nTo pass the cross-table to CA(), we convert crosstable3 into a matrix Xpos:\n\nXpos = as.matrix(crosstable3[,-1])\nXpos[is.na(Xpos)] = 0\nrownames(Xpos) = str_extract(crosstable3$book, \"\\\\w+\")\nXpos\n\n           happy love pleasure happiness comfort affection pretty glad\nEmma         125  117      115        76      65        50     68   50\nMansfield    117  124      101        86      83        52     56   67\nSense        100   77       67        66      63        79     36   44\nPride         83   92       92        72      31        58     24   37\nPersuasion    64   42       39        32      21         9     28   33\nNorthanger    45   43       48        37      29        24     30   32\n           perfectly ready kindness assure superior fine agreeable satisfied\nEmma              67    66       40     59       59   42        50        52\nMansfield         48    60       60     19       11   57        52        44\nSense             43    35       42     32       12   25        25        26\nPride             47    20       29     39       18   31        45        34\nPersuasion        43    22       15     25        9   33        38        23\nNorthanger        23    23       14     18        5   28        32        17\n           regard\nEmma           43\nMansfield      37\nSense          50\nPride          49\nPersuasion     25\nNorthanger     10\n\n\nAnd finally we apply CA() to Xpos to get the CA map:\n\nca_pos = CA(Xpos, graph = FALSE)\n\n# table with row and column coordinates (i.e. factor scores)\nca_dat = data.frame(\n  rbind(ca_pos$row$coord[ ,1:2], \n        ca_pos$col$coord[ ,1:2]))\n\n# type of book or word\nca_dat$type = c(rep(\"book\", nrow(ca_pos$row$coord)), \n                rep(\"word\", nrow(ca_pos$col$coord)))\n\n# correspondence analysis scatterplot\nggplot(ca_dat, aes(x = Dim.1, y = Dim.2, color = type)) +\n  geom_hline(yintercept = 0, col = \"gray60\") +\n  geom_vline(xintercept = 0, col = \"gray60\") +\n  geom_point() +\n  geom_text(label = rownames(ca_dat), alpha = 0.8) +\n  scale_x_continuous(limits = c(-0.4, 0.5)) +\n  labs(title = \"Correspondence Analysis map\",\n       subtitle = \"Words with positive sentiments\",\n       x = sprintf(\"Dim-1 (%0.2f%s)\", ca_pos$eig[1,2], \"%\"),\n       y = sprintf(\"Dim-2 (%0.2f%s)\", ca_pos$eig[2,2], \"%\"))"
  },
  {
    "objectID": "email.html",
    "href": "email.html",
    "title": "Communication via Email",
    "section": "",
    "text": "Email: gastonsanchez@berkeley.edu\nYou should limit your emails to serious problems that cannot be addressed during office hours. The vast majority of questions can be answered during OH. Email should not be used for information that is readily available in course materials (syllabus, discussion forum, announcements, etc.) or from fellow students.\nI do not explain course material over email and will not respond to emails with such requests. Please use office hours, or discussion section, (or schedule another time to meet with the teaching staff if you have irreconcilable conflicts with the office hours)."
  },
  {
    "objectID": "email.html#reading-and-responding-email",
    "href": "email.html#reading-and-responding-email",
    "title": "Communication via Email",
    "section": "Reading and responding email",
    "text": "Reading and responding email\nFor general emails, I will reply to general questions or concerns within 2 to 3 business days, Monday through Friday, during regular academic hours (9:00AM-5:00PM).\nPlease note that I do not read email between 5pm and 9am, or during the weekends. Likewise, I do not respond to emails on the weekend.\nex. If you send an email at 6pm on Friday night, you can expect that I will read it around 9am on Monday morning, and should likely receive a response by around 9am on Tuesday morning.\nIf, for any reason, I haven’t responded to your email after four business days, please email me again. I am human, and there are times when student emails fall through the cracks inadvertently.\nI prefer to have conversations in person rather than via email, thus allowing us to get to know each other better and fostering a more collegial learning atmosphere."
  },
  {
    "objectID": "email.html#communicate-in-a-professional-manner",
    "href": "email.html#communicate-in-a-professional-manner",
    "title": "Communication via Email",
    "section": "Communicate in a professional manner",
    "text": "Communicate in a professional manner\nIf you believe your situation warrants an email, please feel free to send me a professional email. E-mail communication should be courteous and respectful in manner and tone. Please do not send e-mails that are curt or demanding.\nHere’s a short example of an unprofessional email. Let’s assume you missed an exam, for whatever reason. Do not write and say: “I missed an exam. When can I make it up?” Instead, explain why you have extenuating circumstances, and ask the teaching staff if they will allow you to make up the exam. Most likely you won’t be able to make it up, but at least you are asking in a professional way.\nIf you are unsure of how to write an email to me or any other professor, please consult this amusing blog post that gives you a useful template:\nhttps://medium.com/@lportwoodstacer/how-to-email-your-professor-without-being-annoying-af-cf64ae0e4087"
  },
  {
    "objectID": "email.html#subject-line",
    "href": "email.html#subject-line",
    "title": "Communication via Email",
    "section": "Subject line",
    "text": "Subject line\nIf you wish for your email to make it into my inbox, do not leave the subject line blank. Instead, make sure the subject of your email contains the code course and a brief explanation of the nature of the email. For example: “Stat 133-Question about Homework” or “Stat 133-Request for Meeting”."
  },
  {
    "objectID": "email.html#avoid-these-subjects",
    "href": "email.html#avoid-these-subjects",
    "title": "Communication via Email",
    "section": "Avoid these subjects",
    "text": "Avoid these subjects\n\nAvoid emailing me to explain why you missed or will miss class. I usually don’t need to know. If you think this is affecting your performance, then schedule a meeting with me.\nDo not email me to let me know you made a mistake in your submitted assignment. Please refer to the HW policies (see syllabus).\nDo not email me to ask for extra credit. Here’s why: https://marktomforde.com/academic/undergraduates/NoExtraCredit.html\nAbove all, do not email me to engage in grade grubbing. Here’s why: https://marktomforde.com/academic/undergraduates/GradeGrubbing.html"
  },
  {
    "objectID": "email.html#scheduling-a-meeting",
    "href": "email.html#scheduling-a-meeting",
    "title": "Communication via Email",
    "section": "Scheduling a meeting",
    "text": "Scheduling a meeting\nIf you wish to schedule a meeting with me, your message should include at least two times when you would like to meet and a brief (one-two sentence) description of the reason for the meeting."
  },
  {
    "objectID": "email.html#emails-regarding-letters-of-recommendation",
    "href": "email.html#emails-regarding-letters-of-recommendation",
    "title": "Communication via Email",
    "section": "Emails regarding letters of recommendation",
    "text": "Emails regarding letters of recommendation\nBefore you ask me to write you a letter of recommendation, please take a look at the following document: https://github.com/gastonstat/letter-of-rec"
  },
  {
    "objectID": "ed-netiquette.html",
    "href": "ed-netiquette.html",
    "title": "Ed-Discussion Netiquette",
    "section": "",
    "text": "Unfortunately, we just don’t have enough human resources to have a dedicated Ed-Discussion moderator. We will do our best to monitor this tool once per day from Monday to Friday. Please note that we may not be able to monitor Ed during the evening nor weekend. That’s why we strongly encourage student participation on Ed-Discussion rather than answering right away (i.e. we want other students step up and answer questions).\nIn the past, some students have decided to use external discussion forums. When used responsibly and appropriately, we think that’s a great idea. But we have never endorsed their use, nor we have monitored, moderated or managed them, and we won’t do that this time.\nIn order to make Ed-Discussion a better resource for everyone, we’ve outlined some guidelines for you to follow when posting on this tool. Questions which follow these guidelines tend to have a higher chance of being answered!\n\nPlease adhere to the same standards of behavior online that you follow in real life.\nWe want to make sure that you are helping each other out, and having instructors give away the answers isn’t the most beneficial for your education either."
  },
  {
    "objectID": "ed-netiquette.html#important-note",
    "href": "ed-netiquette.html#important-note",
    "title": "Ed-Discussion Netiquette",
    "section": "",
    "text": "Unfortunately, we just don’t have enough human resources to have a dedicated Ed-Discussion moderator. We will do our best to monitor this tool once per day from Monday to Friday. Please note that we may not be able to monitor Ed during the evening nor weekend. That’s why we strongly encourage student participation on Ed-Discussion rather than answering right away (i.e. we want other students step up and answer questions).\nIn the past, some students have decided to use external discussion forums. When used responsibly and appropriately, we think that’s a great idea. But we have never endorsed their use, nor we have monitored, moderated or managed them, and we won’t do that this time.\nIn order to make Ed-Discussion a better resource for everyone, we’ve outlined some guidelines for you to follow when posting on this tool. Questions which follow these guidelines tend to have a higher chance of being answered!\n\nPlease adhere to the same standards of behavior online that you follow in real life.\nWe want to make sure that you are helping each other out, and having instructors give away the answers isn’t the most beneficial for your education either."
  },
  {
    "objectID": "ed-netiquette.html#keep-in-mind-common-rules-of-netiquette",
    "href": "ed-netiquette.html#keep-in-mind-common-rules-of-netiquette",
    "title": "Ed-Discussion Netiquette",
    "section": "Keep in mind common rules of netiquette",
    "text": "Keep in mind common rules of netiquette\n\nDon’t post irrelevant links, comments, thoughts or pictures.\nDon’t type in ALL CAPS! If you do it will look like you are screaming.\nDon’t write anything that sounds angry or sarcastic even as a joke, because without hearing your tone of voice, your peers might not realize you’re joking.\nAlways remember to say “please” and “thank you” when soliciting help from your classmates.\nRespect the opinion of your classmates. If you feel the need to disagree, do so respectfully and acknowledge the valid points in your classmate’s argument.\nRefrain from personal abuse. Don’t badmouth others or call them offensive words. You may express robust disagreement with what someone says, but don’t call them names.\nBe forgiving. If your classmate makes a mistake, don’t badger him or her for it. Just let it go.\nIf you reply to a question from a classmate, make sure your answer is accurate.\nBe brief. If you write a long dissertation in response to a simple question, it’s unlikely that anyone will spend the time to read through it all.\nRemember that your public posts are not anonymous. They can be read by your classmates.\nDon’t expect other people to do your homework for you. If you’re looking for technical help, for example, don’t ask questions you could easily answer yourself by reading the manual or help documentation provided with the software tools used in this course."
  },
  {
    "objectID": "ed-netiquette.html#ask-lab-and-hw-questions-only-in-the-designated-lab-and-hw-posts",
    "href": "ed-netiquette.html#ask-lab-and-hw-questions-only-in-the-designated-lab-and-hw-posts",
    "title": "Ed-Discussion Netiquette",
    "section": "Ask Lab and HW questions only in the designated Lab and HW posts",
    "text": "Ask Lab and HW questions only in the designated Lab and HW posts\nWe’ve created individual posts for each type of assignment. Please ask questions, discuss problems, or help out in those posts only. Before asking a question, read through (or search) the whole thread to see if your question has been answered. Likewise, stay on topic."
  },
  {
    "objectID": "ed-netiquette.html#do-not-post-answers-in-discussion-forums",
    "href": "ed-netiquette.html#do-not-post-answers-in-discussion-forums",
    "title": "Ed-Discussion Netiquette",
    "section": "Do NOT post answers in discussion forums",
    "text": "Do NOT post answers in discussion forums\nPlease don’t give away the answer on any discussion forum. You can explain things in a way that still lets other students figure out the essence of the problem on their own, but don’t spoil the problem. For example, don’t point to a useful stackoverflow or YouTube link that works out essentially what the problem is asking about.\nThat is not cool.\nPost such spoilers after the HW is due. That is totally fine. If you are not sure, post privately to instructors and then we’ll let you know."
  },
  {
    "objectID": "ed-netiquette.html#ask-questions-about-assignments-only",
    "href": "ed-netiquette.html#ask-questions-about-assignments-only",
    "title": "Ed-Discussion Netiquette",
    "section": "Ask questions about assignments only",
    "text": "Ask questions about assignments only\nIf you have questions, comments, or other concerns that are not related to assignments, please email your GSI or the instructor. We want to keep the focus of bCourses tools for assignments in Stat 133."
  },
  {
    "objectID": "ed-netiquette.html#try-to-make-posts-public",
    "href": "ed-netiquette.html#try-to-make-posts-public",
    "title": "Ed-Discussion Netiquette",
    "section": "Try to make posts public",
    "text": "Try to make posts public\nWhile not violating the preceding rules, try to make your questions public, because others might have the same question and we don’t need to answer them multiple times."
  },
  {
    "objectID": "ed-netiquette.html#minute-test",
    "href": "ed-netiquette.html#minute-test",
    "title": "Ed-Discussion Netiquette",
    "section": "3 minute-test",
    "text": "3 minute-test\nIf you think your questions may take more than 3 or 5 minutes to answer, please come to office hours, or try to schedule a zoom meeting with the teaching staff."
  },
  {
    "objectID": "ed-netiquette.html#we-are-not-pre-grading",
    "href": "ed-netiquette.html#we-are-not-pre-grading",
    "title": "Ed-Discussion Netiquette",
    "section": "We are not pre-grading",
    "text": "We are not pre-grading\nPlease do not post questions of the form:\n\n“Is this the correct solution to HW X problem Y?”\n“Would this receive full credit on HW X problem Y?”\n“Is this the right level of detail for HW X problem Y?”\n\nPlease do not ask instructors to check your homework in advance. We simply cannot check every student’s homework.\nFeel free to ask questions of clarification about a certain HW problem, or ask questions about the course content to achieve a deeper understanding, but at a certain point, you must apply your knowledge, give it your best shot, and submit your answers with confidence."
  },
  {
    "objectID": "ed-netiquette.html#post-a-screenshot-of-any-resource-referenced",
    "href": "ed-netiquette.html#post-a-screenshot-of-any-resource-referenced",
    "title": "Ed-Discussion Netiquette",
    "section": "Post a screenshot of any resource referenced",
    "text": "Post a screenshot of any resource referenced\nYour question should be self-contained. The GSIs (and other responders) should not have to scan through PDFs or scripts to even figure out what the question is. Ask yourself: am I referring to some lecture /HW solution/discussion solution/etc?\nIf the answer is yes, post a screenshot of the relevant part. This can include your handwritten notes from the relevant lecture."
  },
  {
    "objectID": "ed-netiquette.html#post-all-your-work",
    "href": "ed-netiquette.html#post-all-your-work",
    "title": "Ed-Discussion Netiquette",
    "section": "Post all your work",
    "text": "Post all your work\nDon’t post one line saying:\n\n“At step n, I get XYZ, and I’m now confused.”\nThis forces the GSIs to guess:\nWhat happened in steps 1, 2, …, n - 1?\n\nMost likely, the GSIs will guess wrong, and we run into a mess of followup questions trying to figure out what steps 1, 2, …, n - 1 were.\nInstead, post:\n\nStarting out, we have: ….\nThen, I do …, and I get …\nNext, I do …, and I get …\nNext, I do …, and I get …\nNow, I get $&%&#(, and this makes no sense.\nThen, the GSI can respond:\nThe mistake is at step 3, you’re not allowed to apply ABC to XYZ because …\n\nIn summary, when you do ask for help, include details of what attempts you’ve made to solve the problem. It will save time and also show people that you are making an effort to help yourself.\n\nWe reserve the right to delete any posts\nWe reserve the right to delete, move, or edit any posts, and even to make Ed-Discussion inactive, at any time, without previous notice.\nDiscussion resources can be a great tools if used appropriately, respectfully, and wisely. Take advantage of Ed, and make the most out of it."
  },
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "Practice",
    "section": "",
    "text": "Additional practice problems.\n\nVector basics\nVector subsetting\nLists\nMatrices\nFunctions\nFunctions and Conditionals (if-else)\nIterations\nMore Loops\nIntro to ggplot2\nMore ggplot2\nIntro to dplyr\nImporting files with readr\nRegular Expressions 1\nRegular Expressions 2",
    "crumbs": [
      "Practice Problems"
    ]
  },
  {
    "objectID": "faqs.html",
    "href": "faqs.html",
    "title": "Some Frequently Asked Questions",
    "section": "",
    "text": "Will STAT 133 be offered in hybrid mode (both in-person and remotely, simultaneously)?  No, STAT 133 will not be offered in hybrid mode. Instead, all classes and sections are to be delivered in-person. If you have time conflicts with lecture and/or section, please don’t take STAT 133 this semester.\n\nWill there be live webcast or recordings of lectures?  Unless Campus authorities decide to switch to remote instruction, there won’t be live webcast or live zoom recordings. With that said, lectures may be recorded for archival purposes, but not necessarily be shared with the class.\n\nDo you have a Covid (or other illness) policy?  Maintaining your health and that of the Berkeley community is of primary importance to course staff, so if you are feeling ill or have been exposed to illness, please do not come to class. All of the materials used in class will be posted either in this website or in bCourses. Likewise, you’re encouraged to reach out to fellow students to discuss the class materials or stop by office hours to chat with the GSI, the tutor, or the instructor.\nHaving said that, we expect you to attend lecture and lab. Past experience tells us that students who constantly miss lecture/lab tend to have a mediocre performance.\nAlso, missing lecture/lab does not give you the right to use OH as a replacement for receiving instruction. We are always willing to help you understand the learning materials during OH, but this also requires that you make an honest effort reviewing them before coming to OH.\n\nI am a concurrent student. What are my chances of enrolling in the class?  Depending on the size of the waitlist, and the available space in the labs, you may or may not have a chance to join the class. For example, there have been semesters in which only 10% of concurrent applications have been accepted. Likewise, there have been semesters in which 100% of concurrent applications have been accepted.\nKeep in mind that the approval process for concurrent enrollment students takes place between the 2nd and 3rd week of instruction, and it is a somewhat slow 2-step process, which takes some days, and it involves not only my intervention but also the participation of one of the advisors in the Dept. of Statistics.\n\nI am a grad student officially enrolled. Do you have a grading structure for grad students?  This semester we don’t have a special grading structure for graduate students. All students will be evaluated with the same criteria. See the course syllabus for more information about the grading structure.\n\nWhat if I join the class late?  If you join the class within the first two weeks, read the syllabus and lecture notes, take a look at bCourses to get a sense of any assignments that may have already passed, and visit office hours to check that you’re up to date with things.\nAfter two weeks into the semester, you’ll have too much material that you’ll need to make up, so you will have to wait to a subsequent semester to take STAT 133.\n\nAre time conflicts allowed?  STAT 133 does not allow students to enroll with time conflicts.\n\nI would like to switch lab sections with other student. Is this possible?  This is not possible. You should attend the lab section you are officially enrolled in.\n\nIs this course a good fit if I don’t have any programming experience?  Quick answer: yes. Because Stat 133 has no prerequisites, we actually expect that many of you come without any coding experience. It is nice to have some programming experience under your belt, which makes the learning curve less steep. Having said that, if this is your first time coding, you should expect to spend a great amount of time doing work outside class (and also deal with the inevitable frustration that comes when learning any language).\n\nIs this course a good fit if I don’t have any data analysis experience?  Yes. Because STAT 133 has no prerequisites, we actually expect that most of you come without any data analysis experience. In this course you will be working with a variety of fairly simple real data sets, as well as with simulated data.\n\nIs this course a good fit if I’ve already taken several programming courses?  You may find some parts of this course somewhat slow (and boring?) in terms of basics concepts such as data types, data structures, conditionals, loops, and functions. Unless Stat 133 is a required course for your major/minor (or you are eager to learn about R), please consider taking more advanced courses if what you are interested in is algorithms, computational statistics, databases, machine learning and statistical learning.\n\nIs this course a good fit if I don’t intend to major in Statistics?  STAT 133 is one of the core courses of the Statistics Major. The way I’ve been teaching this course is having Statistics majors as my target audience. However, much of the content should be helpful for any student who has to analyze data, or for those majors with some sort of data-analysis concentration.\n\nWhat if I want to declare Statistics as my major, but I already have taken other programming courses on Campus?  You may need to talk to a student advisor for more information about this. In 2019, students that took Data 100 (e.g. C100) “Principles & Techniques of Data Science”, were able to waive Stat 133 by just taking Stat 33B “Introduction to Advanced Programming in R”. Please contact your advisor to know if this option is still available.\n\nIs this course a good fit to become a data scientist?  Becoming a data scientist is not a (one-semester) sprint. It is a (years-long) marathon. Like any other profession, it takes many years of learning, practice, practice, practice, and then some practice, to become a proficient data scientist/analyst. This course can be very useful, and we are confident it will help you to build a good foundation in your DS career.\n\nWhat if I don’t want to be a data scientist?  That’s perfect too. You don’t need to be a data scientist aspirant to take this course. Whether your plans are to become a consultant, life scientist, social scientist, journalist, or get some analytic skills, this course should be a good choice.\n\nWhy is R (and not python) the main computational tool used in Stat 133?  Historically, STAT 133 has always been taught with R, and this semester is no exception. Personally, I believe that both R and python are great tools, and it is a good idea that you learn both of them (especially if you are interested in Data Science, analytics, etc). STAT 133 gives you the opportunity to learn a fair amount of R. Quoting Hadley Wickham:\n\n“Generally, there are a lot of people who talk about R versus Python like it’s a war that either R or Python is going to win. I think that is not helpful because it is not actually a battle. These things exist independently and are both awesome in different ways”.\n\nOn a side note, Ross Ihaka, one of the creators of R, obtained his PhD at UC Berkeley (in the Dept. of Statistics), so it is no coincidence that we are heavily influenced by R.\n\nAre we going to learn about machine learning methods?  The Statistics department offers a dedicated course on this topic: STAT 154: Modern Statistical Prediction and Machine Learning. There is also CS 189: Introduction to Machine Learning offered through Electrical Engineering and Computer Sciences (EECS). Similarly, DATA 100: Principles and Techniques of Data Science covers several machine learning concepts.\n\nAre we going to learn about databases?  If you are interested in Databases you should consider CS 186: Introduction to Database Systems offered through Electrical Engineering and Computer Sciences (EECS).\n\nAre we going to learn about linear models?  The Statistics department offers a dedicated course on this topic: STAT 151A: Linear Modeling, Theory and Applications.\n\nAre we going to learn about introductory statistics and/or probability?  The Statistics department offers two core courses on these topics: STAT 134: Concepts of Probability, and STAT 135: Concepts of Statistics.\n\nAre we going to learn about Reproducible Research (RR)?  We are just going to scratch the surface. We will touch on dynamic documents, and some practices and tools that are useful in RR.\n\nCan we work in groups?  Yes, absolutely. We strongly encourage you to not work alone. Well, let me rephrase that. You should try to first work on your own (trial and error). Take notes of the things you don’t understand. Then get with other people and discuss ideas, share tips (but not the entire solution).\n\nAren’t you suppose to teach us?  Yes. But you don’t learn programming by watching someone else program. The same way that you don’t learn to swim by simply watching someone else swimming. You have to get into the pool, and do all the drills your instructor says. This is a very hands-on course, and you will be required to do a great amount of work on your own.\n\nWhat if I don’t agree with all the course policies?  If there is one or more policies you don’t agree with, then please reconsider your enrollment in the course. I am assuming that all students completely agree with the course policies described in the Syllabus.\n\nCan I ask you to write me a Letter of Recommendation (LoR)?  Please take a look at this document before asking me to write you a letter of recommendation: https://github.com/gastonstat/letter-of-rec.\n\nI invited you to join my network in LinkedIn. Why haven’t you accepted my invitation?  First: Don’t take it personal. It’s not you, it’s me. Second: if you really want that I become part of your network, why don’t you talk to me in person? We can meet in OH, or you can also schedule a meeting at a different time. Let me know you better than just as a distant contact in a social media networking site.\n\nDo you have research projects open to undergrad students?  Lecturing takes most of my time and I don’t have a lab. Sometimes, however, I may look for collaborators to create some data-based project. This typically happens in the Summer.",
    "crumbs": [
      "FAQs"
    ]
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html",
    "title": "Correspondence Analysis 1",
    "section": "",
    "text": "This is a companion file to the Stat 133 lectures on “Text Mining”. You’ll need the following packages:\n# used packages\nlibrary(tidyverse)    # base tidy data tools\nlibrary(tidytext)     # text mining; gets along with tidyverse\nlibrary(janeaustenr)  # Jane Austen's novels\nlibrary(FactoMineR)   # Multivariate Statistics methods"
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html#jane-austens-novels",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html#jane-austens-novels",
    "title": "Correspondence Analysis 1",
    "section": "1 Jane Austen’s Novels",
    "text": "1 Jane Austen’s Novels\nAs you know, the package \"janeaustenr\" contains the six novels by Jane Austen:\n\nEmma\n\nMansfield Park\n\nNorthanger Abbey\n\nPersuasion\n\nPride and Prejudice\n\nSense and Sensibility\n\nThe text of each novel is available in vector format: e.g. prideprejudice, emma, persuasion. But you can also find the text of all six novels in a single data frame (tibble) by using the function austen_books()\n\nausten_books()"
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html#detecting-associations-with-correspondence-analysis-ca",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html#detecting-associations-with-correspondence-analysis-ca",
    "title": "Correspondence Analysis 1",
    "section": "2 Detecting Associations with Correspondence Analysis (CA)",
    "text": "2 Detecting Associations with Correspondence Analysis (CA)\nSay we are interested in studying the use of punctuation symbols across all Austen’s novels:\n\ncommas: \",\"\nsemicolons: \";\"\ncolons: \":\"\nquotations: '\\\\\"'\napostrophes: \"'\"\nquestion marks: \"?\"\nexclamation symbols: \"!\"\ndashes (pairs): \"--\"\n\nWe can use str_count() to count the frequencies of these types of symbols, and then get the their total sum for each book:\n\ncrosstable = austen_books() |&gt;\n  mutate(\n    commas = str_count(text, \",\"),\n    colons = str_count(text, \":\"),\n    semicolons = str_count(text, \";\"),\n    quotes = str_count(text, '\\\\\"'),\n    apostrophes = str_count(text, \"'\"),\n    questions = str_count(text, \"\\\\?\"),\n    exclamations = str_count(text, \"\\\\!\"),\n    dashes = str_count(text, \"--\")\n  ) |&gt;\n  group_by(book) |&gt;\n  summarise(\n    commas = sum(commas),\n    colons = sum(colons),\n    semis = sum(semicolons),\n    quotes = sum(quotes),\n    aposts = sum(apostrophes),\n    quests = sum(questions),\n    bangs = sum(exclamations),\n    dashes = sum(dashes)\n  )\n\ncrosstable\n\n# A tibble: 6 × 9\n  book                commas colons semis quotes aposts quests bangs dashes\n  &lt;fct&gt;                &lt;int&gt;  &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n1 Sense & Sensibility   9900     66  1572   3084    914    451   561   1178\n2 Pride & Prejudice     9132    132  1538   3531    741    462   499    395\n3 Mansfield Park       12439    339  2260   3292   1135    471   496    413\n4 Emma                 12020    174  2353   4189   1226    621  1063   3100\n5 Northanger Abbey      6085     83  1172   2151    545    392   433    419\n6 Persuasion            7025    130  1320   1565    582    217   318    142\n\n\nThe above table, technically speaking, is an example of a cross-table, also referred to as a 2-way table or a contingency table. The important thing about this table is that it contains counts, which in turn are non-negative numbers.\nFrom a statistical point of view, this table is the result of crossing the categories of 2 qualitative (i.e. categorical) variables:\n\nVariable \\(V_1\\): name of book or novel\nVariable \\(V_2\\): type of punctuation symbol\n\n\n\n\nCross-table from 2 categorical variables\n\n\nWith this kind of table, we could ask questions like:\n\nIs there an association between books and punctuation symbols?\nDo some books tend to have more (or less) of a certain punctuation symbol?\n\nTo answer this kind of questions, we can use a statistical multivariate method known as Correspondence Analysis (CA).\nOriginally, CA was developed to analyze contingency tables in which a sample of observations is described by two nominal variables, but it was rapidly extended to the analysis of any data table with non-negative entries.\nOn a side note, we should mention that CA was often discovered (and rediscovered), and so variations of CA can be found under several different names such as “dual scaling,” “optimal scaling,” “homogeneity analysis,” or “reciprocal averaging.” The multiple identities of correspondence analysis are a consequence of its large number of properties, that answer a lot of apparently different problems."
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html#table-of-relative-frequencies",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html#table-of-relative-frequencies",
    "title": "Correspondence Analysis 1",
    "section": "3 Table of relative frequencies",
    "text": "3 Table of relative frequencies\nIn order to explain Correspondence Analysis, and also to simplify some of the computations on the data in crosstable, it’s better if we reformat this object as a matrix:\n\n# cross-table in matrix format\nX = as.matrix(crosstable[,-1])\nrownames(X) = str_extract(crosstable$book, \"\\\\w+\")\n\nX\n\n           commas colons semis quotes aposts quests bangs dashes\nSense        9900     66  1572   3084    914    451   561   1178\nPride        9132    132  1538   3531    741    462   499    395\nMansfield   12439    339  2260   3292   1135    471   496    413\nEmma        12020    174  2353   4189   1226    621  1063   3100\nNorthanger   6085     83  1172   2151    545    392   433    419\nPersuasion   7025    130  1320   1565    582    217   318    142\n\n\n\n\n\nCross-table from 2 categorical variables\n\n\n\n3.1 Relative Frequencies or Probabilities\nThe first step involves converting the frequencies or counts in X into relative frequencies (i.e. proportions) by dividing the cells in X over the total count of punctuation symbols:\n\nXprobs = X / sum(X)\nround(Xprobs, 4)\n\n           commas colons  semis quotes aposts quests  bangs dashes\nSense      0.0967 0.0006 0.0154 0.0301 0.0089 0.0044 0.0055 0.0115\nPride      0.0892 0.0013 0.0150 0.0345 0.0072 0.0045 0.0049 0.0039\nMansfield  0.1216 0.0033 0.0221 0.0322 0.0111 0.0046 0.0048 0.0040\nEmma       0.1175 0.0017 0.0230 0.0409 0.0120 0.0061 0.0104 0.0303\nNorthanger 0.0595 0.0008 0.0115 0.0210 0.0053 0.0038 0.0042 0.0041\nPersuasion 0.0687 0.0013 0.0129 0.0153 0.0057 0.0021 0.0031 0.0014\n\n\nYou can think of the proportions in Xprobs as joint probabilities. For instance, the probability of Sense and Sensibility AND commas is about 0.0967\n\\[\nProb(V_1 = \\text{Sense} \\ \\text{ AND } \\ V_2 = \\text{commas}) \\approx 0.0967\n\\]\nThe following diagram illustrates a table of probabilities derived from the cross-table between two variables \\(V_1\\) and \\(V_2\\). The relative frequency between the \\(i\\)-th category of \\(V_1\\) and the \\(j\\)-th category of \\(V_2\\) is denoted as \\(f_{ij}\\)\n\\[\nf_{ij} = \\frac{x_{ij}}{n}\n\\]\n\n\n\n\n\n\n\n3.2 Marginal Probabilities\nFrom the table of probabilities \\(f_{ij}\\), we can calculate marginal probabilities.\n\n\n\n\n\nColumn Margin. The column margin, depicted in blue in the preceding figure, with its \\(j\\)-th term denoted as \\(f_{.j}\\) is given by the sum of all the entries in each column, column by column:\n\\[\nf_{.j} = \\sum_{i=1}^{I} f_{ij}\n\\]\nThese marginal probabilities can be easily obtained with colSums()\n\n# column margin\ncol_margin = colSums(Xprobs)\nround(col_margin, 4)\n\ncommas colons  semis quotes aposts quests  bangs dashes \n0.5531 0.0090 0.0998 0.1741 0.0503 0.0255 0.0329 0.0552 \n\n\nThink of this proportions as marginal probabilities:\n\\[\nProb(V_2 = \\text{commas}) \\approx 0.5531\n\\]\n\nRow Margin. The row margin, depicted in red in the preceding figure, with its \\(i\\)-th term denoted as \\(f_{i.}\\) is given by the sum of all the entries in each row, row by row:\n\\[\nf_{i.} = \\sum_{j=1}^{J} f_{ij}\n\\]\nThese marginal probabilities can be easily obtained with rowSums()\n\n# row margin\nrow_margin = rowSums(Xprobs)\nround(row_margin, 4)\n\n     Sense      Pride  Mansfield       Emma Northanger Persuasion \n    0.1732     0.1606     0.2037     0.2418     0.1102     0.1104 \n\n\nThink of this proportions as marginal probabilities:\n\\[\nProb(V_1 = \\text{Sense}) \\approx 0.1732\n\\]"
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html#independence-model",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html#independence-model",
    "title": "Correspondence Analysis 1",
    "section": "4 Independence Model",
    "text": "4 Independence Model\nLet’s review the kind of probabilities that we have so far:\n\njoint probabilities: \\(f_{ij}\\)\nmarginal probability of rows: \\(f_{i.}\\)\nmarginal probability of columns: \\(f_{.j}\\)\n\nFrom basic probability rules, we know that if two events \\(A\\) and \\(B\\) are independent, their joint probability \\(P(A \\text{ and } B)\\) is given by the product of the marginal probabilities, that is:\n\\[\nP(A \\text{ and } B) = P(A) \\times P(B)\n\\]\nIn other words, if the \\(i\\)-th row is independent from the \\(j\\)-th column, the joint probability \\(f_{ij}\\) is given by\n\\[\nf_{ij} = f_{i.} \\times f_{.j}\n\\]\n\n4.1 Relative Frequencies under Independence\nWhat if the categories of \\(V_1\\) are independent from the categories in \\(V_2\\)? In other words, what would the joint probabilities should like if there was no association between the books and the punctuation symbols? Well, if this was the case then the table of joint probabilities should be approximately:\n\n# under independence\nXindep = row_margin %o% col_margin\nround(Xindep, 4)\n\n           commas colons  semis quotes aposts quests  bangs dashes\nSense      0.0958 0.0016 0.0173 0.0302 0.0087 0.0044 0.0057 0.0096\nPride      0.0888 0.0014 0.0160 0.0279 0.0081 0.0041 0.0053 0.0089\nMansfield  0.1127 0.0018 0.0203 0.0355 0.0102 0.0052 0.0067 0.0112\nEmma       0.1338 0.0022 0.0241 0.0421 0.0122 0.0062 0.0080 0.0133\nNorthanger 0.0610 0.0010 0.0110 0.0192 0.0055 0.0028 0.0036 0.0061\nPersuasion 0.0611 0.0010 0.0110 0.0192 0.0055 0.0028 0.0036 0.0061\n\n\nTo visualize the joint probability distributions under the assumption of independence, we can make a mosaicplot like the following one.\n\nmosaicplot(t(Xindep), las = 1, border = NA, main = \"Independence Model\")\n\n\n\n\n\n\n\n\nThe independence model stipulates that the joint probability \\(f_{ij}\\) is dependent on the marginal probabilities \\(f_{i.}\\) and \\(f_{.j}\\) alone.\nStudying the association between two categorical variables requires us to position the data in terms of a given starting point: in this case the absence of a relationship given by the independence model. The more a given joint probability \\(f_{ij}\\) departures from the expected probability \\(f_{i.} \\times f_{.j}\\) under independence, the stronger the association will between the “events” \\(i\\)-th and \\(j\\)-th. This is one of the core ideas behind Correspondence Analysis."
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html#row-analysis",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html#row-analysis",
    "title": "Correspondence Analysis 1",
    "section": "5 Row Analysis",
    "text": "5 Row Analysis\nUsing the table of probabilities (Xprobs), we can divide its entries \\(f_{ij}\\) by the row margin \\(f_{i.}\\) (i.e. marginal probabilities of books)\n\n\n\n\n\n\n# row profiles (i.e. conditional probabilities on books)\nrow_profiles = sweep(Xprobs, MARGIN = 1, STATS = row_margin, FUN = \"/\")\nround(row_profiles, 4)\n\n           commas colons  semis quotes aposts quests  bangs dashes\nSense      0.5585 0.0037 0.0887 0.1740 0.0516 0.0254 0.0316 0.0665\nPride      0.5558 0.0080 0.0936 0.2149 0.0451 0.0281 0.0304 0.0240\nMansfield  0.5967 0.0163 0.1084 0.1579 0.0544 0.0226 0.0238 0.0198\nEmma       0.4857 0.0070 0.0951 0.1693 0.0495 0.0251 0.0430 0.1253\nNorthanger 0.5395 0.0074 0.1039 0.1907 0.0483 0.0348 0.0384 0.0371\nPersuasion 0.6217 0.0115 0.1168 0.1385 0.0515 0.0192 0.0281 0.0126\n\n\nThe entries in this table are basically conditional probabilities:\n\\[\nProb(V_2 = \\text{commas} \\ | \\ V_1 = \\text{Sense}) = 0.5585\n\\]\nA property of this table is that its row-sums are equal to 1:\n\nrowSums(row_profiles)\n\n     Sense      Pride  Mansfield       Emma Northanger Persuasion \n         1          1          1          1          1          1 \n\n\n\nAverage Book profile: We can take into account the average book profile given by the marginal probabilities in col_margin\n\nRows = rbind(row_profiles, average = col_margin)\nround(Rows, 4)\n\n           commas colons  semis quotes aposts quests  bangs dashes\nSense      0.5585 0.0037 0.0887 0.1740 0.0516 0.0254 0.0316 0.0665\nPride      0.5558 0.0080 0.0936 0.2149 0.0451 0.0281 0.0304 0.0240\nMansfield  0.5967 0.0163 0.1084 0.1579 0.0544 0.0226 0.0238 0.0198\nEmma       0.4857 0.0070 0.0951 0.1693 0.0495 0.0251 0.0430 0.1253\nNorthanger 0.5395 0.0074 0.1039 0.1907 0.0483 0.0348 0.0384 0.0371\nPersuasion 0.6217 0.0115 0.1168 0.1385 0.0515 0.0192 0.0281 0.0126\naverage    0.5531 0.0090 0.0998 0.1741 0.0503 0.0255 0.0329 0.0552\n\n\nUnder the assumption of independence (i.e. no association between \\(i\\)-th category and \\(j\\)-th category), the conditional probabilities \\(f_{ij}/f_{i.}\\) should be close to the marginal probabilities \\(f_{.j}\\):\n\\[\n\\frac{f_{ij}}{f_{i.}} = f_{.j}\n\\]\nThe more associated \\(i\\)-th and \\(j\\)-th are, the bigger the discrepancy between \\(f_{ij}/f_{i.}\\) and \\(f_{.j}\\).\nOne way to visualize departure from independence is with a mosaicplot of the above table of conditional probabilities or row profiles (see below). Notice that we are also including the marginal probabilities of col_margin which is the average book profile.\n\nmosaicplot(\n  t(Rows),\n  las = 1, \n  border = NA, \n  col = rainbow(ncol(Rows)), \n  main = \"Row Profiles\")\n\n\n\n\n\n\n\n\nFrom this picture, we can immediately tell that:\n\nCommas \",\" are the most used punctuation symbol; also the use of commas seems to be evenly distributed across all books.\nIn contrast, colons \":\" are the least used symbol; notice that Mansfield has the largest proportion of colons.\nSemicolons \";\" also seem to be evenly distributed across all books, although not as much as commas.\nDashes \"--\" exhibit the largest amount of variability across different books; Persuasion being the book with the least amount of dashes, whereas Emma is the novel with most dashes (compared to other books)."
  },
  {
    "objectID": "docs/tm-correspondence/text-mining-corresp-analysis1.html#column-analysis",
    "href": "docs/tm-correspondence/text-mining-corresp-analysis1.html#column-analysis",
    "title": "Correspondence Analysis 1",
    "section": "6 Column Analysis",
    "text": "6 Column Analysis\nWe can repeat the same analysis of the preceding section but this time applied on the columns of the probability table. This time we divide the entries \\(f_{ij}\\) by the column margin \\(f_{.j}\\) (i.e. marginal probabilities of symbols)\n\n\n\n\n\n\n# column profiles (i.e. conditional probabilities on symbols)\ncol_profiles = sweep(Xprobs, MARGIN = 2, STATS = col_margin, FUN = \"/\")\nround(col_profiles, 4)\n\n           commas colons  semis quotes aposts quests  bangs dashes\nSense      0.1749 0.0714 0.1539 0.1731 0.1777 0.1725 0.1665 0.2086\nPride      0.1613 0.1429 0.1506 0.1982 0.1441 0.1767 0.1481 0.0699\nMansfield  0.2198 0.3669 0.2212 0.1848 0.2207 0.1802 0.1472 0.0731\nEmma       0.2124 0.1883 0.2303 0.2352 0.2384 0.2376 0.3154 0.5490\nNorthanger 0.1075 0.0898 0.1147 0.1208 0.1060 0.1500 0.1285 0.0742\nPersuasion 0.1241 0.1407 0.1292 0.0879 0.1132 0.0830 0.0944 0.0251\n\n\n\nAverage Symbol profile: We can take into account the average symbol profile given by the marginal probabilities in row_margin\n\n# adding average column profile\nCols = cbind(col_profiles, average = row_margin)\nround(Cols, 4)\n\n           commas colons  semis quotes aposts quests  bangs dashes average\nSense      0.1749 0.0714 0.1539 0.1731 0.1777 0.1725 0.1665 0.2086  0.1732\nPride      0.1613 0.1429 0.1506 0.1982 0.1441 0.1767 0.1481 0.0699  0.1606\nMansfield  0.2198 0.3669 0.2212 0.1848 0.2207 0.1802 0.1472 0.0731  0.2037\nEmma       0.2124 0.1883 0.2303 0.2352 0.2384 0.2376 0.3154 0.5490  0.2418\nNorthanger 0.1075 0.0898 0.1147 0.1208 0.1060 0.1500 0.1285 0.0742  0.1102\nPersuasion 0.1241 0.1407 0.1292 0.0879 0.1132 0.0830 0.0944 0.0251  0.1104\n\n\nSimilarly, we can get a mosaicplot to visualize the distribution of these conditional probabilities. Notice that we are also including the marginal probabilities of row_margin which is the average symbol profile.\n\nmosaicplot(\n  t(Cols),\n  las = 1, \n  border = NA, \n  col = rainbow(nrow(Cols)), \n  main = \"Column Profiles\")\n\n\n\n\n\n\n\n\nFrom this mosaicplot we can see that:\n\nCommas and semicolons have similar distributions.\nSimilarly, quotes and question marks also have similar distributions.\nCommas have the closest distribution to the average profile.\nCompared to average profile, colons and dashes are the symbols that deviate the most from the average profile.\nAs we have previously detected, Emma is the book that has the largest proportion of dashes; in contrast Persuasion has the least proportion of dashes.\nAlso, Mansfield has the largest proportion of colons."
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#leaflet-web-interactive-maps",
    "href": "docs/maps-storms/storms-slides2.html#leaflet-web-interactive-maps",
    "title": "North Atlantic Storms",
    "section": "Leaflet: Web Interactive Maps",
    "text": "Leaflet: Web Interactive Maps"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#leaflet",
    "href": "docs/maps-storms/storms-slides2.html#leaflet",
    "title": "North Atlantic Storms",
    "section": "Leaflet",
    "text": "Leaflet\nLeaflet is a JavaScript library used to build interactive maps for websites and web mapping applications.\n\nThe R package \"leaflet\" lets you create and customize Leaflet maps in R.\n\n\nThese maps can be used directly from the R console, from RStudio, in Markdown documents (e.g. qmd, Rmd), and in Shiny applications."
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#basic-usage",
    "href": "docs/maps-storms/storms-slides2.html#basic-usage",
    "title": "North Atlantic Storms",
    "section": "Basic Usage",
    "text": "Basic Usage\nYou create a Leaflet map with these basic steps:\n\nCreate a map widget by calling leaflet().\nAdd layers (i.e. features) to the map by using layer functions (e.g.  addTiles, addMarkers, addPolygons) to modify the map widget.\nRepeat step 2 as desired.\nPrint the map widget to display it."
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#leaflet-basic-example",
    "href": "docs/maps-storms/storms-slides2.html#leaflet-basic-example",
    "title": "North Atlantic Storms",
    "section": "Leaflet: Basic Example",
    "text": "Leaflet: Basic Example\n\n\nView Code\n# view with marker at UC Berkeley\nleaflet() |&gt;\n  addTiles() |&gt; # default OpenStreetMap map tiles\n  addMarkers(lng = -122.2579, lat = 37.8718, popup = \"Berkeley\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#basic-example-map-and-marker",
    "href": "docs/maps-storms/storms-slides2.html#basic-example-map-and-marker",
    "title": "North Atlantic Storms",
    "section": "Basic Example: Map and Marker",
    "text": "Basic Example: Map and Marker\n\n\nView Code\n# view with marker at Berkeley, CA\nleaflet() |&gt;\n  addTiles() |&gt;\n  setView(lng = -122, lat = 38, zoom = 8) |&gt;\n  addMarkers(lng = -122.27, lat = 37.87, popup = \"Berkeley\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#basic-example-map-and-marker-contd",
    "href": "docs/maps-storms/storms-slides2.html#basic-example-map-and-marker-contd",
    "title": "North Atlantic Storms",
    "section": "Basic Example: Map and Marker (cont’d)",
    "text": "Basic Example: Map and Marker (cont’d)\n\n\nView Code\n# view with marker at Berkeley, CA\nleaflet() |&gt;\n  addTiles() |&gt;\n  setView(lng = -100, lat = 37, zoom = 4) |&gt;\n  addMarkers(lng = -122.27, lat = 37.87, popup = \"Berkeley\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#map-tiles",
    "href": "docs/maps-storms/storms-slides2.html#map-tiles",
    "title": "North Atlantic Storms",
    "section": "Map Tiles",
    "text": "Map Tiles\nLeaflet uses map tiles from:\n\nOpenStreetMap (OSM): https://www.openstreetmap.org/\n\nOSM is simply the database with all the data in xml-vector format.\n\nCartoDB: https://carto.com/basemaps/"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#adding-data-objects",
    "href": "docs/maps-storms/storms-slides2.html#adding-data-objects",
    "title": "North Atlantic Storms",
    "section": "Adding Data Objects",
    "text": "Adding Data Objects\nBoth leaflet() and the map layer functions have an optional data parameter that is designed to receive spatial data in one of several forms:\n\nFrom base R:\n\nlng/lat matrix\ndata frame with lng/lat columns\n\nFrom the \"sf\" package:\n\nthe data frame of class \"sf\"\n\nFrom the \"maps\" package\n\nthe data frame from returned from map()"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#example-adding-sf-data-polygons",
    "href": "docs/maps-storms/storms-slides2.html#example-adding-sf-data-polygons",
    "title": "North Atlantic Storms",
    "section": "Example: adding \"sf\" data polygons",
    "text": "Example: adding \"sf\" data polygons"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#leaflet-maps",
    "href": "docs/maps-storms/storms-slides2.html#leaflet-maps",
    "title": "North Atlantic Storms",
    "section": "Leaflet Maps",
    "text": "Leaflet Maps\n\n\nView Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\nleaflet() |&gt;\n  setView(lng = -50, lat = 30, zoom = 3) |&gt;\n  addTiles() |&gt;\n  addProviderTiles(provider = \"NASAGIBS.ViirsEarthAtNight2012\") |&gt;\n  addCircleMarkers(\n    lng = ~long, \n    lat = ~lat,\n    radius = 1, \n    color = \"#DDFF03\")"
  },
  {
    "objectID": "docs/maps-storms/storms-slides2.html#leaflet-maps-1",
    "href": "docs/maps-storms/storms-slides2.html#leaflet-maps-1",
    "title": "North Atlantic Storms",
    "section": "Leaflet Maps",
    "text": "Leaflet Maps\n\n\nView Code\nstorms |&gt;\n  filter(year == 1975) |&gt;\nleaflet() |&gt;\n  setView(lng = -50, lat = 30, zoom = 3) |&gt;\n  addTiles() |&gt;\n  addProviderTiles(provider = \"NASAGIBS.ViirsEarthAtNight2012\") |&gt;\n  addCircleMarkers(\n    lng = ~long, \n    lat = ~lat,\n    radius = 1, \n    color = \"#DDFF03\", \n    weight = ~wind/5)\n\n\n\n\n\n\n\n\n\nReturn to Home Page"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#about",
    "href": "docs/api-open-notify/open-notify-slides.html#about",
    "title": "Open Notify API",
    "section": "About",
    "text": "About\nIn these slides we describe an example to get data from an API with R."
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#required-packages",
    "href": "docs/api-open-notify/open-notify-slides.html#required-packages",
    "title": "Open Notify API",
    "section": "Required Packages",
    "text": "Required Packages\nThe content in these slides depend on the following packages:\n\nlibrary(tidyverse)   # data wrangling and graphics\n\nlibrary(leaflet)     # for working with geospatial vector-data\n\nlibrary(httr)        # for HTTP requests\n\nlibrary(jsonlite)    # for working with JSON data"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#open-notify-api-httpopen-notify.org",
    "href": "docs/api-open-notify/open-notify-slides.html#open-notify-api-httpopen-notify.org",
    "title": "Open Notify API",
    "section": "Open Notify API http://open-notify.org/",
    "text": "Open Notify API http://open-notify.org/"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#about-open-notify",
    "href": "docs/api-open-notify/open-notify-slides.html#about-open-notify",
    "title": "Open Notify API",
    "section": "About Open Notify",
    "text": "About Open Notify\nOpen Notify is an open source project to provide a simple programming interface (API) for some of NASA’s data.\nThis API is developed and maintained by Nathan Bergey.\nhttp://open-notify.org/about"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#open-notify-api-current-iss-location",
    "href": "docs/api-open-notify/open-notify-slides.html#open-notify-api-current-iss-location",
    "title": "Open Notify API",
    "section": "Open Notify API: Current ISS Location",
    "text": "Open Notify API: Current ISS Location"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#open-notify-api-current-iss-location-1",
    "href": "docs/api-open-notify/open-notify-slides.html#open-notify-api-current-iss-location-1",
    "title": "Open Notify API",
    "section": "Open Notify API: Current ISS Location",
    "text": "Open Notify API: Current ISS Location"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#current-iss-location",
    "href": "docs/api-open-notify/open-notify-slides.html#current-iss-location",
    "title": "Open Notify API",
    "section": "Current ISS Location",
    "text": "Current ISS Location\nURL:\nhttp://api.open-notify.org/iss-now.json\n\nReturned ISS Location 1 data in JSON format:\n{\"iss_position\": {\"longitude\": \"-58.8531\", \"latitude\": \"-28.5444\"}, \"message\": \"success\", \"timestamp\": 1699732761}\n\ntimestamp is the number of seconds since Jan-01-1970 (UTC)\nKeep in mind that the current location will be different."
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-1",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-1",
    "title": "Open Notify API",
    "section": "Getting Data in R: Approach 1",
    "text": "Getting Data in R: Approach 1\nA simple approach to get the location of the ISS is to use readLines() to import the data—returned by the URL—in R.\nBecause the data is in JSON format, we then use from JSON() to convert it into an R list:\n\niss_loc_url = \"http://api.open-notify.org/iss-now.json\"\n\niss_loc_json = readLines(iss_loc_url)\n\niss_loc_list = fromJSON(iss_loc_json)\n\n\nA much simpler approach is to overpass readLines():\n\niss_loc_url = \"http://api.open-notify.org/iss-now.json\"\n\niss_loc_list = fromJSON(iss_loc_url)"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-1-contd",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-1-contd",
    "title": "Open Notify API",
    "section": "Getting Data in R: Approach 1 (cont’d)",
    "text": "Getting Data in R: Approach 1 (cont’d)\n\niss_loc_url = \"http://api.open-notify.org/iss-now.json\"\n\niss_loc_json = readLines(iss_loc_url)\n\niss_loc_list = fromJSON(iss_loc_json)\n\niss_loc_list\n\n\n\n$iss_position\n$iss_position$longitude\n[1] \"-58.8531\"\n\n$iss_position$latitude\n[1] \"-28.5444\"\n\n\n$message\n[1] \"success\"\n\n$timestamp\n[1] 1699732761"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#map-with-leaflet",
    "href": "docs/api-open-notify/open-notify-slides.html#map-with-leaflet",
    "title": "Open Notify API",
    "section": "Map with \"leaflet\"",
    "text": "Map with \"leaflet\"\n\n\nView Plot Code\niss_loc_dat = data.frame(\n  lng = as.numeric(iss_loc_list$iss_position$longitude),\n  lat = as.numeric(iss_loc_list$iss_position$latitude)\n)\n\nleaflet(data = iss_loc_dat) |&gt;\n  addTiles() |&gt;\n  addCircleMarkers(\n    radius = 50,\n    stroke = FALSE, \n    fillOpacity = 0.3) |&gt;\n  addMarkers() |&gt;\n  setView(lng = iss_loc_dat$lng, lat = iss_loc_dat$lat, zoom = 3)"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#map-with-leaflet-adding-icon-of-iss",
    "href": "docs/api-open-notify/open-notify-slides.html#map-with-leaflet-adding-icon-of-iss",
    "title": "Open Notify API",
    "section": "Map with \"leaflet\", adding icon of ISS",
    "text": "Map with \"leaflet\", adding icon of ISS\n\n\nView Plot Code\n# url of ISS icon from Wikimedia Commons (png file)\nwikimedia = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/\"\niss = \"International_Space_Station.svg/\"\npng = \"320px-International_Space_Station.svg.png\"\niss_icon = paste0(wikimedia, iss, png)\n\n# define icon properties\nissIcon &lt;- makeIcon(\n  iconUrl = iss_icon,\n  iconWidth = 100,\n  iconHeight = 70,\n  iconAnchorX = 50,\n  iconAnchorY = 35)\n\n# leaflet map\nleaflet(data = iss_loc_dat) |&gt;\n  addTiles() |&gt;\n  addCircleMarkers(\n    lng = ~lng, \n    lat = ~lat,\n    radius = 70,\n    stroke = FALSE, \n    fillOpacity = 0.3) |&gt;\n  addMarkers(\n    lng = ~lng, \n    lat = ~lat, \n    icon = issIcon) |&gt; \n  setView(lng = iss_loc_dat$lng, lat = iss_loc_dat$lat, zoom = 2)"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-2",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-2",
    "title": "Open Notify API",
    "section": "Getting Data in R: Approach 2",
    "text": "Getting Data in R: Approach 2\nAnother approach to get the location of the ISS is to:\n\nmake an HTTP request with GET()\nextract the content from the request object\n\n\nres = GET(\"http://api.open-notify.org/iss-now.json\")\nres\n\nResponse [https://api.open-notify.org/astros.json]\n  Date: 2023-11-11 20:51\n  Status: 200\n  Content-Type: application/json\n  Size: 113 B\n\nnames(res)\n\n[1] \"url\"         \"status_code\" \"headers\"     \"all_headers\" \"cookies\"    \n[6] \"content\"     \"date\"        \"times\"       \"request\"     \"handle\""
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-2-contd",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-2-contd",
    "title": "Open Notify API",
    "section": "Getting Data in R: Approach 2 (cont’d)",
    "text": "Getting Data in R: Approach 2 (cont’d)\n\n# res$content is a \"raw\" vector (i.e. binary data format)\nres$content\n\n  [1] 7b 22 69 73 73 5f 70 6f 73 69 74 69 6f 6e 22 3a 20 7b 22 6c\n [21] 61 74 69 74 75 64 65 22 3a 20 22 2d 31 32 2e 36 36 30 38 22\n [41] 2c 20 22 6c 6f 6e 67 69 74 75 64 65 22 3a 20 22 2d 39 2e 35\n [61] 30 37 33 22 7d 2c 20 22 6d 65 73 73 61 67 65 22 3a 20 22 73\n [81] 75 63 63 65 73 73 22 2c 20 22 74 69 6d 65 73 74 61 6d 70 22\n[101] 3a 20 31 36 39 39 38 39 34 37 31 32 7d\n\n\n# convert to character type\nrawToChar(res$content)\n\n[1] \"{\\\"iss_position\\\": {\\\"latitude\\\": \\\"-28.5444\\\", \\\"longitude\\\": \\\"-58.8531\\\"}, \\\"message\\\": \\\"success\\\", \\\"timestamp\\\": 1699732761}\""
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-2-contd-1",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-in-r-approach-2-contd-1",
    "title": "Open Notify API",
    "section": "Getting Data in R: Approach 2 (cont’d)",
    "text": "Getting Data in R: Approach 2 (cont’d)\n\niss_loc_list = fromJSON(rawToChar(res$content))\n\niss_loc_list\n\n\n\n$iss_position\n$iss_position$longitude\n[1] \"-58.8531\"\n\n$iss_position$latitude\n[1] \"-28.5444\"\n\n\n$message\n[1] \"success\"\n\n$timestamp\n[1] 1699732761"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#people-in-space-1",
    "href": "docs/api-open-notify/open-notify-slides.html#people-in-space-1",
    "title": "Open Notify API",
    "section": "People in Space",
    "text": "People in Space\nURL:\nhttp://api.open-notify.org/astros.json\n\nReturned number of people 1 in JSON format:\n{\"message\": \"success\", \"people\": [{\"name\": \"Jasmin Moghbeli\", \"craft\": \"ISS\"}, {\"name\": \"Andreas Mogensen\", \"craft\": \"ISS\"}, {\"name\": \"Satoshi Furukawa\", \"craft\": \"ISS\"}, {\"name\": \"Konstantin Borisov\", \"craft\": \"ISS\"}, {\"name\": \"Oleg Kononenko\", \"craft\": \"ISS\"}, {\"name\": \"Nikolai Chub\", \"craft\": \"ISS\"}, {\"name\": \"Loral O'Hara\", \"craft\": \"ISS\"}], \"number\": 7}\nKeep in mind that the current astronauts will be different."
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-with-get-request",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-with-get-request",
    "title": "Open Notify API",
    "section": "Getting Data with GET request",
    "text": "Getting Data with GET request\n\nres = GET(\"http://api.open-notify.org/astros.json\")\n\nres\n\nResponse [https://api.open-notify.org/astros.json]\n  Date: 2023-11-11 20:52\n  Status: 200\n  Content-Type: application/json\n  Size: 360 B"
  },
  {
    "objectID": "docs/api-open-notify/open-notify-slides.html#getting-data-with-get-request-contd",
    "href": "docs/api-open-notify/open-notify-slides.html#getting-data-with-get-request-contd",
    "title": "Open Notify API",
    "section": "Getting Data with GET request (cont’d)",
    "text": "Getting Data with GET request (cont’d)\n\niss_astros_list = fromJSON(rawToChar(res$content))\n\niss_astros_list\n\n\n\n$message\n[1] \"success\"\n\n$people\n                name craft\n1    Jasmin Moghbeli   ISS\n2   Andreas Mogensen   ISS\n3   Satoshi Furukawa   ISS\n4 Konstantin Borisov   ISS\n5     Oleg Kononenko   ISS\n6       Nikolai Chub   ISS\n7       Loral O'Hara   ISS\n\n$number\n[1] 7\n\n\n\n\n\nReturn to Home Page"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics 133: Concepts in Computing with Data",
    "section": "",
    "text": "bCourses\n\n  Ed\n\n  R-DataHub\n\n\nNo matching items",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#announcement",
    "href": "index.html#announcement",
    "title": "Statistics 133: Concepts in Computing with Data",
    "section": "Announcement",
    "text": "Announcement\nLecture notes contributed by students are now available in Contributions",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Statistics 133: Concepts in Computing with Data",
    "section": "Schedule",
    "text": "Schedule\nTentative calendar subject to change.\n\n\n   Week 1\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 1: Introduction\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Aug 28\n             \n             \n               Lecture  Welcome to Stat 133 (slides)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Aug 29\n             \n             \n               Labwork  Lab 1: Intro to R and RStudio\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Aug 30\n             \n             \n               Lecture  Vectors, part 1 (notes)\n             \n             \n               Slides\n              \n             \n               Demo\n              \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  Vectors, part 2 (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 2\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 2: R Vectors\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 2\n             \n             \n               Lecture  No class (Labor day)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 4\n             \n             \n               Lecture  Vectors, part 3 (notes)\n             \n             \n               Slides\n              \n             \n               Demo\n              \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  Vectors, part 4 (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 5\n             \n             \n               Labwork  Lab 2: Vectors  (due 9/06)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 6\n             \n             \n               Shiny  Shiny Friday: Old Faithful (default app)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  HW 1: Vectors (avail 9/07, due 9/13)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 3\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 3: R Matrices and Lists\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 9\n             \n             \n               Lecture  Matrices, part 1 (notes)\n             \n             \n               Slides\n              \n             \n               Demo\n              \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  Matrices, part 2 (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 11\n             \n             \n               Lecture  Lists (notes)\n             \n             \n               Slides\n              \n             \n               Demo\n              \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 12\n             \n             \n               Labwork  Lab 3: Lists and Matrices (due 9/13)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 13\n             \n             \n               Shiny  Shiny Friday: Future Value\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  HW 2: Lists & Matrices (avail 9/14, due 9/20)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 4\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 4: Simple Functions and Conditionals\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 16\n             \n             \n               Lecture  Intro to Functions (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  R Compound Expressions (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 18\n             \n             \n               Lecture  If-else statements (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 19\n             \n             \n               Labwork  Lab 4: Functions and If-else (due 9/20)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 20\n             \n             \n               Shiny  Shiny Friday: Old Faithful (enriched app)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  HW 3: Functions (avail 9/21, due 9/27)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 5\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 5: Tables and Tidyverse (part 1)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 23\n             \n             \n               Lecture  Graphics with ggplot2 (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 25\n             \n             \n               Lecture  More graphics with ggplot2 (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 26\n             \n             \n               Labwork  Lab 5a: Intro to ggplot2 (due 9/27)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Labwork2  Lab 5b: Shiny app Old Faithful w/ggplot2\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 27\n             \n             \n               Shiny  Shiny Friday: graphics with ggplot\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  HW4: Graphics with ggplot2 (avail 9/28, due 10/04)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 6\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 6: Tables and Tidyverse (part 2)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Sep 30\n             \n             \n               Lecture  Manipulating tables with dplyr (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 2\n             \n             \n               Lecture  More dplyr (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 3\n             \n             \n               Labwork  Lab 6: Intro to dplyr (due 10/04)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 4\n             \n             \n               Shiny  Shiny Friday: Top-n mtcars\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  HW5: Data Wrangling (avail 10/05, due 10/11)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 7\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 7: Iterations and Loops\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 7\n             \n             \n               Lecture  Iterations (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 9\n             \n             \n               Lecture  More Iterations and Simulations (slides)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 10\n             \n             \n               Labwork  Lab 7: Loops in R (due 10/11)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 11\n             \n             \n               Shiny  Shiny Friday: Top-n mtcars (continued)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  HW6: Iterations (avail 10/12, due 10/18)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 8\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 8: Regular Expressions\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 14\n             \n             \n               Lecture  Intro to Regular Expressions (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  Character sets (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 16\n             \n             \n               Lecture  Anchors (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  Quantifiers (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 17\n             \n             \n               Labwork  Lab 8: Intro to Regex (due 10/18)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 18\n             \n             \n               Lecture  Look Arounds (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  Shiny App-1 (avail 10/19, due 11/01)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 9\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 9: Text Mining 1\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 21\n             \n             \n               Lecture  Text Mining, introduction (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 23\n             \n             \n               Lecture  Text Mining, word frequencies (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 24\n             \n             \n               Labwork  Lab 9a: More Regex (due 10/25)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Labwork2  Lab 9b: Publishing a shiny app\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 25\n             \n             \n               Lecture  Text Mining, part 3\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Midterm  More information TBA\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 10\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 10: Text Mining 2\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 28\n             \n             \n               Lecture  Sentiment Analysis 1 (notes)\n             \n             \n               Doc\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 30\n             \n             \n               Lecture  Sentiment Analysis 2 (notes)\n             \n             \n               Doc\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  Correspondence Analysis (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Oct 31\n             \n             \n               Labwork  Lab 10: Text Mining (due 11/01)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 1\n             \n             \n               Lecture  More Correspondence Analysis (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  Shiny App-2 (avail 11/02, due 11/15)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 11\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 11: Geospatial Data 1\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 4\n             \n             \n               Lecture  Mapping Storms, simple features (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 6\n             \n             \n               Lecture  Mapping Storms, leaflet (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 7\n             \n             \n               Labwork  Lab 11: Maps 1 (due 11/08)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 8\n             \n             \n               Lecture  Mapping Storms (part 3)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 12\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 12: Geospatial Data 2\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 11\n             \n             \n               Lecture  No class (Veterans day)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 13\n             \n             \n               Lecture  Choropleth maps 1\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 14\n             \n             \n               Labwork  Lab 12: Maps 2 (due 11/15)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 15\n             \n             \n               Lecture  Choropleth maps 2\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Homework  Shiny App-3 (avail 11/16, due 12/06)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 13\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 13: Web Tech 1\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 18\n             \n             \n               Lecture  JSON data (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  APIs (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 20\n             \n             \n               Lecture  XML 1 (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n  \n  \n  \n             \n             \n             \n               Lectur2  XML 2 (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 21\n             \n             \n               Labwork  Lab 13: Bart API (due 11/22)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 22\n             \n             \n               Lecture  Xpath (notes)\n             \n             \n               Slides\n              \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 14\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 14: Web Tech 2\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 25\n             \n             \n               Lecture  Web Scraping: HTML (notes)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 27\n             \n             \n               Lecture  No class (Thanksgiving)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 28\n             \n             \n               Labwork  No lab (Thanksgiving)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Nov 29\n             \n             \n               Lecture  No class (Thanksgiving)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 15\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  Unit 15: Web Tech 2 (cont'd)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Dec 2\n             \n             \n               Lecture  Web Scraping 2\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Dec 4\n             \n             \n               Lecture  Web Scraping 3\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Dec 5\n             \n             \n               Labwork  Lab 14: Web Scraping (due 12/06)\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Dec 6\n             \n             \n               Lecture  Closing Talk\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 16\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             About\n             \n             \n               Overview  RRR Week\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n  \n          \n  \n  \n  \n             \n             \n             Dec ??\n             \n             \n               Review  Final Review TBA\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n   Week 17\n\n   \n   \n   \n   \n   \n     \n  \n          \n  \n  \n  \n             \n             \n             Dec 18\n             \n             \n               Final  Final Exam\n             \n             \n                \n             \n             \n                \n             \n                  \n             \n          \n     \n     \n  \n   \n  \n\n\nNo matching items",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "units/unit14.html",
    "href": "units/unit14.html",
    "title": "14) Web Tech 2",
    "section": "",
    "text": "For our last week of the semester we provide an example of web scraping using a high-level approach that involves parsing XML and scraping data with functions from packages \"xml2\" and \"rvest\" (and a bit of \"stringr\").",
    "crumbs": [
      "Units",
      "14) Web Tech 2"
    ]
  },
  {
    "objectID": "units/unit14.html#lecture",
    "href": "units/unit14.html#lecture",
    "title": "14) Web Tech 2",
    "section": "",
    "text": "For our last week of the semester we provide an example of web scraping using a high-level approach that involves parsing XML and scraping data with functions from packages \"xml2\" and \"rvest\" (and a bit of \"stringr\").",
    "crumbs": [
      "Units",
      "14) Web Tech 2"
    ]
  },
  {
    "objectID": "units/unit14.html#reading",
    "href": "units/unit14.html#reading",
    "title": "14) Web Tech 2",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead the following chapters from “R Web Technologies”:\n\nhttps://www.gastonsanchez.com/R-web-technologies/xml.html\nhttps://www.gastonsanchez.com/R-web-technologies/parsing-xml.html\nhttps://www.gastonsanchez.com/R-web-technologies/xpath.html",
    "crumbs": [
      "Units",
      "14) Web Tech 2"
    ]
  },
  {
    "objectID": "units/unit14.html#lab",
    "href": "units/unit14.html#lab",
    "title": "14) Web Tech 2",
    "section": "🔬 Lab",
    "text": "🔬 Lab\n\nPractice web scraping data.",
    "crumbs": [
      "Units",
      "14) Web Tech 2"
    ]
  },
  {
    "objectID": "units/unit14.html#objectives",
    "href": "units/unit14.html#objectives",
    "title": "14) Web Tech 2",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nDescribe what web scraping is.\nExaplain the purpose of Xpath expressions\nScrape some web data using \"rvest\" functions.",
    "crumbs": [
      "Units",
      "14) Web Tech 2"
    ]
  },
  {
    "objectID": "units/unit14.html#assignments",
    "href": "units/unit14.html#assignments",
    "title": "14) Web Tech 2",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nApp3 due on 12/06",
    "crumbs": [
      "Units",
      "14) Web Tech 2"
    ]
  },
  {
    "objectID": "units/unit11.html",
    "href": "units/unit11.html",
    "title": "11) Maps 1",
    "section": "",
    "text": "Many data sets (e.g. storms data set from \"dplyr\") contain geographical variables such as longitude and latitude that can be visualized with a map. This week we take \"ggplot2\" a further step to learn how to plot basic maps with some dedicated packages such as \"sf\" and \"rnaturalearth\". Likewise, we’ll also discuss how to produce web-interactive maps with the package \"leaflet\".",
    "crumbs": [
      "Units",
      "11) Maps 1"
    ]
  },
  {
    "objectID": "units/unit11.html#lecture",
    "href": "units/unit11.html#lecture",
    "title": "11) Maps 1",
    "section": "",
    "text": "Many data sets (e.g. storms data set from \"dplyr\") contain geographical variables such as longitude and latitude that can be visualized with a map. This week we take \"ggplot2\" a further step to learn how to plot basic maps with some dedicated packages such as \"sf\" and \"rnaturalearth\". Likewise, we’ll also discuss how to produce web-interactive maps with the package \"leaflet\".",
    "crumbs": [
      "Units",
      "11) Maps 1"
    ]
  },
  {
    "objectID": "units/unit11.html#reading",
    "href": "units/unit11.html#reading",
    "title": "11) Maps 1",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 17, 18, and 19 of “Tidy Hurricanes”:\n\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/5-01-maps-intro.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/5-03-maps-sf.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/5-04-maps-leaflet.html",
    "crumbs": [
      "Units",
      "11) Maps 1"
    ]
  },
  {
    "objectID": "units/unit11.html#lab",
    "href": "units/unit11.html#lab",
    "title": "11) Maps 1",
    "section": "🔬 Lab",
    "text": "🔬 Lab\n\nGraphing basic maps with \"ggplot2\" & \"sf\".\nMaking web-interactive maps with \"leaflet\".",
    "crumbs": [
      "Units",
      "11) Maps 1"
    ]
  },
  {
    "objectID": "units/unit11.html#objectives",
    "href": "units/unit11.html#objectives",
    "title": "11) Maps 1",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nExplain the concept of a “simple feature”\nDescribe how to use the layer geom_sf()\nMap latitude and longitude coordinates in a geom_sf() layer.",
    "crumbs": [
      "Units",
      "11) Maps 1"
    ]
  },
  {
    "objectID": "units/unit11.html#assignments",
    "href": "units/unit11.html#assignments",
    "title": "11) Maps 1",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nShiny App2, due 11/14",
    "crumbs": [
      "Units",
      "11) Maps 1"
    ]
  },
  {
    "objectID": "units/unit12.html",
    "href": "units/unit12.html",
    "title": "12) Maps 2",
    "section": "",
    "text": "We continue discussing maps in R. In particular, we use two interesting data sets:\n\nIBTrACS shapefiles. We’ll use this to work with shapefiles, which is perhaps the most common format for vector data.\nUS Presidential Election Results (2020). We’ll use this data to make some choropleth maps. A choropleth map is a thematic map that is used to visualize how a variable varies across a geographic area.",
    "crumbs": [
      "Units",
      "12) Maps 2"
    ]
  },
  {
    "objectID": "units/unit12.html#lecture",
    "href": "units/unit12.html#lecture",
    "title": "12) Maps 2",
    "section": "",
    "text": "We continue discussing maps in R. In particular, we use two interesting data sets:\n\nIBTrACS shapefiles. We’ll use this to work with shapefiles, which is perhaps the most common format for vector data.\nUS Presidential Election Results (2020). We’ll use this data to make some choropleth maps. A choropleth map is a thematic map that is used to visualize how a variable varies across a geographic area.",
    "crumbs": [
      "Units",
      "12) Maps 2"
    ]
  },
  {
    "objectID": "units/unit12.html#reading",
    "href": "units/unit12.html#reading",
    "title": "12) Maps 2",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 17, 18, and 19 of “Tidy Hurricanes”:\n\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/5-01-maps-intro.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/5-03-maps-sf.html\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/5-04-maps-leaflet.html",
    "crumbs": [
      "Units",
      "12) Maps 2"
    ]
  },
  {
    "objectID": "units/unit12.html#lab",
    "href": "units/unit12.html#lab",
    "title": "12) Maps 2",
    "section": "🔬 Lab",
    "text": "🔬 Lab\n\nGraphing maps with \"ggplot2\", \"sf\", and \"leaflet\".",
    "crumbs": [
      "Units",
      "12) Maps 2"
    ]
  },
  {
    "objectID": "units/unit12.html#objectives",
    "href": "units/unit12.html#objectives",
    "title": "12) Maps 2",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nDescribe the components of a shapefile.\nImport shapefiles in R.\nMake maps with shapefile data.\nExplain the concept of a “choropleth map”\nPlot a map of US counties with geom_sf().",
    "crumbs": [
      "Units",
      "12) Maps 2"
    ]
  },
  {
    "objectID": "units/unit12.html#assignments",
    "href": "units/unit12.html#assignments",
    "title": "12) Maps 2",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nShiny App2, due 11/14\nShiny App3 released on 11/15, due 12/06",
    "crumbs": [
      "Units",
      "12) Maps 2"
    ]
  },
  {
    "objectID": "units/unit9.html",
    "href": "units/unit9.html",
    "title": "9) Text Mining 1",
    "section": "",
    "text": "We move on to our next topic which involves basic principles behind Text Mining, “the process of distilling actionable insights from text”.\nBroadly speaking, Text Mining analysis can be divided in two big categories: 1) Bag-of-Words (bow) analysis, and 2) Syntactic Parsing. In this course, we will focus exclusively on topics related to bag-of-words analysis.\nPreliminary Operations: Because text data is rarely ready to be analyzed, we need to first discuss some of the common preparation steps for having text data in a way that can be mathematically/statistically analyzed.\nFrequency Analysis: The most basic type of bag-of-words text mining analysis consists of counting the number of occurrences or frequencies of each token.",
    "crumbs": [
      "Units",
      "9) Text Mining 1"
    ]
  },
  {
    "objectID": "units/unit9.html#lecture",
    "href": "units/unit9.html#lecture",
    "title": "9) Text Mining 1",
    "section": "",
    "text": "We move on to our next topic which involves basic principles behind Text Mining, “the process of distilling actionable insights from text”.\nBroadly speaking, Text Mining analysis can be divided in two big categories: 1) Bag-of-Words (bow) analysis, and 2) Syntactic Parsing. In this course, we will focus exclusively on topics related to bag-of-words analysis.\nPreliminary Operations: Because text data is rarely ready to be analyzed, we need to first discuss some of the common preparation steps for having text data in a way that can be mathematically/statistically analyzed.\nFrequency Analysis: The most basic type of bag-of-words text mining analysis consists of counting the number of occurrences or frequencies of each token.",
    "crumbs": [
      "Units",
      "9) Text Mining 1"
    ]
  },
  {
    "objectID": "units/unit9.html#reading",
    "href": "units/unit9.html#reading",
    "title": "9) Text Mining 1",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 1, 2 and 4 of “Text Mining with R” (by Julia Silge and David Robinson):\n\nhttps://www.tidytextmining.com/tidytext\nhttps://www.tidytextmining.com/sentiment\nhttps://www.tidytextmining.com/ngrams",
    "crumbs": [
      "Units",
      "9) Text Mining 1"
    ]
  },
  {
    "objectID": "units/unit9.html#lab",
    "href": "units/unit9.html#lab",
    "title": "9) Text Mining 1",
    "section": "🔬 Lab",
    "text": "🔬 Lab\n\nPublish a shiny app to shinyapps.io\nKeep practicing regular expressions.",
    "crumbs": [
      "Units",
      "9) Text Mining 1"
    ]
  },
  {
    "objectID": "units/unit9.html#objectives",
    "href": "units/unit9.html#objectives",
    "title": "9) Text Mining 1",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nList at least four operations that are commonly applied to a text data set before it can be analyzed with text mining techniques.\nDescribe the notion of stopwords.\nExplain what a corpus (or corpora) is.\nExplain what a token is.\nExplain the concept of tokenization.\nCompute frequencies of tokens.\nVisualize frequencies with barcharts and wordclouds.",
    "crumbs": [
      "Units",
      "9) Text Mining 1"
    ]
  },
  {
    "objectID": "units/unit9.html#assignments",
    "href": "units/unit9.html#assignments",
    "title": "9) Text Mining 1",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nMidterm on Friday 10/25\nKeep working on your shiny App1, due 11/01",
    "crumbs": [
      "Units",
      "9) Text Mining 1"
    ]
  },
  {
    "objectID": "units/unit3.html",
    "href": "units/unit3.html",
    "title": "3) Lists and Matrices",
    "section": "",
    "text": "This week in class we discuss more data objects in R, specifically matrices and lists.\nAlthough we won’t work with matrices that much in Stat 133, it’s worth learning the following:\n\nWhy matrices, like vectors, are atomic objects,\nIn what sense a matrix is a 2-dimensional array,\nHow R stores matrices,\nFunctions to create matrices, and inspect their structure\nHow to manipulate matrices using bracket notation\n\nAs for lists, they are the most generic kind of data container in R, and you’ll learn:\n\nIn what sense a list is a non-atomic atomic\nIn what sense a list is a one-dimensional object\nHow to create lists\nDifferent ways to manipulate lists",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit3.html#lecture",
    "href": "units/unit3.html#lecture",
    "title": "3) Lists and Matrices",
    "section": "",
    "text": "This week in class we discuss more data objects in R, specifically matrices and lists.\nAlthough we won’t work with matrices that much in Stat 133, it’s worth learning the following:\n\nWhy matrices, like vectors, are atomic objects,\nIn what sense a matrix is a 2-dimensional array,\nHow R stores matrices,\nFunctions to create matrices, and inspect their structure\nHow to manipulate matrices using bracket notation\n\nAs for lists, they are the most generic kind of data container in R, and you’ll learn:\n\nIn what sense a list is a non-atomic atomic\nIn what sense a list is a one-dimensional object\nHow to create lists\nDifferent ways to manipulate lists",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit3.html#reading",
    "href": "units/unit3.html#reading",
    "title": "3) Lists and Matrices",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 6, 7 and 8 of “R Coding Basics”:\n\nhttps://www.gastonsanchez.com/R-coding-basics/3-01-matrices-intro.html\nhttps://www.gastonsanchez.com/R-coding-basics/3-02-matrices-operations.html\nhttps://www.gastonsanchez.com/R-coding-basics/4-01-lists.html",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit3.html#lab",
    "href": "units/unit3.html#lab",
    "title": "3) Lists and Matrices",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nIn lab you will practice creating and manipulating matrices and lists.",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit3.html#objectives",
    "href": "units/unit3.html#objectives",
    "title": "3) Lists and Matrices",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\n\nCreate simple matrices with matrix()\nDescribe and give examples of matrix subsetting (subscripting, indexing)\nExplain in what sense a matrix is a 2-dimensional object\nDescribe and give examples of subsetting (subscripting, indexing) of an R list\nProvide an example of list subsetting with single brackets (e.g. lis[index])\nProvide an example of list subsetting with double brackets, and a single element (e.g. lis[[index]])\nProvide a manipulation example of a list with the dollar operator (e.g. lis$wagon )",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit3.html#shiny-friday",
    "href": "units/unit3.html#shiny-friday",
    "title": "3) Lists and Matrices",
    "section": "🔆 Shiny Friday",
    "text": "🔆 Shiny Friday\nThe shiny app of this week is based on the computation of Future Value (compounding interest) in its simplest version:\n\\[\nFV = P (1 + r)^n\n\\]\nThis is a simple app that takes three inputs:\n\nP = principal or initial amount (how much you deposit)\nr = annual interest rate (or rate of return)\nn = number of years\n\nIn turn, the app produces one (graphical) output which is a timeline to visualize the Future Value.\nThere are two versions of the app: one uses three sliders (one slider per input), and the other one uses three numeric inputs (one number per input)\n\nhttps://github.com/data133/shiny/tree/main/future-value1-numerics\nhttps://github.com/data133/shiny/tree/main/future-value2-sliders",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit3.html#hw-assignments",
    "href": "units/unit3.html#hw-assignments",
    "title": "3) Lists and Matrices",
    "section": "🔔 HW Assignments",
    "text": "🔔 HW Assignments\n\nHW1 due this 9/13\nHW2 released on 9/14, due 9/20",
    "crumbs": [
      "Units",
      "3) Lists and Matrices"
    ]
  },
  {
    "objectID": "units/unit4.html",
    "href": "units/unit4.html",
    "title": "4) Functions and Conditionals",
    "section": "",
    "text": "You don’t need to be an expert programmer to be a data scientist, but learning more about programming allows you to automate common tasks, and solve new problems with greater ease.\nThis week we’ll discuss how to write basic functions, the notion of compound expressions in R, and an introduction to conditionals (i.e. if-else statements).",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit4.html#lecture",
    "href": "units/unit4.html#lecture",
    "title": "4) Functions and Conditionals",
    "section": "",
    "text": "You don’t need to be an expert programmer to be a data scientist, but learning more about programming allows you to automate common tasks, and solve new problems with greater ease.\nThis week we’ll discuss how to write basic functions, the notion of compound expressions in R, and an introduction to conditionals (i.e. if-else statements).",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit4.html#reading",
    "href": "units/unit4.html#reading",
    "title": "4) Functions and Conditionals",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 10, 11, and 12 of “R Coding Basics”:\n\nhttps://www.gastonsanchez.com/R-coding-basics/5-01-functions-intro.html\nhttps://www.gastonsanchez.com/R-coding-basics/5-02-expressions.html\nhttps://www.gastonsanchez.com/R-coding-basics/5-03-conditionals.html",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit4.html#lab",
    "href": "units/unit4.html#lab",
    "title": "4) Functions and Conditionals",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nYou will get your hands “dirty” writing basic functions, and conditional statements.",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit4.html#objectives",
    "href": "units/unit4.html#objectives",
    "title": "4) Functions and Conditionals",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\nAt the end of this week you will be able to:\n\nDescribe the main parts of a function (i.e. anatomy of a function)\nGive a simple example for creating a function\nExplain the concept of an R compound expression\nWrite if-else statements to handle simple conditions\nUse if-else statements when writing functions to decide what code to execute",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit4.html#shiny-friday",
    "href": "units/unit4.html#shiny-friday",
    "title": "4) Functions and Conditionals",
    "section": "🔆 Shiny Friday",
    "text": "🔆 Shiny Friday\nThe shiny app for this week is a modified version of the default “Old Faithful” app.\nThe main modification has to do with the use of an if-statement to decide whether to display additional statistics on the histogram of waiting times.\nMore specifically, we have three new versions:\n\nold-faithful3-average-radio: includes radio buttons to display line of average waiting time  https://github.com/data133/shiny/tree/main/old-faithful3-average-radio\nold-faithful4-average-checkbox: includes a checkbox to display line of average waiting time  https://github.com/data133/shiny/tree/main/old-faithful4-average-checkbox\nold-faithful5-statistics: includes an auxiliary function to compute descriptive statistics, and also a checkbox to display descriptive statistics  https://github.com/data133/shiny/tree/main/old-faithful5-statistics",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit4.html#assignments",
    "href": "units/unit4.html#assignments",
    "title": "4) Functions and Conditionals",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nHW2 due this 9/20\nHW3 released on 9/21, due 9/27",
    "crumbs": [
      "Units",
      "4) Functions and Conditionals"
    ]
  },
  {
    "objectID": "units/unit7.html",
    "href": "units/unit7.html",
    "title": "7) Iterations",
    "section": "",
    "text": "In addition to writing functions to reduce duplication in your code, you also need to learn about iteration, which helps you when you need to do the same operation several times. Namely, we review control flow structures such as for loops, while loops, repeat loops, and the apply family functions.",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "units/unit7.html#lecture",
    "href": "units/unit7.html#lecture",
    "title": "7) Iterations",
    "section": "",
    "text": "In addition to writing functions to reduce duplication in your code, you also need to learn about iteration, which helps you when you need to do the same operation several times. Namely, we review control flow structures such as for loops, while loops, repeat loops, and the apply family functions.",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "units/unit7.html#reading",
    "href": "units/unit7.html#reading",
    "title": "7) Iterations",
    "section": "📚 Reading",
    "text": "📚 Reading\nRead chapters 13 and 14 of “R Coding Basics”:\n\nhttps://www.gastonsanchez.com/R-coding-basics/5-04-for-loop.html\nhttps://www.gastonsanchez.com/R-coding-basics/5-05-while-loop.html",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "units/unit7.html#lab",
    "href": "units/unit7.html#lab",
    "title": "7) Iterations",
    "section": "🔬 Lab",
    "text": "🔬 Lab\nYou’ll keep working writing a variety of loops in R (e.g. for, while, repeat).",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "units/unit7.html#objectives",
    "href": "units/unit7.html#objectives",
    "title": "7) Iterations",
    "section": "🎯 Objectives",
    "text": "🎯 Objectives\nAt the end of this week you will be able to:\n\nWrite for loops to repeat the same operation a given number of times\nWrite while loops to repeat the same operation an unknown number of times",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "units/unit7.html#shiny-friday",
    "href": "units/unit7.html#shiny-friday",
    "title": "7) Iterations",
    "section": "🔆 Shiny Friday",
    "text": "🔆 Shiny Friday\nThe shiny app for this week is the same one from last week: it uses mtcars data set to visualize the top-n cars given a selected variable.\nAn important component of this app is the use of the reactive() function to create so-called reactive conductors (i.e. an R expression that uses widget input(s) and returns a value).\n\nmtcars-topn-barchart: produces a simple barchart—via \"ggplot2\"—to visualize the top-n cars given a selected variable. In addition to the plot, it also displays a table with the top-n cars. More important, this app uses a so-called reactive conductor element. https://github.com/data133/shiny/tree/main/mtcars-topn-barchart",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "units/unit7.html#assignments",
    "href": "units/unit7.html#assignments",
    "title": "7) Iterations",
    "section": "🔔 Assignments",
    "text": "🔔 Assignments\n\nHW5 due this 10/11\nHW6 released on 10/12, due 10/18",
    "crumbs": [
      "Units",
      "7) Iterations"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Announcement\n\n\n\n\nInstructor: Gaston Sanchez\nLecture: MWF 1pm-2pm in Stanley 105\nLab:\n\nLab 101, Th 9am-11am, Evans 342 (GSI Dylan Webb)\nLab 102, Th 9am-11am, Evans 330 (GSI Calvin Carter)\nLab 103, Th 11am-1pm, Evans 342 (GSI Huong Vu)\nLab 104, Th 1pm-3pm, Evans 342 (GSI Calvin Carter)\nLab 105, Th 3pm-5pm, Evans 342 (GSI Dylan Webb)\nLab 106, Th 3:30pm-5:30pm, Evans 330 (GSI Huong Vu)\n\nCode #: 22957\nUnits: 3\nFinal Exam: Wed Dec-18th, 7pm-10pm, location TBD.\nDates: Aug-28 / Dec-06\nStat 133 is an introductory-to-intermediate level course to computational data analysis with an emphasis on four major cornerstones:\nBecause Stat 133 is one of the core courses for Statistics majors, the underlying goal is to provide foundations for “computing with data” so that stat majors, as well as other data-dependent majors (e.g. Data Science, Applied Math, CogSci, Economics, etc), have the basic computational skills for subsequent upper division courses (e.g. Stat 150, 151A, 152, 153, 154, 155, 157, 158, 159).",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "about.html#info",
    "href": "about.html#info",
    "title": "About",
    "section": "",
    "text": "Instructor: Gaston Sanchez\nLecture: MWF 1pm-2pm in Stanley 105\nLab:\n\nLab 101, Th 9am-11am, Evans 342 (GSI Dylan Webb)\nLab 102, Th 9am-11am, Evans 330 (GSI Calvin Carter)\nLab 103, Th 11am-1pm, Evans 342 (GSI Huong Vu)\nLab 104, Th 1pm-3pm, Evans 342 (GSI Calvin Carter)\nLab 105, Th 3pm-5pm, Evans 342 (GSI Dylan Webb)\nLab 106, Th 3:30pm-5:30pm, Evans 330 (GSI Huong Vu)\n\nCode #: 22957\nUnits: 3\nFinal Exam: Wed Dec-18th, 7pm-10pm, location TBD.\nDates: Aug-28 / Dec-06",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "about.html#more-information",
    "href": "about.html#more-information",
    "title": "About",
    "section": "More Information",
    "text": "More Information\n\nSchedule\nSyllabus\nStaff\nCommunication via email\nEd Netiquette\nQ&As\n5 things you need to know",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This is an introductory-to-intermediate level course to computational data analysis with an emphasis on four major cornerstones:\n\n🔢 Understand common data formats, and principles of data manipulation (e.g. wrangling, reshaping, tidying)\n📊 Production of data visualizations and their role in data analysis projects\n💻 Learn basic principles for writing code, and programming concepts (with emphasis on data analysis)\n⚒️ Use computational tools to carry out the data analysis cycle, organize your workflow, and become familiar with reporting tools (via dynamic documents and web-apps)\n\nBecause Stat 133 is one of the core courses for Statistics majors, the underlying goal is to provide foundations for “computing with data” so that stat majors, as well as other data-dependent majors (e.g. Data Science, Applied Math, CogSci, Economics, etc), have the basic computational skills for subsequent upper division courses (e.g. Stat 150, 151A, 152, 153, 154, 155, 157, 158, 159).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#about-stat-133",
    "href": "syllabus.html#about-stat-133",
    "title": "Syllabus",
    "section": "",
    "text": "This is an introductory-to-intermediate level course to computational data analysis with an emphasis on four major cornerstones:\n\n🔢 Understand common data formats, and principles of data manipulation (e.g. wrangling, reshaping, tidying)\n📊 Production of data visualizations and their role in data analysis projects\n💻 Learn basic principles for writing code, and programming concepts (with emphasis on data analysis)\n⚒️ Use computational tools to carry out the data analysis cycle, organize your workflow, and become familiar with reporting tools (via dynamic documents and web-apps)\n\nBecause Stat 133 is one of the core courses for Statistics majors, the underlying goal is to provide foundations for “computing with data” so that stat majors, as well as other data-dependent majors (e.g. Data Science, Applied Math, CogSci, Economics, etc), have the basic computational skills for subsequent upper division courses (e.g. Stat 150, 151A, 152, 153, 154, 155, 157, 158, 159).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#goals",
    "href": "syllabus.html#goals",
    "title": "Syllabus",
    "section": "🎯 Goals",
    "text": "🎯 Goals\nBy the end of the course, students will:\n\nConstruct and execute basic programs in R using elementary programming techniques and tidyverse packages.\nVisualize information and data using appropriate graphical techniques.\nImport data from files or the internet.\nMunge raw data into a tidy format.\nCreate visualizations using geospatial data.\nParse and analyze text documents.\nCreate reproducible documents.\nConstruct interactive web applications.\n\nWe don’t expect that you become a jedi data scientist, an R ninja, or a super coder. That takes YEARS of practice, training, learning, and collaboration. Instead, we want to give you a good foundation around tools for computational data analysis.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-culture",
    "href": "syllabus.html#course-culture",
    "title": "Syllabus",
    "section": "🏫 Course Culture",
    "text": "🏫 Course Culture\nStudents taking Stat 133 come from a wide range of backgrounds. We hope to foster an inclusive and supportive learning environment based on curiosity rather than competition. All members of the course community—the instructor, GSIs, students, tutors, and readers—are expected to treat each other with courtesy and respect.\nYou will be interacting with course staff and fellow students in several different environments: in class, in lab, over the discussion forum, and in office hours. Some of these will be in person, some of them will be online, but the same expectations hold: be kind, be respectful, be professional.\nIf you are concerned about classroom environment issues created by other students or course staff, please come talk to us about it.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#ℹ-prerequisites",
    "href": "syllabus.html#ℹ-prerequisites",
    "title": "Syllabus",
    "section": "ℹ️ Prerequisites",
    "text": "ℹ️ Prerequisites\nThis course does not have any prerequisites, although it would be nice if you have taken an introductory course in statistics (e.g. Stat 2, 20, 21, 131A).\nThe curriculum and format is designed specifically for students (ideally majoring in Statistics and/or Data Science) who have no-or-minimum programming experience. You also don’t need previous data analysis experience—although it helps if you do.\nStudents with some prior experience in either computational statistics or computing are welcome to enroll, though some parts of the course might feel extremely slow. We recommend that you take more advanced courses unless you need Stat 133 because of your major/minor’s requirements.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "📚 Textbooks",
    "text": "📚 Textbooks\nWe’ll be using a handful of textbooks (most of them based on the notes I’ve authored for Stat 133 in the last 8 years):\n\nhttps://www.gastonsanchez.com/R-coding-basics/\nhttps://www.gastonsanchez.com/R-tidy-hurricanes/\nhttps://www.gastonsanchez.com/R-rolling-dice/\nhttps://www.gastonsanchez.com/R-for-strings/\nhttps://www.gastonsanchez.com/R-web-technologies/\nhttps://www.tidytextmining.com/ (by Julia Silge and David Robinson)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#computational-tools",
    "href": "syllabus.html#computational-tools",
    "title": "Syllabus",
    "section": "🔧 Computational Tools",
    "text": "🔧 Computational Tools\nWe will be mainly using the computing and programming environment R (via RStudio) to analyze data in this class. We may also ask you to use a command line interface to interact with your operating system. You do need your own computer to use R and do the assignments.\nWe don’t expect that students have already been exposed to R. For those who come from Data 8 or some previous coding experience in python, the first labs will help you transfer that knowledge over to R. Both languages are excellent platforms for analyzing data, are widely used in data science, and have their individual strengths. R has been developed within the statistics community specifically for data analysis, while python is a general-purpose programming language but has large data analysis capabilities.\nThe lectures tend to be focused on the data analysis concepts, while learning how to apply/use them in R tend to be the focus of the labs and assignments. Do not be surprised or worried about not following the details of R code during class—that is not the point (furthermore, there will sometimes be code that is really specific to the instructional purposes of the lecture, e.g. to make a specific plot, and is beyond the scope of what you would be expected to understand or know how to do it by yourself).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#waitlisted-students-and-late-joining",
    "href": "syllabus.html#waitlisted-students-and-late-joining",
    "title": "Syllabus",
    "section": "⏳ Waitlisted Students and Late Joining",
    "text": "⏳ Waitlisted Students and Late Joining\nIf you are on the waiting list or have a pending application or added the course late, you must still do all coursework and complete labs and homework by the deadlines. We will not be offering extensions if you are admitted/enrolled into the course later. So it is your responsibility to stay up to date on the assignments.\nUnfortunately, doing all the work is not a guarantee of enrollment. You will only be enrolled if there is space in your lab. Enrollment will proceed by CalCentral.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#office-hours",
    "href": "syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "🚪 Office hours",
    "text": "🚪 Office hours\nMe (the instructor) and the GSIs will offer office hours each week across a range of times. You are welcome to visit the office hours of any instructor, not just the ones of your GSI. We may adjust the office hour schedule throughout the semester as we understand student needs and preferences. Please check the office hours tab on the staff page to see the times of the various OH sessions.\nI should also say that OH are an opportunity to chat one-on-one with me. If you can, please come to my office hours! Coming to OH does not necessarily send a signal that you are behind or need extra help. On the contrary, coming to office hours early and often tends to co-occur with success in the course. I am happy to chat about the course material, statistics in general, careers in statistics, and whatever other statistics or data science topics are on your mind!",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#group-tutoring",
    "href": "syllabus.html#group-tutoring",
    "title": "Syllabus",
    "section": "🎒 Group Tutoring",
    "text": "🎒 Group Tutoring\nTutors will offer group tutoring sessions several times each week. This is an opportunity to finish up any assignments that you’ve started in class or review any topics that are confusing for you. You’re welcome to attend any session that works well for your schedule.\nGroup tutoring is a great place to go to meet other students and collaborate on assignments with tutors on hand to help you get unstuck.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#labs-10-of-final-grade",
    "href": "syllabus.html#labs-10-of-final-grade",
    "title": "Syllabus",
    "section": "🔬 Labs (10% of final grade)",
    "text": "🔬 Labs (10% of final grade)\n\nWeekly lab discussions are an essential part of the course and we will introduce concepts not necessarily covered in class.\nThursdays are the official days for lab section.\nYou must attend the lab section you are officially enrolled in.\nDuring lab, you will work on short-form assignments designed to apply the concepts on real and simulated data sets.\nLab assignments will be released every Thursday (available in bCourses),\nThe due date is always on a Friday (please check the assignments tab in bCourses to keep track of deadlines).\nSolutions to lab assignments will be available a few days after their due date.\nWe will be giving credit on lab assignments based on completion.\nThe first lab assignment (lab-1) does not count toward your grade.\nOf all lab assignments (lab-2 to lab-14), your lowest 2 scores will be dropped in the calculation of your overall grade.\nIn addition to lab assignments, you will also find Practice problems (and their solutions) in the course website.\nAs its name indicates, they are there to give you the opportunity to practice the concepts covered every week.\nYou don’t need to submit practice problems. Also, these are no for extra credit.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#problem-sets-35-of-final-grade",
    "href": "syllabus.html#problem-sets-35-of-final-grade",
    "title": "Syllabus",
    "section": "📁 Problem Sets (35% of final grade)",
    "text": "📁 Problem Sets (35% of final grade)\n\nThere will be about 6 Problem-Set (PS) assignments (available in bCourses).\nPS are long-form assignments designed to apply the concepts you’ve learned in class and lab.\nStarting on week-2 they will be assigned every week, until week-7.\nThe due date is always on a Friday (please check the assignments tab in bCourses to keep track of deadlines).\nYou must write your own answers (using your own words and/or code). Copy and plagiarism will not be tolerated (see Academic Honesty policy).\nIf you don’t submit all required files, you will receive an automatic 10% deduction.\nIf you submit the incorrect files, you will receive no credit.\nSolutions will become available a few days (e.g. 3-4 days) after the due date.\nWe will drop the lowest Problem-Set assignment score in the calculation of your overall grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#app-projects-27-of-final-grade",
    "href": "syllabus.html#app-projects-27-of-final-grade",
    "title": "Syllabus",
    "section": "📂 App Projects (27% of final grade)",
    "text": "📂 App Projects (27% of final grade)\n\nThere will be about 3 Shiny App projects.\nThese are larger assignments intended to combine many of the ideas from the course, in order to create interactive web-apps.\nAs part of the submission you will have to record a video (with screen and face capture) in which you describe how to use your app, and explain the performed analysis and some of the obtained results.\nStarting on week-8 app projects will be assigned about every two weeks, until the end of instruction.\nWe will not drop any of the App assignment scores in the calculation of your overall grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#late-policy-and-hw-assignment-extensions",
    "href": "syllabus.html#late-policy-and-hw-assignment-extensions",
    "title": "Syllabus",
    "section": "🕚 Late Policy and HW Assignment Extensions",
    "text": "🕚 Late Policy and HW Assignment Extensions\nIf you cannot turn in a HW assignment on time, our default policy is:\n\nSubmissions within 24 hours after the deadline will receive a 15% deduction.\nSubmissions within 48 hours after the deadline will receive a 30% deduction.\nSubmissions that are 48 hours or more after the deadline will receive no credit.\n\nRequesting an extension: If you need to request an extension, regardless of your DSP status, fill out this google form. Submissions to this form will be visible only to the course staff members.\n\nAny first-time request for a 1-day extension on a problem set assignment, made before an assignment’s deadline, will be guaranteed to be approved, so long as it is made in good faith.\nAny first-time request for a 1-day extension on a shiny app assignment, made before an assignment’s deadline, will be guaranteed to be approved, so long as it is made in good faith.\nAny occasional request for a 2-day extension (requested before an assignment’s deadline) made by a student with a DSP accommodation for assignment extensions will be approved automatically.\n\nAlso, please keep in mind that we are dropping the lowest score of your six Problem-set assignments (do not confuse with App projects). This policy is in place to take care of any extenuating circumstances that prevent you from submitting one of these assignments.\nPlease plan ahead and pace yourself. Don’t wait until the last day to do an assignment. Don’t wait until the last minute to submit your assignments.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#midterm-7-of-final-grade",
    "href": "syllabus.html#midterm-7-of-final-grade",
    "title": "Syllabus",
    "section": "📝 Midterm (7% of final grade)",
    "text": "📝 Midterm (7% of final grade)\n\nThere will be one midterm assigned on Friday Oct-25th.\nMore information about the midterm will be announced as we approach its due date.\nUnless you have approved accommodations, we won’t be able to provide any extensions if you miss the midterm.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#final-exam-21-of-final-grade",
    "href": "syllabus.html#final-exam-21-of-final-grade",
    "title": "Syllabus",
    "section": "📝 Final Exam (21% of final grade)",
    "text": "📝 Final Exam (21% of final grade)\n\nThere will be one final exam.\nThe final exam will be on Wed Dec-18th (7pm-10pm), as scheduled by the University.\nMore information about the final exam will be provided as we approach its due date.\nUnless you have accommodations as determined by the university and approved by the instructor, you must take the exam at the date and times provided here.\nPlease check your course schedule and make sure that you can take the final exam on the scheduled date. Otherwise, do not take the class if you are not available at this date.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading-structure",
    "href": "syllabus.html#grading-structure",
    "title": "Syllabus",
    "section": "💯 Grading Structure",
    "text": "💯 Grading Structure\nGrades will be assigned using the following weighted components:\n\n10% Lab (drop 2 lowest scores)\n35% Psets (drop lowest score)\n8% App1 (no drop)\n9% App2 (no drop)\n10% App3 (no drop)\n7% Midterm\n21% Final Exam\n\n\nTo complete the course, you must take the final exam.\nTo try to keep grading consistent across semesters, I may occasionally curve an individual assignment. I will do this only if I made the assignment or exam harder than I intended, and no one’s scores will decrease as a result of the curve. This will happen very rarely, probably not at all.\nTo give you a rough idea of the grading scheme, the assignment of letter grades in previous semesters has been as follows:\n\n😀 90-100% (Excellent) A-/A/A+ range\n🙂 80-90% (Good) B-/B/B+ range\n😐 70-80% (Fair) C-/C/C+ range\n🙁 60-70% (Deficient) D\n😞 Below 60% (Failed) F\n\nIf you are taking the class pass-fail, the cut-oﬀ for passing is 70% (C-).\nAs a matter of course policy, I do not round up when calculating letter grades. Ex: if your overall score is 79.9999%, then the highest letter grade that you can expect is a C+, not a B-.\nThere is no curve; your grade will depend only on how well you do, and not on how well everyone else does.\nLetter grades are final; I don’t enter into negotiations with students about grades.\nPlease do not engage in grade grubbing.\nAlso, please remember that we grade your course performance, not your personal worth.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#generative-a.i.-policy",
    "href": "syllabus.html#generative-a.i.-policy",
    "title": "Syllabus",
    "section": "⚠️ Generative A.I. Policy",
    "text": "⚠️ Generative A.I. Policy\nGenerative A.I. refers to artificial intelligence technologies, like those used for ChatGPT and similar, that can draw on a large corpus of training data to create new written, visual, or audio content.\nThere are two principles we use to guide our class policy on AI use:\n\nCognitive dimension: Working with AI should not reduce your ability to think clearly. The use of AI should facilitate—rather than hinder—learning.\nEthical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nIn this course, we’ll be developing skills that are important to practice on your own. Because use of generative A.I. may inhibit the development of those skills, the use of these tools is permitted in this course for the following activities:\n\nBrainstorming and refining your ideas;\nFine tuning your exploratory/research questions;\nDrafting an outline to organize your thoughts;\nChecking syntax errors or bugs in your code; and\nPolishing your spelling and grammar.\n\nThe use of generative A.I. tools is not permitted in this course for the following activities:\n\nImpersonating you in classroom contexts, such as by using the tool to compose discussion board prompts assigned to you or content that you put into a discussion forum/chat.\nAttempting to pass off AI-generated work as your own.\nWriting a draft of your assignment.\nWriting entire blocks of code, functions, or scripts to complete class assignments.\n\nPlease keep in mind that use of generative A.I. tools can impede your learning by generating ideas for you before you had a chance to think of your own ideas; inhibiting the development of your own writing skills; generating factually inaccurate statements or fictional reference sources; etc.\nIf you are unsure of whether and how much of a submission has been AI-generated, or whether you are in violation of a certain policy, please reach out to us and ask for guidance.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-honesty",
    "href": "syllabus.html#academic-honesty",
    "title": "Syllabus",
    "section": "☝️ Academic Honesty",
    "text": "☝️ Academic Honesty\nYou should not share your code or answers, directly or indirectly, with other students. Doing so doesn’t help them; it just sets them up for trouble on exams. Feel free to discuss the problems with others beforehand, but not the solutions. Please complete your own work and keep it to yourself (e.g. avoid sharing it in hosting platforms like Github or similar). If you suspect other people may be plagiarizing you, let us know ASAP.\nWe expect you to do your own work and to uphold the standards of intellectual integrity. Collaborating on homework is fine and we encourage you to work together—but copying is not, nor is having somebody else submit assignments for you. Likewise, obtaining and/or using solutions from previous years or from the internet, if such happen to be available, is considered cheating.\nBeyond the templates or starting code provided by the teaching staff, any writing, code, media, or other submissions not explicitly identified as AI-generated will be assumed as original to the student. Submitting AI-generated work without identifying it as such will be considered a violation of the Code of Student Conduct.\nCheating will not be tolerated. Any evidence of academic misconduct will result in a score of zero (0) on the entire assignment or examination, and a failing letter grade. We will always report incidences of cheating to the Center for Student Conduct.\nIf you are having trouble with an assignment or studying for an exam, or if you are uncertain about permissible and impermissible conduct or collaboration, please contact us.\nRather than copying someone else’s work, ask for help. You are not alone in this course! The course staff is here to help you succeed. If you invest the time to learn the material and complete the projects, you won’t need to copy any answers.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#email-policy",
    "href": "syllabus.html#email-policy",
    "title": "Syllabus",
    "section": "✉️ Email Policy",
    "text": "✉️ Email Policy\nIf you wish for your email to make it into our inbox, the subject of your email must contain the text: Stat 133.\nPlease refer to my email guidelines for more information: communication via email",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#special-accommodations",
    "href": "syllabus.html#special-accommodations",
    "title": "Syllabus",
    "section": "🚸 Special Accommodations",
    "text": "🚸 Special Accommodations\nStudents needing accommodations for any physical, psychological, or learning disability, should contact the teaching staff during the first two weeks of the semester, and see http://dsp.berkeley.edu to learn about Berkeley’s policy. If you are a DSP student, please contact us at least three weeks prior to a midterm or final so that we can work out acceptable accommodations.\nFor relevant DSP accommodations that provide occasional extensions on assignments, please see the above Late Policy.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#incomplete-grade",
    "href": "syllabus.html#incomplete-grade",
    "title": "Syllabus",
    "section": "❗Incomplete Grade",
    "text": "❗Incomplete Grade\nUnder emergency/special circumstances, students may petition me to receive an Incomplete grade. By University policy, for a student to get an Incomplete requires (i) that the student was performing passing-level work until the time that (ii) something happened that—through no fault of the student—prevented the student from completing the coursework. If you take the final, you completed the course, even if you took it while ill, exhausted, mourning, etc. The time to talk to me about incomplete grades is BEFORE you take the final (several weeks before), when the situation that prevents you from finishing the course presents itself. Please clearly state your reasoning in your comments to me.\nIt is your responsibility to develop good time management skills, good studying habits, know your limits, and learn to ask for professional help. Life happens. Social, family, cultural, scholar, and individual circumstances can affect your performance (both positive and negatively). If you find yourself in a situation that raises concerns about passing the course, please contact me as soon as possible.\nAbove all, please-please-please do not wait till the end of the semester to share your concerns about passing the course because it will be too late by then.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#safe-and-inclusive-environment",
    "href": "syllabus.html#safe-and-inclusive-environment",
    "title": "Syllabus",
    "section": "🌻 Safe and Inclusive Environment",
    "text": "🌻 Safe and Inclusive Environment\nWhenever a faculty member, staff member, post-doc, or GSI is responsible for the supervision of a student, a personal relationship between them of a romantic or sexual nature, even if consensual, is against university policy. Any such relationship jeopardizes the integrity of the educational process.\nAlthough faculty and staff can act as excellent resources for students, you should be aware that they are required to report any violations of this campus policy. If you wish to have a confidential discussion on matters related to this policy, you may contact the Confidential Care Advocates on campus for support related to counseling or sensitive issues. Appointments can be made by calling (510) 642-1988.\nThe classroom, lab, and work place should be safe and inclusive environments for everyone. The Office for the Prevention of Harassment and Discrimination (OPHD) is responsible for ensuring the University provides an environment for faculty, staff and students that is free from discrimination and harassment on the basis of categories including race, color, national origin, age, sex, gender, gender identity, and sexual orientation. Questions or concerns? Call (510) 643-7985, email ask_ophd@berkeley.edu, or go to http://survivorsupport.berkeley.edu/.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#last-but-not-least",
    "href": "syllabus.html#last-but-not-least",
    "title": "Syllabus",
    "section": "🎉 Last But Not Least",
    "text": "🎉 Last But Not Least\nThe main goal of Stat 133 is that you should learn, and have a fantastic experience doing so. Please keep that goal in mind throughout the semester.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "five-things.html",
    "href": "five-things.html",
    "title": "Five things you need to know to pass this class",
    "section": "",
    "text": "Here they are, in no particular order."
  },
  {
    "objectID": "five-things.html#read-instructions-carefully",
    "href": "five-things.html#read-instructions-carefully",
    "title": "Five things you need to know to pass this class",
    "section": "1) Read Instructions Carefully",
    "text": "1) Read Instructions Carefully\nYou must carefully read the instructions provided for each assignment. Read, not skim! They contain information vital for the completion of the assigned work."
  },
  {
    "objectID": "five-things.html#do-all-the-assigned-work",
    "href": "five-things.html#do-all-the-assigned-work",
    "title": "Five things you need to know to pass this class",
    "section": "2) Do all the assigned work",
    "text": "2) Do all the assigned work\nThis course is a very hands-on course and requires many hours of practical work outside class and lab. It also requires reviewing ALL the learning materials shared in this website and in bCourses.\nIt goes without saying that you should do all the assigned work: attend lecture and section, review the practice material discussed in lab, and of course do all HW assignments. Keep in mind that the activities and assignments build upon earlier work. So it’s important not to fall behind and avoid leaving gaps along the semester.\nOn the technical side, you should have your own computer, (good) internet connection, download and install specific software (e.g. R, RStudio, gitbash, zoom), and also know how to record a video of both 1) computer’s screen capture, and 2) face capture (e.g. a zoom recording makes this easy). We will provide more detailed instructions about the required tools as we move forward with the semester."
  },
  {
    "objectID": "five-things.html#no-need-to-memorize-all-commands",
    "href": "five-things.html#no-need-to-memorize-all-commands",
    "title": "Five things you need to know to pass this class",
    "section": "3) No need to memorize all commands",
    "text": "3) No need to memorize all commands\nDo you need to memorize all commands? No! We don’t expect that you memorize all commands. In fact, you can find a series of cheatsheets that you can (and should) use at all times (even during quizzes and tests).\nHowever, we do expect that you learn the most common types of functions in R: e.g. library(), function(), help(), etc. More important, we expect that you understand the “logic” and working principles of certain data objects, common programming structures, good practices, etc."
  },
  {
    "objectID": "five-things.html#study-for-tests",
    "href": "five-things.html#study-for-tests",
    "title": "Five things you need to know to pass this class",
    "section": "4) Study for tests",
    "text": "4) Study for tests\nThe exams are a way to test your understanding of the various concepts presented in the course. The exams are also a way to test whether you are really doing all the practical work by yourself.\nIn theory, students who do an honest effort in completing all the assignments (e.g. writing commands, understanding commands, learning the syntax, etc) should be able to get a passing score in these tests."
  },
  {
    "objectID": "five-things.html#what-else-do-you-recommend-to-succeed-in-this-course",
    "href": "five-things.html#what-else-do-you-recommend-to-succeed-in-this-course",
    "title": "Five things you need to know to pass this class",
    "section": "5) What else do you recommend to succeed in this course?",
    "text": "5) What else do you recommend to succeed in this course?\nThis one is hard to answer, in part because it depends on your personal definition of “success”. Simply put, I don’t think there’s a unique recipe for success. Instead, let me answer this question by telling you about the typical factors that may negatively affect your performance:\n\nnot attending lecture and/or lab,\nnot submitting assignments,\nlooking at the solutions of other students and “inadvertently” copy them,\npoor studying/working habits\nbeing afraid/scared/ashamed of asking the teaching staff for help\nyou’ve been doing work of passing quality and you cannot complete the course due to circumstances beyond your control\n\nDon’t underestimate the second to last item. Coding (in any programming language) can be extremely frustrating at times. You would be surprised to hear my collection of student stories about all sorts of bugs, typos, misspellings, and the like, that gave them a fair amount of frustration. So please, ask the teaching staff for help in a timely and respectful manner.\nAs for the last item, please let us know you’ve been affected by circumstances beyond your control as soon as possible. While we cannot guarantee any outcome, we will do what is within our reach to help you in this class."
  },
  {
    "objectID": "practice/practice-tidy2-more-ggplot.html",
    "href": "practice/practice-tidy2-more-ggplot.html",
    "title": "Practice: Graphics with ggplot2 (part 2)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nGet started with \"ggplot2\"\nProduce basic plots with ggplot()\nGain familiarity with the aes() function\nLearn about the various geoms, or geometric objects, and recognize them\nUnderstand why and how to facet\nTry out different plot themes"
  },
  {
    "objectID": "practice/practice-tidy2-more-ggplot.html#data-mpg",
    "href": "practice/practice-tidy2-more-ggplot.html#data-mpg",
    "title": "Practice: Graphics with ggplot2 (part 2)",
    "section": "1.1 Data mpg",
    "text": "1.1 Data mpg\nFor illustration purposes we are going to use the mpg data which is one of the data sets in \"ggplot2\":\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows"
  },
  {
    "objectID": "practice/practice-tidy2-more-ggplot.html#using-geom_text",
    "href": "practice/practice-tidy2-more-ggplot.html#using-geom_text",
    "title": "Practice: Graphics with ggplot2 (part 2)",
    "section": "3.1 Using geom_text()",
    "text": "3.1 Using geom_text()\nLet’s label each point using model by adding a geom_text() layer, and mapping this argument with aes():\n\nggplot(data = audi, aes(hwy, displ)) +\n  geom_point() +\n  geom_text(aes(label = model))\n\n\n\n\n\n\n\n\n\nThe model names overlap with the points. Modify your code above by using the nudge_y argument in geom_text(). Does it go inside or outside of aes()? Now, replace geom_text() with geom_label(). What difference do you notice? Did you have to modify the arguments to aes() at all?\n\n\n\nShow answer\n# argument nudge_y goes outside aes()\nggplot(data = audi, aes(hwy, displ)) +\n  geom_point() +\n  geom_text(aes(label = model), nudge_y = 0.1)\n\n\n\nNext, cut and paste the aes(x = displ, y = hwy) from the argument of ggplot() to the argument of geom_point(). Do you run into an error? What if you copy the x and y arguments over to the aes() function in geom_text()?\n\n\n\nShow answer\n# specifying a local mapping just for geom_point results in an error\nggplot(data = audi) +\n  geom_point(aes(hwy, displ)) +\n  geom_text(aes(label = model), nudge_y = 0.1)"
  },
  {
    "objectID": "practice/practice-tidy2-more-ggplot.html#more-facets",
    "href": "practice/practice-tidy2-more-ggplot.html#more-facets",
    "title": "Practice: Graphics with ggplot2 (part 2)",
    "section": "6.1 More facets",
    "text": "6.1 More facets\nFinally, let’s study just the distribution of highway mileage.\n\nggplot(data = mpg) +\n  geom_histogram(aes(x = hwy)) +\n  facet_wrap(~ class)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nInstead of using a histogram to study the distribution, let’s try a boxplot instead.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = hwy))\n\n\n\n\n\n\n\n\nNotice that geom_histogram() and geom_boxplot() required only an x aesthetic. What happens if you replace x with y?\n\nFacet again by modifying the code above, this time using any variable of your choice.\n\n\n\nShow answer\n# facets by 'drv' (the type of drive train)\nggplot(data = mpg) +\n  geom_boxplot(aes(x = displ)) +\n  facet_wrap(~ drv)"
  },
  {
    "objectID": "practice/practice-prog1-functions.html",
    "href": "practice/practice-prog1-functions.html",
    "title": "Practice: Functions (part 1)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nDefine a function that takes arguments\nReturn a value from a function\nTest a function\nSet default values for function arguments\nThe goal of this module is to give you practice writing very simple functions. The following exercises are mostly designed for those of you without any programming experience. If you have previous programming experience, you can move to the next module."
  },
  {
    "objectID": "practice/practice-prog1-functions.html#writing-a-simple-function",
    "href": "practice/practice-prog1-functions.html#writing-a-simple-function",
    "title": "Practice: Functions (part 1)",
    "section": "2.1 Writing a simple function",
    "text": "2.1 Writing a simple function\nSo, how do you create a function? The first step is to write code and make sure that it works. In this case we already have the code that converts a number in Fahrenheit units into Celsius.\nThe next step is to encapsulate the code in the form of a function. You have to choose a name, some argument(s), and determine the output. Here’s one example with a function fahrenheit_to_celsius()\n\nfahrenheit_to_celsius &lt;- function(x) {\n  (x - 32) * (5/9)\n}\n\nfahrenheit_to_celsius(100)\n\n[1] 37.77778\n\n\nIf you want to get the conversion of 90 fahrenheit degrees, you just simply execute it again by changing its argument:\n\nfahrenheit_to_celsius(90)\n\n[1] 32.22222\n\n\nAnd because we are using arithmetic operators (i.e. multiplication, subtraction, division), the function is also vectorized:\n\nfahrenheit_to_celsius(c(90, 100, 110))\n\n[1] 32.22222 37.77778 43.33333\n\n\nSometimes it is recommended to add a default value to one (or more) of the arguments. In this case, we can give a default value of x = 1. When the user executes the function without any input, fahrenheit_to_celsius returns the value of 1 fahrenheit degree to Celsius degrees:\n\nfahrenheit_to_celsius &lt;- function(x = 1) {\n  (x - 32) * (5/9)\n}\n\n# default execution\nfahrenheit_to_celsius()\n\n[1] -17.22222"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#miles-to-kilometers",
    "href": "practice/practice-prog1-functions.html#miles-to-kilometers",
    "title": "Practice: Functions (part 1)",
    "section": "3.1 miles to kilometers",
    "text": "3.1 miles to kilometers\nWrite a function miles_to_kms() that converts miles into kilometers: 1 mile is equal to 1.6 kilometers. Give the argument a default value of 1.\n\n\nShow answer\nmiles_to_kms = function(x = 1) {\n  x * 1.6\n}"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#gallons-to-liters",
    "href": "practice/practice-prog1-functions.html#gallons-to-liters",
    "title": "Practice: Functions (part 1)",
    "section": "3.2 gallons to liters",
    "text": "3.2 gallons to liters\nWrite a function gallon_to_liters() that converts gallons to liters: 1 gallon is equal to 3.78541 liters:\n\n\nShow answer\ngallon_to_liters = function(x = 1) {\n  x * 3.78541\n}"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#seconds-to-years",
    "href": "practice/practice-prog1-functions.html#seconds-to-years",
    "title": "Practice: Functions (part 1)",
    "section": "3.3 seconds to years",
    "text": "3.3 seconds to years\nAccording to Wikipedia, in 2015 the life expectancy of a person born in the US was 79 years. Consider the following question: Can a newborn baby in USA expect to live for one billion (\\(10^9\\)) seconds?\nTo answer this question, write a function seconds2years() that takes a number in seconds and returns the equivalent number of years. Assume a year with 365 days. Test the function with seconds2years(1000000000)\n\n\nShow answer\nseconds2years = function(x = 1) {\n  x / (365 * 24 * 60 * 60)\n}\n\nseconds2years(1000000000)"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#function-f",
    "href": "practice/practice-prog1-functions.html#function-f",
    "title": "Practice: Functions (part 1)",
    "section": "4.1 Function f()",
    "text": "4.1 Function f()\nWrite a function f() based on the above equation.\n\n\nShow answer\nf = function(x = 1) {\n  x^2\n}\n\n\nTest your function with:\nf(2)\nf(-5)"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#function-g",
    "href": "practice/practice-prog1-functions.html#function-g",
    "title": "Practice: Functions (part 1)",
    "section": "4.2 Function g()",
    "text": "4.2 Function g()\nWrite a function g() based on the above equation.\n\n\nShow answer\ng = function(x = 1) {\n  2*x + 5\n}\n\n\nTest your function with:\ng(0)\ng(-5/2)"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#composite-function-fog",
    "href": "practice/practice-prog1-functions.html#composite-function-fog",
    "title": "Practice: Functions (part 1)",
    "section": "4.3 Composite function fog()",
    "text": "4.3 Composite function fog()\nWrite code to create the composite function fog(): \\(f \\circ g(x)\\)\n\n\nShow answer\nfog = function(x = 1) {\n  f(g(x))\n}\n\n\nTest your composite function with:\nfog(2)\nfog(-5)"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#composite-function-gof",
    "href": "practice/practice-prog1-functions.html#composite-function-gof",
    "title": "Practice: Functions (part 1)",
    "section": "4.4 Composite function gof()",
    "text": "4.4 Composite function gof()\nWrite code to create the composite function gof(): \\(g \\circ f(x)\\)\n\n\nShow answer\ngof = function(x = 1) {\n  g(f(x))\n}\n\n\nTest your composite function with:\ngof(0)\ngof(-5/2)"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#some-polynomials",
    "href": "practice/practice-prog1-functions.html#some-polynomials",
    "title": "Practice: Functions (part 1)",
    "section": "5.1 Some polynomials",
    "text": "5.1 Some polynomials\nWrite functions and graph the following polynomials in the x-axis interval -4 to 4:\n\n\\(f(x) = x^3\\)\n\n\n\nShow answer\npoly2 &lt;- function(x) {\n  x^3\n}\n\nx &lt;- seq(-4, 4, length.out = 30)\ny &lt;- poly2(x)\n\n# graph polynomial\nplot(x, y, type = 'l', lwd = 3, col = \"#FB7215\", las = 1)\nabline(h = 0, v = 0, col = '#888888aa', lwd = 1.5)\ntitle(main = expression(paste(f(x), ' = ', x^3)))\n\n\n\n\\(f(x) = (x^2 - 1)(x + 3)^3\\)\n\n\n\nShow answer\npoly3 &lt;- function(x) {\n  (x^2 - 1) * (x + 3)^3\n}\n\nx &lt;- seq(-4, 4, length.out = 30)\ny &lt;- poly3(x)\n\n# graph polynomial\nplot(x, y, type = 'l', lwd = 3, col = \"#FB7215\", las = 1)\nabline(h = 0, v = 0, col = '#888888aa', lwd = 1.5)\ntitle(main = expression(paste(f(x), ' = ', (x^2 - 1), (x + 3)^3)))\n\n\n\n\\(f(x) = (x^2 - 1)(x^2 - 9)\\)\n\n\n\nShow answer\npoly4 &lt;- function(x) {\n  (x^2 - 1) * (x^2 - 9)\n}\n\nx &lt;- seq(-4, 4, length.out = 30)\ny &lt;- poly4(x)\n\n# graph polynomial\nplot(x, y, type = 'l', lwd = 3, col = \"#FB7215\", las = 1)\nabline(h = 0, v = 0, col = '#888888aa', lwd = 1.5)\ntitle(main = expression(paste(f(x), ' = ', (x^2 - 1), (x^2 - 9))))"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#first-quartile",
    "href": "practice/practice-prog1-functions.html#first-quartile",
    "title": "Practice: Functions (part 1)",
    "section": "7.1 First Quartile",
    "text": "7.1 First Quartile\nWe can write a function to compute the first quartile of a numeric vector; this can be easily done with the advantage of the quantile() function:\n\nquartile1 &lt;- function(x) {\n  quantile(x, probs = 0.25)\n}\n\n# test it\nquartile1(mtcars$wt)\n\n    25% \n2.58125"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#argument-na.rm",
    "href": "practice/practice-prog1-functions.html#argument-na.rm",
    "title": "Practice: Functions (part 1)",
    "section": "7.2 Argument na.rm",
    "text": "7.2 Argument na.rm\nMany functions that work on vectors have a special argument: na.rm. This parameter is a logical value to indicate whether NAs should be removed or not. Because the quantile() function does come with the na.rm argument, we can take advantage of it and pass it to our quartile1() function:\n\nquartile1 &lt;- function(x, na.rm = FALSE) {\n  quantile(x, probs = 0.25, na.rm = na.rm)\n}\n\nLet’s get the weight of cars and add some missing values:\n\nweight_na = mtcars$wt\nweight_na[c(1, 10, 20)] = NA\n\nIf you apply quartile1() on weight_na using the default call, you will get an error:\n\nquartile1(weight_na)\n\nError in quantile.default(x, probs = 0.25, na.rm = na.rm): missing values and NaN's not allowed if 'na.rm' is FALSE\n\n\nTo remove missing values, you can use na.rm = TRUE:\n\nquartile1(weight_na, na.rm = TRUE)\n\n 25% \n2.77"
  },
  {
    "objectID": "practice/practice-prog1-functions.html#your-turn-function-quartiles",
    "href": "practice/practice-prog1-functions.html#your-turn-function-quartiles",
    "title": "Practice: Functions (part 1)",
    "section": "7.3 Your Turn: function quartiles()",
    "text": "7.3 Your Turn: function quartiles()\nAs you know, there are three quartile values—lower quartile, median, and upper quartile—to divide the data set into four ranges, each containing 25% of the data points.\nWrite a function quartiles() that computes the three quartiles of a numeric vector. BTW: take advantage of quantile()’s vectorization behavior. Include an argument na.rm to decide whether missing values should be removed. Give a default value of na.rm = FALSE.\nTest quartiles() on vectors mtcars$wt and weight_na.\n\n\nShow answer\nquartiles &lt;- function(x = 1, na.rm = FALSE) {\n  quantile(x, probs = c(0.25, 0.50, 0.75), na.rm = na.rm)\n}"
  },
  {
    "objectID": "practice/practice-objs3-lists.html",
    "href": "practice/practice-objs3-lists.html",
    "title": "Practice: Lists",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nCreate Lists\nSubset (subscript) lists with double brackets [[]]\nSubset (subscript) named elements with $"
  },
  {
    "objectID": "practice/practice-objs3-lists.html#creating-lists-with-list",
    "href": "practice/practice-objs3-lists.html#creating-lists-with-list",
    "title": "Practice: Lists",
    "section": "1.1 Creating lists with list()",
    "text": "1.1 Creating lists with list()\nBecause all these vectors refer to Leia, we can take a step further and use an R list to put them all in one place:\n\nleia &lt;- list(\n  \"name\" = name,\n  \"body\" = body,\n  \"force\" = force,\n  \"home\" = home\n)\n\nleia\n\n$name\n   first     last \n  \"Leia\" \"Organa\" \n\n$body\nheight weight \n   150     49 \n\n$force\n[1] TRUE\n\n$home\n[1] \"Alderaan\"\n\n\nNotice how R display the contents of a list in which its elements have names."
  },
  {
    "objectID": "practice/practice-objs3-lists.html#list-with-unnamed-elements",
    "href": "practice/practice-objs3-lists.html#list-with-unnamed-elements",
    "title": "Practice: Lists",
    "section": "1.2 List with unnamed elements",
    "text": "1.2 List with unnamed elements\nTo create a list use the function list(). You can pass any number of objects inside lists, separated by comma. Naming elements in a list is optional. This means that we could also create a list for Leia as follows:\n\nleia2 &lt;- list(\n  name,\n  body,\n  force,\n  home\n)\n\nleia2\n\n[[1]]\n   first     last \n  \"Leia\" \"Organa\" \n\n[[2]]\nheight weight \n   150     49 \n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] \"Alderaan\"\n\n\nThe lists leia and leia2 store the same vectors, in the same order. The only difference is that leia has named elements, whereas leia2 has unnamed elements. Whenever possible, I highly recommend giving names to the elements in a list because this makes it easier to understand which elements are being manipulated referring to them by their names."
  },
  {
    "objectID": "practice/practice-objs3-lists.html#lists-are-generic-objects",
    "href": "practice/practice-objs3-lists.html#lists-are-generic-objects",
    "title": "Practice: Lists",
    "section": "1.3 Lists are generic objects",
    "text": "1.3 Lists are generic objects\nR lists are the most general class of data object in R. Any other object can be an element of a list, even other lists.\nFor instance, let’s implement name as a list instead of a vector:\n\nname &lt;- list(\"first\" = \"Leia\", \"last\" = \"Organa\")\nname\n\n$first\n[1] \"Leia\"\n\n$last\n[1] \"Organa\"\n\n\nAnd now let’s create a new list leia in which the first element, name, is the previously created list:\n\nleia &lt;- list(\n  \"name\" = name,\n  \"body\" = body,\n  \"force\" = force,\n  \"home\" = home\n)\n\nleia\n\n$name\n$name$first\n[1] \"Leia\"\n\n$name$last\n[1] \"Organa\"\n\n\n$body\nheight weight \n   150     49 \n\n$force\n[1] TRUE\n\n$home\n[1] \"Alderaan\""
  },
  {
    "objectID": "practice/practice-objs3-lists.html#what-about-subsetting-lists",
    "href": "practice/practice-objs3-lists.html#what-about-subsetting-lists",
    "title": "Practice: Lists",
    "section": "2.1 What about subsetting lists?",
    "text": "2.1 What about subsetting lists?\nR lists admit three kinds of subsetting:\n\nwith single brackets: lis[2]\nwith double brackets: lis[[2]]\nwith dollar sign (on a single named element): lis$name\n\nRun the following commands and try to understand how R is subsetting the list leia:\nleia[1]\n\nleia[1:2]\n\nleia[-1]\n\nleia[c(4, 2)]\n\nleia[\"name\"]\n\nleia[c(\"home\", \"force\")]\n\nleia[c(FALSE, TRUE, FALSE, TRUE)]\n\nNow inspect the next set of commands that use double brackets:\nleia[[1]]\n\nleia[[2]]\n\nleia[[\"name\"]]\n\nleia[[\"unknown\"]]\n\nWhen one or more elements of a list are named, you can also use the dollar $ operator to subset a single element by referring to its name. Quoting the name is optional:\nleia$\"name\"\n\nleia$home\nReflect on the similarities and differences of the various syntax in which the elements of a list can be subset."
  },
  {
    "objectID": "practice/practice-objs3-lists.html#solar-list",
    "href": "practice/practice-objs3-lists.html#solar-list",
    "title": "Practice: Lists",
    "section": "3.1 solar list",
    "text": "3.1 solar list\n\nUse these vectors to create a list solar. When printed, your solar list should be displayed as:\n\n$planet\n[1] \"Mercury\" \"Venus\"   \"Earth\"   \"Mars\"    \"Jupiter\" \"Saturn\"  \"Uranus\"  \"Neptune\"\n\n$mass\n[1]    0.330    4.870    5.970    0.642 1898.000  568.000   86.800  102.000\n\n$temperature\n[1]  167  464   15  -65 -110 -140 -195 -200\n\n$moons\n[1]  0  0  1  2 79 62 27 14\n\n$rings\n[1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nShow answer\n# solar list\nsolar &lt;- list(\n  planet = planet,\n  mass = mass,\n  temperature = temperature,\n  moons = moons,\n  rings = rings\n)"
  },
  {
    "objectID": "practice/practice-objs3-lists.html#manipulation-of-solar",
    "href": "practice/practice-objs3-lists.html#manipulation-of-solar",
    "title": "Practice: Lists",
    "section": "3.2 Manipulation of solar",
    "text": "3.2 Manipulation of solar\nUse the list solar to write R commands—displaying the output—that answer the following questions (use only the list solar, NOT the individual vectors):\n\nWhat is the name of the lightest planet? Hint: the which.min() function is your friend.\n\n\n\nShow answer\nsolar$planet[which.min(solar$mass)]\n\n\n\nWhat is the name of the heaviest planet? Hint: the which.max() function is your friend.\n\n\n\nShow answer\nsolar$planet[which.max(solar$mass)]\n\n\n\nWhat is the temperature of the planet with the most number of moons? Hint: the which.max() function is your friend.\n\n\n\nShow answer\nsolar$temperature[which.max(solar$moons)]\n\n\n\nWhat is the mass of the planet with one moon?\n\n\n\nShow answer\nsolar$mass[solar$moons == 1]\n\n\n\nHow many planets have temperatures less than or equal to zero?\n\n\n\nShow answer\nsum(solar$temperature &lt;= 0)\n\n\n\nWhat is the 80th percentile of temperature for planets that have no rings? Hint: the quantile() function is your friend.\n\n\n\nShow answer\nquantile(solar$temperature[solar$rings == FALSE], \n         probs = 0.80)\n\n\n\nWhat is the name of the planet whose mass is furthest from the average mass (of all planets)?\n\n\n\nShow answer\nsolar$planet[which.max(abs(solar$mass - mean(solar$mass)))]"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html",
    "href": "practice/practice-prog3-iterations.html",
    "title": "Practice: Intro to Iterations",
    "section": "",
    "text": "In this module, we review various constructs and idioms in R to handle iterative computations:\n\nfor() loop\nwhile() loop\nrepeat loop\napply(), lapply(), sapply() functions\nsweep()"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#example-summation-series",
    "href": "practice/practice-prog3-iterations.html#example-summation-series",
    "title": "Practice: Intro to Iterations",
    "section": "2.1 Example: Summation Series",
    "text": "2.1 Example: Summation Series\nConsider the following summation series:\n\\[\n\\sum_{k=0}^{n} \\frac{1}{2^k} = 1 + \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\dots + \\frac{1}{2^n}\n\\]\n\n2.1.1 Using vectorized code\nAssuming \\(n = 5\\), we can compute the summation series using vectorized code. First, we generate each of the individual terms \\(1/2^k\\) with values for \\(k = 0, 1, \\dots, n\\). And then we add those terms:\n\nn = 5\nk = 0:n\n\n# individual terms\nterms = rep(1/(2^k))\nterms\n\n[1] 1.00000 0.50000 0.25000 0.12500 0.06250 0.03125\n\n# series\nsum(terms)\n\n[1] 1.96875\n\n\n\n\n2.1.2 Using a for loop\nFor learning purposes, we are going to ask you to forget about vectorization for a moment. And instead let’s see how to use a for loop.\nIn the following loop, we generate each individual term at each iteration, storing them in a vector terms. We also accumulate each term in the object series_sum:\n\n# input (5 terms)\nn = 5\n\n# initialize terms and series objects\nterms = 0\nseries_sum = 0\n\n# generate individual terms and accumulate them\nfor (k in 0:n) {\n  term &lt;- 1 / (2^k)\n  print(term)\n  terms[k+1] &lt;- term\n  series_sum = series_sum + term\n}\n\n[1] 1\n[1] 0.5\n[1] 0.25\n[1] 0.125\n[1] 0.0625\n[1] 0.03125\n\nseries_sum\n\n[1] 1.96875"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#example-arithmetic-series",
    "href": "practice/practice-prog3-iterations.html#example-arithmetic-series",
    "title": "Practice: Intro to Iterations",
    "section": "2.2 Example: Arithmetic Series",
    "text": "2.2 Example: Arithmetic Series\nConsider the following arithmetic series:\n\\[\na_n = a_1 + (n-1)d, \\qquad n = 2, 3, \\dots\n\\]\nFor instance, when \\(a_1 = 3\\), \\(d = 3\\), the terms \\(a_2, \\dots, a_5\\) are given by:\n\\[\\begin{align*}\na_2 &= a_1 + (2 - 1) d = 6 \\\\\na_3 &= a_2 + (3 - 1) d = 9 \\\\\na_4 &= a_3 + (4 - 1) d = 12 \\\\\na_5 &= a_4 + (5 - 1) d = 15 \\\\\n\\end{align*}\\]\n\n2.2.1 Using a for loop\nHere’s one way to obtain the above series using a for loop:\n\n# Arithmetic Series\na1 = 3\nd = 3\nnum = 5\n\n# output\nseries = rep(0, num)\n\n# iterations\nfor (n in 1:num) {\n  an = a1 + (n-1)*d\n  series[n] &lt;- an\n}\n\nseries\n\n[1]  3  6  9 12 15"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#geometric-sequence",
    "href": "practice/practice-prog3-iterations.html#geometric-sequence",
    "title": "Practice: Intro to Iterations",
    "section": "2.3 Geometric Sequence",
    "text": "2.3 Geometric Sequence\nA sequence such as \\(3, 6, 12, 24, 48\\) is an example of a geometric sequence. In this type of sequence, the \\(n\\)-th term is obtained as:\n\\[\na_n = a_1 \\times r^{n-1}\n\\]\nwhere: \\(a_1\\) is the first term, \\(r\\) is the common ratio, and \\(n\\) is the number of terms.\n\n2.3.1 Your Turn: for loop\n\nWrite a for loop to compute the sum of the first \\(n\\) terms of: 3 + 6 + 12 + 24 + …\nObtain the geometric series up to \\(n = 10\\).\n\n\n\nShow answer\n# inputs\na1 = 3\nr = 2\nnum = 10\n\n# output\nseries = rep(0, num)\n\n# iterations\nfor (n in 1:num) {\n  an = a1 * r^(n-1)\n  series[n] &lt;- an\n}"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#average",
    "href": "practice/practice-prog3-iterations.html#average",
    "title": "Practice: Intro to Iterations",
    "section": "2.4 Average",
    "text": "2.4 Average\nAs you know, the average of \\(n\\) numbers \\(x_1, x_2, \\dots, x_n\\) is given by the following formula:\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{x_1 + x_2 + \\dots + x_n}{n}\n\\]\n\n2.4.1 Your Turn: Average\nWrite R code, using both a for loop, and a while loop, to compute the average of the vector x = 1:100. Don’t use sum() or mean().\n\n\nShow answer\nx = 1:100\nn = length(x)\n\nsum_entries = 0\n\nfor (i in 1:n) {\n  sum_entries &lt;- sum_entries + x[i]\n}\n\navg = sum_entries / n"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#example-column-means-with-a-loop",
    "href": "practice/practice-prog3-iterations.html#example-column-means-with-a-loop",
    "title": "Practice: Intro to Iterations",
    "section": "3.1 Example: Column-means with a loop",
    "text": "3.1 Example: Column-means with a loop\nConsider the following matrix (based on data frame mtcars)\n\nmat = as.matrix(mtcars[1:10,1:5])\nmat\n\n                   mpg cyl  disp  hp drat\nMazda RX4         21.0   6 160.0 110 3.90\nMazda RX4 Wag     21.0   6 160.0 110 3.90\nDatsun 710        22.8   4 108.0  93 3.85\nHornet 4 Drive    21.4   6 258.0 110 3.08\nHornet Sportabout 18.7   8 360.0 175 3.15\nValiant           18.1   6 225.0 105 2.76\nDuster 360        14.3   8 360.0 245 3.21\nMerc 240D         24.4   4 146.7  62 3.69\nMerc 230          22.8   4 140.8  95 3.92\nMerc 280          19.2   6 167.6 123 3.92\n\n\nA common statistical operation involves computing summary statistics (e.g. mean, median, min, max) of the variables in a table. For example, say you want to calculate column-means. This could be done using a for loop that iterates over all columns, computing the mean for each of them:\n\n# pre-allocate (i.e. initialize) vector of means\ncol_means = c(0, ncol(mat))\n\n# iterate over all columns of mat\nfor (j in 1:ncol(mat)) {\n  col_means[j] = mean(mat[ ,j])\n}\n\n# assign names\nnames(col_means) = colnames(mat)\ncol_means\n\n    mpg     cyl    disp      hp    drat \n 20.370   5.800 208.610 122.800   3.538"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#example-column-means-with-apply",
    "href": "practice/practice-prog3-iterations.html#example-column-means-with-apply",
    "title": "Practice: Intro to Iterations",
    "section": "3.2 Example: Column-means with apply()",
    "text": "3.2 Example: Column-means with apply()\nInterestingly, instead of using a loop, you can also use apply() which allows you to apply a function to the columns, or the rows, or both cols-rows, of a matrix. The three main arguments of apply() are:\n\nX: input array (including a matrix)\nMARGIN: dimension index (1 = rows, 2 = columns) on which the function will be applied\nFUN: the function to be applied\n\nSo, to obtain the column means of mat, we apply the mean() function (FUN = mean) to each column (MARGIN = 2) of the input matrix mat\n\ncol_means = apply(X = mat, MARGIN = 2, FUN = mean)\ncol_means\n\n    mpg     cyl    disp      hp    drat \n 20.370   5.800 208.610 122.800   3.538"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#example-column-means-with-apply-1",
    "href": "practice/practice-prog3-iterations.html#example-column-means-with-apply-1",
    "title": "Practice: Intro to Iterations",
    "section": "3.3 Example: Column-means with apply()",
    "text": "3.3 Example: Column-means with apply()\nSometimes you may want to apply a computation for which R has no built-in function. This can be done by passing an anonymous function to the argument FUN. Recall that an anonymous function is a function that has no name. Here’s an example to calculate column-means with our own anonymous function:\n\ncol_avgs = apply(\n  X = mat, \n  MARGIN = 2, \n  FUN = function(x) sum(x) / length(x)\n)\n\ncol_avgs\n\n    mpg     cyl    disp      hp    drat \n 20.370   5.800 208.610 122.800   3.538 \n\n\nIf the body of the anonymous function involves several lines of code, you just have to use curly braces to wrap the body of the function:\n\ncol_avgs = apply(\n  X = mat, \n  MARGIN = 2, \n  FUN = function(x) {\n    n = length(x)\n    sum(x) / n\n  }\n)\n\ncol_avgs\n\n    mpg     cyl    disp      hp    drat \n 20.370   5.800 208.610 122.800   3.538 \n\n\nAlternatively, you can create your own (non-anonymous) function first, and then pass it to apply()\n\naverage = function(x, na.rm = FALSE) {\n  if (na.rm) {\n    x = x[!is.na(x)]\n  }\n  sum(x) / length(x)\n}\n\ncol_avgs = apply(X = mat, MARGIN = 2, FUN = average)\ncol_avgs\n\n    mpg     cyl    disp      hp    drat \n 20.370   5.800 208.610 122.800   3.538 \n\n\nNotice that the function average() takes two arguments: x and na.rm. When we pass a function to apply() that takes more than one argument, these additional arguments can also be provided to apply(). The way you do this is by specifying them after the argument FUN, for example:\n\ncol_avgs = apply(X = mat, MARGIN = 2, FUN = average, na.rm = TRUE)\ncol_avgs\n\n    mpg     cyl    disp      hp    drat \n 20.370   5.800 208.610 122.800   3.538"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#sweep-example",
    "href": "practice/practice-prog3-iterations.html#sweep-example",
    "title": "Practice: Intro to Iterations",
    "section": "3.4 sweep() example",
    "text": "3.4 sweep() example\nHaving obtained column-means, we can mean-center the values in mat, that is, compute deviations from the mean for each column. Again, you could write a loop to do this:\n\n# pre-allocate (i.e. initialize) matrix object\nmat_centered = matrix(0, nrow = nrow(mat), ncol = ncol(mat))\n\nfor (j in 1:ncol(mat)) {\n  mat_centered[ ,j] = mat[ ,j] - col_means[j]\n}\nmat_centered\n\n       [,1] [,2]    [,3]  [,4]   [,5]\n [1,]  0.63  0.2  -48.61 -12.8  0.362\n [2,]  0.63  0.2  -48.61 -12.8  0.362\n [3,]  2.43 -1.8 -100.61 -29.8  0.312\n [4,]  1.03  0.2   49.39 -12.8 -0.458\n [5,] -1.67  2.2  151.39  52.2 -0.388\n [6,] -2.27  0.2   16.39 -17.8 -0.778\n [7,] -6.07  2.2  151.39 122.2 -0.328\n [8,]  4.03 -1.8  -61.91 -60.8  0.152\n [9,]  2.43 -1.8  -67.81 -27.8  0.382\n[10,] -1.17  0.2  -41.01   0.2  0.382\n\n\nThe same can be accomplished without writing a loop thanks to the function sweep()\n\nmat_centered = sweep(mat, MARGIN = 2, STATS = col_means, FUN = \"-\")\nmat_centered\n\n                    mpg  cyl    disp    hp   drat\nMazda RX4          0.63  0.2  -48.61 -12.8  0.362\nMazda RX4 Wag      0.63  0.2  -48.61 -12.8  0.362\nDatsun 710         2.43 -1.8 -100.61 -29.8  0.312\nHornet 4 Drive     1.03  0.2   49.39 -12.8 -0.458\nHornet Sportabout -1.67  2.2  151.39  52.2 -0.388\nValiant           -2.27  0.2   16.39 -17.8 -0.778\nDuster 360        -6.07  2.2  151.39 122.2 -0.328\nMerc 240D          4.03 -1.8  -61.91 -60.8  0.152\nMerc 230           2.43 -1.8  -67.81 -27.8  0.382\nMerc 280          -1.17  0.2  -41.01   0.2  0.382\n\n\n\nMARGIN = 2 indicates sweeping column-by-column\nSTATS is the statistic to be taking into account\nFUN is the function applied (with the given STATS)"
  },
  {
    "objectID": "practice/practice-prog3-iterations.html#your-turn-apply",
    "href": "practice/practice-prog3-iterations.html#your-turn-apply",
    "title": "Practice: Intro to Iterations",
    "section": "3.5 Your Turn: apply()",
    "text": "3.5 Your Turn: apply()\nConsider the matrix mat defined above.\n\nUse apply() to get a vector with column maxima (see below).\n\n\n\nShow answer\ncol_max = apply(mat, MARGIN = 2, FUN = max)\n\n\n\n\n   mpg    cyl   disp     hp   drat \n 24.40   8.00 360.00 245.00   3.92 \n\n\n\nUse sweep() to scale the columns of mat by dividing them by the column maxima (see below).\n\n\n\nShow answer\nmat_scaled = sweep(mat, MARGIN = 2, STATS = col_max, FUN = \"/\")\n\n\n\n\n                        mpg  cyl      disp        hp      drat\nMazda RX4         0.8606557 0.75 0.4444444 0.4489796 0.9948980\nMazda RX4 Wag     0.8606557 0.75 0.4444444 0.4489796 0.9948980\nDatsun 710        0.9344262 0.50 0.3000000 0.3795918 0.9821429\nHornet 4 Drive    0.8770492 0.75 0.7166667 0.4489796 0.7857143\nHornet Sportabout 0.7663934 1.00 1.0000000 0.7142857 0.8035714\nValiant           0.7418033 0.75 0.6250000 0.4285714 0.7040816\nDuster 360        0.5860656 1.00 1.0000000 1.0000000 0.8188776\nMerc 240D         1.0000000 0.50 0.4075000 0.2530612 0.9413265\nMerc 230          0.9344262 0.50 0.3911111 0.3877551 1.0000000\nMerc 280          0.7868852 0.75 0.4655556 0.5020408 1.0000000"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html",
    "href": "practice/practice-tidy3-dplyr-intro.html",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nLearn the basic verbs of dplyr\nSubset rows by position with slice()\nSubset rows that match a condition with filter()\nSelect columns by name with select()\nModify variables with mutate()\nReorder rows with arrange()\nReduce variables to values with summarise()\nGroup values by one or more variables with group_by()"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html#data-starwars",
    "href": "practice/practice-tidy3-dplyr-intro.html#data-starwars",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "1.1 Data starwars",
    "text": "1.1 Data starwars\nWe are going to use a data starwars that, as you can imagine, has to do with Star Wars characters.\n\nstarwars\n\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n 3 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 8 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html#your-turn-using-slice-and-friends",
    "href": "practice/practice-tidy3-dplyr-intro.html#your-turn-using-slice-and-friends",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "3.1 Your turn: using slice() and friends",
    "text": "3.1 Your turn: using slice() and friends\n\nuse slice() to subset the 10th row of starwars.\n\n\n\nShow answer\nslice(starwars, 10)\n\n\n\nuse slice_head() to subset the first 4 rows of starwars\n\n\n\nShow answer\nslice_head(starwars, n = 4)\n\n\n\nuse slice_tail() to subset the last 3 rows of starwars\n\n\n\nShow answer\nslice_tail(starwars, n = 3)\n\n\n\nuse slice_min() to subset the row with the smallest height value\n\n\n\nShow answer\nslice_min(starwars, height)\n\n\n\nuse slice() to subset the data by selecting rows 10, 20, 30, …, 50. Optional hint: seq() is your friend.\n\n\n\nShow answer\nslice(starwars, seq(from = 10, to = 50, by = 10))"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html#your-turn-using-filter",
    "href": "practice/practice-tidy3-dplyr-intro.html#your-turn-using-filter",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "4.1 Your turn: using filter()",
    "text": "4.1 Your turn: using filter()\n\nuse filter() to subset those individuals with height less than 100 cm tall.\n\n\n\nShow answer\nfilter(starwars, height &lt; 100)\n\n\n\nuse filter() to subset rows of female individuals (sex).\n\n\n\nShow answer\nfilter(starwars, sex == \"female\")\n\n\n\nuse filter() to subset rows of female individuals (sex) no more than 160cm tall.\n\n\n\nShow answer\nfilter(starwars, sex == \"female\" & height &lt; 160)"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html#your-turn-using-select",
    "href": "practice/practice-tidy3-dplyr-intro.html#your-turn-using-select",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "5.1 Your turn: using select()",
    "text": "5.1 Your turn: using select()\n\nuse filter() to subset rows of individuals from homeworld Naboo, and then select() their names.\n\n\n\nShow answer\nselect(filter(starwars, homeworld == 'Naboo'), name)\n\n\n\nfind how to select the name, and homeworld, of human female individuals.\n\n\n\nShow answer\nselect(filter(starwars, sex == 'female' & species == \"Human\"), name, homeworld)\n\n\n\nfind how to select the name, and gender, of \"Droid\" species.\n\n\n\nShow answer\nselect(filter(starwars, species == 'Droid' ), name, gender)"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html#your-turn",
    "href": "practice/practice-tidy3-dplyr-intro.html#your-turn",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "7.1 Your Turn",
    "text": "7.1 Your Turn\n\nuse the original data frame starwars to filter() and arrange() those individuals with height less than 150 cm tall, in increasing order by height.\n\n\n\nShow answer\narrange(filter(starwars, height &lt; 150), height)\n\n\n\ndisplay the name, homeworld, and species, of the top-5 tallest individuals.\n\n\n\nShow answer\nslice(select(arrange(starwars, desc(height)), name, homeworld, species), 1:5)\n\n\n\ndisplay the name, homeworld, and species, for the top-5 heaviest individuals.\n\n\n\nShow answer\nslice(select(arrange(starwars, desc(mass)), name, homeworld, species), 1:5)"
  },
  {
    "objectID": "practice/practice-tidy3-dplyr-intro.html#your-turn-1",
    "href": "practice/practice-tidy3-dplyr-intro.html#your-turn-1",
    "title": "Practice: Manipulating tables with dplyr",
    "section": "9.1 Your Turn",
    "text": "9.1 Your Turn\n\nuse summarise() to get the largest height value.\n\n\n\nShow answer\nsummarise(starwars, max_height = max(height, na.rm = TRUE))\n\n\n\nuse summarise() and group_by() to display the median of mass, by homeworld\n\n\n\nShow answer\nsummarise(group_by(starwars, homeworld), med_mass = median(mass, na.rm = TRUE))\n\n\n\nuse arrange(), summarise() and group_by() display the average mass by gender, in ascending order\n\n\n\nShow answer\narrange(\n  summarise(group_by(starwars, gender), \n            avg = mean(mass, na.rm = TRUE)),\n  avg)"
  },
  {
    "objectID": "practice/practice-regex2.html",
    "href": "practice/practice-regex2.html",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nGetting familiar with regex functions from \"stringr\"\nUse regex operations to clean/process “messy” data\nFocus on detection and extraction of string patterns"
  },
  {
    "objectID": "practice/practice-regex2.html#stringr-cheatsheet",
    "href": "practice/practice-regex2.html#stringr-cheatsheet",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "1.1 Stringr cheatsheet",
    "text": "1.1 Stringr cheatsheet\nWe recommend having at hand the stringr cheatsheet (available in bCourses)\nhttps://bcourses.berkeley.edu/courses/1526481/files/folder/cheatsheets?preview=86322354"
  },
  {
    "objectID": "practice/practice-regex2.html#getting-the-data",
    "href": "practice/practice-regex2.html#getting-the-data",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "2.1 Getting the Data",
    "text": "2.1 Getting the Data\nPerhaps the simplest and most straightforward way to get the data in R is by passing the URL to a function that lets you import HTML files such as read_html():\n\n# assemble url\nwiki = \"https://en.wikipedia.org/wiki/\"\nwomen_discus = \"Women%27s_discus_throw_world_record_progression\"\nurl = paste0(wiki, women_discus)\n\n# import HTML file\ndoc = read_html(url)\nclass(doc)\n\n\n\n[1] \"xml_document\" \"xml_node\"    \n\n\nAs you can tell, doc is an object of class \"xml_document\" that contains, among other things, the HTML table with the data of discus world records."
  },
  {
    "objectID": "practice/practice-regex2.html#another-option-to-get-the-data",
    "href": "practice/practice-regex2.html#another-option-to-get-the-data",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "2.2 Another option to get the data",
    "text": "2.2 Another option to get the data\nAnother option to get the data involves a 2-step process:\n\ndownload the html file of the wikipedia page to your working directory,\nthen import this file in R.\n\nThis is my preferred method for working with data from the web, following good practices to avoid making recurrent and unnecessary requests to the server where the data is hosted.\n\n# step 1) download a copy of the HTML file, \n# (run this code in R's console!!!)\nwiki = \"https://en.wikipedia.org/wiki/\"\nwomen_discus = \"Women%27s_discus_throw_world_record_progression\"\nurl = paste0(wiki, women_discus)\ndownload.file(wiki_women_discus, \"women-discus-throw.html\")\n\nAssuming that you’ve downloaded the html content in the file women-discus-throw.html, and that this file is in your working directory, you can then import it with read_html():\n\n# step 2) extract HTML table into a data.frame\ndoc = read_html(\"women-discus-throw.html\")\n\nTo extract the HTML tables from doc you use the html_table() function:\n\ntbls = html_table(doc)\nlength(tbls)\n\n[1] 4"
  },
  {
    "objectID": "practice/practice-regex2.html#raw-messy-table",
    "href": "practice/practice-regex2.html#raw-messy-table",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "2.3 Raw (messy) Table",
    "text": "2.3 Raw (messy) Table\nIf you inspect all the extracted tables in tbls, you’ll see that the table we are interested in is the second one:\n\ndat = tbls[[2]]\ndat\n\n# A tibble: 57 × 4\n   Mark                                                   Athlete Location Date \n   &lt;chr&gt;                                                  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;\n 1 24.90 m (.mw-parser-output .frac{white-space:nowrap}.… Lilli … Berlin   1 Oc…\n 2 26.62 m (87 ft 4 in)                                   Lilli … Berlin   8 Ju…\n 3 27.39 m (89 ft 10+1⁄4 in)                              Yvonne… Paris    23 S…\n 4 27.70 m (90 ft 10+1⁄2 in)                              Lucie … Paris    14 J…\n 5 28.325 m (92 ft 11 in)                                 Lisett… Brussels 21 J…\n 6 30.225 m (99 ft 1+3⁄4 in)                              Lucien… Paris    14 S…\n 7 31.15 m (102 ft 2+1⁄4 in)                              Maria … Prague   11 O…\n 8 34.15 m (112 ft 1⁄4 in)                                Halina… Warsaw   23 M…\n 9 38.34 m (125 ft 9+1⁄4 in)                              Milly … Braunsc… 22 A…\n10 39.18 m (128 ft 6+1⁄2 in)                              Halina… Warsaw   4 Se…\n# ℹ 47 more rows"
  },
  {
    "objectID": "practice/practice-regex2.html#your-turn-meters",
    "href": "practice/practice-regex2.html#your-turn-meters",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "3.1 Your Turn: Meters",
    "text": "3.1 Your Turn: Meters\n\nUse str_extract() with a pattern that matches a string beginning with two digits, followed by a dot \".\", followed by two more digits. Come up with three different regex patterns that meet these criteria.\n\n\n\nShow answer\n# pattern 1\nstr_extract(tmp, \"^[0-9][0-9]\\\\.[0-9][0-9]\")\n\n# pattern 2\nstr_extract(tmp, \"^[0-9]{2}\\\\.[0-9]{2}\")\n\n# pattern 3\nstr_extract(tmp, \"^[[:digit:]]{2}\\\\.[[:digit:]]{2}\")\n\n\n\nOnce you have a simple pattern, use it on the entire column Mark and get a numeric vector mark:\n\n\n\nShow answer\n# numeric vector mark\nmark = as.numeric(str_extract(dat$Mark, \"^[0-9]{2}\\\\.[0-9]{2}\"))"
  },
  {
    "objectID": "practice/practice-regex2.html#your-turn-play-with-ath",
    "href": "practice/practice-regex2.html#your-turn-play-with-ath",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "4.1 Your Turn: play with ath",
    "text": "4.1 Your Turn: play with ath\n\nWork with the sample vector ath and try to str_extract() the first name. You can look for a pattern consisting of a word at the beginning of the string. This involves using the beginning of the string anchor \"^\", and the word pattern \"\\\\w+\" (i.e. one or more alphanumeric characters):\n\n\n\nShow answer\nstr_extract(ath, \"^\\\\w+\")\n\n\n\nNow use the patterns whitespace \"\\\\s\" and word \"\\\\w+\" to attempt extracting the athlete’s last name \"\\\\s\\\\w+\"; hint: to remove the extra matched space you can use str_trim()\n\n\n\nShow answer\nath_last = str_extract(ath, \"\\\\s\\\\w+\")\nstr_trim(ath_last)\n\n\n\nOnce you are done working with ath, use your code to extract the first and last names of all athletes; use vectors first_name and last_name for this purpose:\n\n\n\nShow answer\n# first and last name of all athletes\nfirst_name = str_extract(dat$Athlete, \"^\\\\w+\")\n\nlast_str = str_extract(dat$Athlete, \"\\\\s\\\\w+\")\nlast_name = str_trim(last_str)"
  },
  {
    "objectID": "practice/practice-regex2.html#your-turn-athletes-initials",
    "href": "practice/practice-regex2.html#your-turn-athletes-initials",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "4.2 Your Turn: Athlete’s Initials",
    "text": "4.2 Your Turn: Athlete’s Initials\nUse first_name and last_name to select the first letter in each vector in order to form a new vector initials containing the initials of each athlete’s name: e.g. \"J.T.\", \"T.L.\", \"G.H.\", ...\n\n\nShow answer\n# initials vector\nfirst_initial = str_extract(first_name, \"\\\\w\")\nlast_initial = str_extract(last_name, \"\\\\w\")\ninitials = paste0(first_initial, \".\", last_initial, \".\")"
  },
  {
    "objectID": "practice/practice-regex2.html#your-turn-athletes-country",
    "href": "practice/practice-regex2.html#your-turn-athletes-country",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "5.1 Your Turn: Athlete’s country",
    "text": "5.1 Your Turn: Athlete’s country\n\nUse str_extract() with a regex pattern that matches the country abbreviation formed by three consecutive upper case letters. Come up with three different regex patterns that lets you get these characters:\n\n\n\nShow answer\n# pattern 1\nstr_extract(ath, \"[A-Z][A-Z][A-Z]\")\n\n# pattern 2\nstr_extract(ath, \"[A-Z]{3}\")\n\n# pattern 3\nstr_extract(ath, \"[[:upper:]]{3}\")\n\n\n\nOnce you have the right pattern, use your code to extract the country abbreviations on the entire column to produce a vector country\n\n\n\nShow answer\ncountry = str_extract(dat$Athlete, \"[A-Z][A-Z][A-Z]\")"
  },
  {
    "objectID": "practice/practice-regex2.html#your-turn-play-with-dts",
    "href": "practice/practice-regex2.html#your-turn-play-with-dts",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "6.1 Your Turn: play with dts",
    "text": "6.1 Your Turn: play with dts\nWith the dts vector, extract in separate vectors the values of day, month name, and year: you can try using patterns such as:\n\ndigit: \"[0-9]\", \"\\\\d\",\nnon-digits: \"\\\\D\"\nword-character: \"\\\\w\":\n\n\n\nShow answer\n# days\nday = as.numeric(str_extract(dat$Date, \"^[0-9]+\"))\n\n# months\nmonth = str_trim(str_extract(dat$Date, \"\\\\D+\"))\n\n# years\nyear = as.numeric(str_extract(dat$Date, \"\\\\d{4}\"))"
  },
  {
    "objectID": "practice/practice-regex2.html#your-turn-assemble-table-discus",
    "href": "practice/practice-regex2.html#your-turn-assemble-table-discus",
    "title": "Practice: Regular Expressions (part 2)",
    "section": "7.1 Your Turn: assemble table discus",
    "text": "7.1 Your Turn: assemble table discus\nCreate a data frame discus with all the above vectors used as columns of this table. The head() of your table should look like this:\n\n\n   mark first_name last_name initials country day     month year\n1 24.90      Lilli    Henoch     L.H.     GER   1   October 1922\n2 26.62      Lilli    Henoch     L.H.     GER   8      July 1923\n3 27.39     Yvonne Tembouret     Y.T.     FRA  23 September 1923\n4 27.70      Lucie     Petit     L.P.     FRA  14      July 1924\n5 28.32    Lisette     Petré     L.P.     BEL  21      July 1924\n6 30.22   Lucienne      Velu     L.V.     FRA  14 September 1924\n\n\n\n\nShow answer\ndiscus = data.frame(\n  mark = mark,\n  first_name = first_name,\n  last_name = last_name,\n  initials = initials,\n  country = country,\n  day = day,\n  month = month,\n  year = year\n)"
  },
  {
    "objectID": "practice/practice-regex1.html",
    "href": "practice/practice-regex1.html",
    "title": "Practice: Regular Expressions (part 1)",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\nGetting familiar with regex functions from \"stringr\"\nUse regex operations to clean/process “messy” data\nFocus on detection and extraction of string patterns"
  },
  {
    "objectID": "practice/practice-regex1.html#your-turn",
    "href": "practice/practice-regex1.html#your-turn",
    "title": "Practice: Regular Expressions (part 1)",
    "section": "2.1 Your turn",
    "text": "2.1 Your turn\nUse logical subsetting with str_detect(), to find the names of animals with:\n\nzero or more o\n\n\n\nShow answer\nanimals[str_detect(animals, 'o*')]\n\n\n\nzero or one o\n\n\n\nShow answer\nanimals[str_detect(animals, 'o?')]\n\n\n\nat least 1 o: \"dog\" \"dolphin\" \"lion\" \"wolf\" \"osprey\" \"kangaroo\" \"koala\"\n\n\n\nShow answer\nanimals[str_detect(animals, 'o+')]\n\n\n\nexactly 2 o’s together: \"kangaroo\"\n\n\n\nShow answer\nanimals[str_detect(animals, 'o{2}')]\n\n\n\none o, but not two o’s together: \"dog\" \"dolphin\" \"lion\" \"wolf\" \"osprey\" \"koala\"\n\n\n\nShow answer\nanimals[str_detect(animals, 'o[^o]')]\n\n\n\ntwo vowels together: \"lion\" \"eagle\" \"kangaroo\" \"koala\"\n\n\n\nShow answer\nanimals[str_detect(animals, '[aeiou]{2}')]\n\n\n\ntwo or more consonants together: \"bird\" \"dolphin\"  \"zebra\" \"wolf\" \"whale\" \"eagle\" \"osprey\" \"kangaroo\"\n\n\n\nShow answer\nanimals[str_detect(animals, '[^aeiou]{2,}')]\n\n\n\nthree consonants together: \"dolphin\" \"osprey\"\n\n\n\nShow answer\nanimals[str_detect(animals, '[^aeiou]{3}')]\n\n\n\nthree letters only: \"dog\" \"cat\" \"pig\"\n\n\n\nShow answer\nanimals[str_detect(animals, '^[a-z]{3}$')]\n\n\n\nfour letters only: \"bird\" \"lion\" \"wolf\"\n\n\n\nShow answer\nanimals[str_detect(animals, '^[a-z]{4}$')]"
  },
  {
    "objectID": "practice/practice-regex1.html#your-turn-1",
    "href": "practice/practice-regex1.html#your-turn-1",
    "title": "Practice: Regular Expressions (part 1)",
    "section": "3.1 Your turn",
    "text": "3.1 Your turn\n\nFind the file names containing numbers\n\n\n\nShow answer\nfiles[str_detect(files, '[0123456789]')]\n\nfiles[str_detect(files, '[0-9]')]\n\nfiles[str_detect(files, '[[:digit:]]')]\n\n\n\nFind the file names containing no numbers\n\n\n\nShow answer\nfiles[!str_detect(files, '[0-9]')]\n\n\n\nFind the file names containing lower case letters (including file extension)\n\n\n\nShow answer\nfiles[str_detect(files, '[[:lower:]]')]\n\n\n\nFind the file names containing lower case letters (just the name, not the file extension)\n\n\n\nShow answer\nfiles[!str_detect(files, '[[:upper:]]')]\n\n\n\nFind the file names containing a dash\n\n\n\nShow answer\nfiles[str_detect(files, '-')]\n\n\n\nFind the file names containing no dash\n\n\n\nShow answer\nfiles[!str_detect(files, '-')]\n\n\n\nCreate a vector of files by replacing the ‘csv’ extension into ‘txt’ extension\n\n\n\nShow answer\nstr_replace(files, pattern = \"csv\", replacement = \"txt\")\n\n\n\nExtract just the file name (without the extension)\n\n\n\nShow answer\nstr_replace(files, pattern = \"\\\\.csv\", replacement = \"\")\n\nstr_remove(files, pattern = \"\\\\.csv\")"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html",
    "href": "demos/demo-lec3-vectors2.html",
    "title": "Lec-3: Vectors (part 2)",
    "section": "",
    "text": "Vectors and their data types (data primitives)\n\nlogical (boolean)\ninteger\ndouble or real (float)\ncharacter (string)\n\nHerer are some simple examples:\n\n# logical\na = c(TRUE, FALSE, NA)\n\n# integer\nb = c(2L, 4L, 6L)\n\n# double (real)\nc = c(1, 2, 3, 4)\nd = c(1.1, 2.2, 3.3, 4.0)\n\n# character\ne = c(\"a\", \"b\", \"c\", \"d\")\n\n\n\nAs you know, we can use names() to assign names to the elements of a vector\n\n# hypothetical example\nnames(c) = e\n\nQuestion: Do the input vector c and the vector of names e must be of the same length? Answer: Yes, and No. It depends. Let’s see three scenarios:\n\n# this works\nx = c(2, 4, 6)\nabc = c(\"a\", \"b\", \"c\")\n\nnames(x) = abc\nx\n\na b c \n2 4 6 \n\n\n\n# this fails\ny = c(2, 4, 6)\nabcd = c(\"a\", \"b\", \"c\", \"d\")\n\nnames(y) = abcd\n\nError in names(y) = abcd: 'names' attribute [4] must be the same length as the vector [3]\n\n\n\n# this works (but you get a missing named element)\nz = c(2, 4, 6, 8)\n\nnames(z) = abc\nz\n\n   a    b    c &lt;NA&gt; \n   2    4    6    8"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html#question-from-last-time",
    "href": "demos/demo-lec3-vectors2.html#question-from-last-time",
    "title": "Lec-3: Vectors (part 2)",
    "section": "",
    "text": "As you know, we can use names() to assign names to the elements of a vector\n\n# hypothetical example\nnames(c) = e\n\nQuestion: Do the input vector c and the vector of names e must be of the same length? Answer: Yes, and No. It depends. Let’s see three scenarios:\n\n# this works\nx = c(2, 4, 6)\nabc = c(\"a\", \"b\", \"c\")\n\nnames(x) = abc\nx\n\na b c \n2 4 6 \n\n\n\n# this fails\ny = c(2, 4, 6)\nabcd = c(\"a\", \"b\", \"c\", \"d\")\n\nnames(y) = abcd\n\nError in names(y) = abcd: 'names' attribute [4] must be the same length as the vector [3]\n\n\n\n# this works (but you get a missing named element)\nz = c(2, 4, 6, 8)\n\nnames(z) = abc\nz\n\n   a    b    c &lt;NA&gt; \n   2    4    6    8"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html#repetition",
    "href": "demos/demo-lec3-vectors2.html#repetition",
    "title": "Lec-3: Vectors (part 2)",
    "section": "Repetition",
    "text": "Repetition\n\nrep(x, times = 2)\n\na b c a b c \n2 4 6 2 4 6 \n\nrep(x, each = 3)\n\na a a b b b c c c \n2 2 2 4 4 4 6 6 6 \n\nrep(x, each = 2, times = 2)\n\na a b b c c a a b b c c \n2 2 4 4 6 6 2 2 4 4 6 6"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html#function-vector-and-siblings",
    "href": "demos/demo-lec3-vectors2.html#function-vector-and-siblings",
    "title": "Lec-3: Vectors (part 2)",
    "section": "Function vector() and siblings",
    "text": "Function vector() and siblings\n\n# good for initialization purposes\nvector(mode = \"logical\", length = 3)\n\n[1] FALSE FALSE FALSE\n\nvector(mode = \"integer\", length = 3)\n\n[1] 0 0 0\n\nvector(mode = \"double\", length = 3)\n\n[1] 0 0 0\n\n# creates a char vector of empty strings\nvector(mode = \"character\", length = 3)\n\n[1] \"\" \"\" \"\"\n\n\n\nlogical()\ninteger()\ndouble()\ncharacter()\n\n\nlogical(3)\n\n[1] FALSE FALSE FALSE"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html#coercion",
    "href": "demos/demo-lec3-vectors2.html#coercion",
    "title": "Lec-3: Vectors (part 2)",
    "section": "Coercion",
    "text": "Coercion\nWhat R does when it encounters an operation/computation that deals with different data types.\n\nImplicit Coercion\n\n# implicit coercion rules\nint = c(2L, 4L, 6L)\nlogi = c(TRUE, FALSE)\n\nvec = c(FALSE, 1L)\nvec\n\n[1] 0 1\n\n\nRemember the hierarchy of data types:\nlogical &lt; integer &lt; double &lt; character\nVectors are Atomic objects.\nEvery element of a vector has to be of the same data type\n\n\nExplicit Coercion Functions\n\nas.logical(c(0, 1, 2, 133))\n\n[1] FALSE  TRUE  TRUE  TRUE\n\nas.integer(c(1, 2.2, 3.33, 4.444))\n\n[1] 1 2 3 4\n\nas.double(c(\"a\", \"b\", TRUE, 133))\n\nWarning: NAs introduced by coercion\n\n\n[1]  NA  NA  NA 133\n\n\n\n\nFunctions to test data types\n\nis.logical()\nis.integer()\nis.double()\nis.character()\nis.numeric()\n\n\nis.logical(x)\n\n[1] FALSE\n\nis.logical(logi)\n\n[1] TRUE"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html#vectorization-vectorized-code",
    "href": "demos/demo-lec3-vectors2.html#vectorization-vectorized-code",
    "title": "Lec-3: Vectors (part 2)",
    "section": "Vectorization (vectorized code)",
    "text": "Vectorization (vectorized code)\nWhen R applies the same operation/computation to each element of a vector.\n\nsqrt(x)\n\n       a        b        c \n1.414214 2.000000 2.449490 \n\n\n\n# this in NOT vectorization\nmean(x)\n\n[1] 4"
  },
  {
    "objectID": "demos/demo-lec3-vectors2.html#recycling",
    "href": "demos/demo-lec3-vectors2.html#recycling",
    "title": "Lec-3: Vectors (part 2)",
    "section": "Recycling",
    "text": "Recycling\nWhen you operate with 2 vectors of different length, the elements of the shorter vector are recycled as many as times as necessary to match the length of the longer vector.\n\nx = c(2, 4, 6, 8)\nx\n\n[1] 2 4 6 8\n\ny = c(2, 1)\ny\n\n[1] 2 1\n\n\n\nx + y\n\n[1] 4 5 8 9\n\n\n\nc(2, 4, 6, 8) + c(2, 1, 2, 1)\n\n[1] 4 5 8 9\n\n\n\nu = c(2, 4, 6, 8, 10)\nu\n\n[1]  2  4  6  8 10\n\nv = c(2, 1)\nv\n\n[1] 2 1\n\nu + v\n\nWarning in u + v: longer object length is not a multiple of shorter object\nlength\n\n\n[1]  4  5  8  9 12"
  },
  {
    "objectID": "demos/demo-lec2-vectors1.html",
    "href": "demos/demo-lec2-vectors1.html",
    "title": "Lec-2: Vectors (part 1)",
    "section": "",
    "text": "I don’t have a good definition of data, but I would like to give you my framework about data:\n\nHow do statisticians / analysts think of data?\nHow do computers treat data?\nHow do data sets get stored?\nHow do programs handle data?\n\nThere is not just one way to talk about data, but multiple perspectives that in one way or another involve different aspects of data.\n\n\nAs a first example, let’s start with the following tiny data set about three individuals from a galaxy far, far away:\n\n\n\nname\nheight (cm)\nforce\n\n\n\n\nLeia\n150\nTrue\n\n\nLuke\n175\nTrue\n\n\nHan\n185\nFalse\n\n\n\n\nSince we are going to use R (and RStudio), the question is:\n\nHow can R handle this kind of data?"
  },
  {
    "objectID": "demos/demo-lec2-vectors1.html#example",
    "href": "demos/demo-lec2-vectors1.html#example",
    "title": "Lec-2: Vectors (part 1)",
    "section": "",
    "text": "As a first example, let’s start with the following tiny data set about three individuals from a galaxy far, far away:\n\n\n\nname\nheight (cm)\nforce\n\n\n\n\nLeia\n150\nTrue\n\n\nLuke\n175\nTrue\n\n\nHan\n185\nFalse\n\n\n\n\nSince we are going to use R (and RStudio), the question is:\n\nHow can R handle this kind of data?"
  },
  {
    "objectID": "demos/demo-lec2-vectors1.html#data-types",
    "href": "demos/demo-lec2-vectors1.html#data-types",
    "title": "Lec-2: Vectors (part 1)",
    "section": "Data Types",
    "text": "Data Types\nLike most programming languages, R gives you 4 common data types:\n\nlogical (boolean)\ninteger\ndouble (real or float)\ncharacter (string)\n\nThere are 2 more special data types (complex, and raw) bu we won’t do anything with them."
  },
  {
    "objectID": "demos/demo-lec2-vectors1.html#properties-of-vectors",
    "href": "demos/demo-lec2-vectors1.html#properties-of-vectors",
    "title": "Lec-2: Vectors (part 1)",
    "section": "Properties of Vectors",
    "text": "Properties of Vectors\n\ntype (of data)\nlength\nindices or positions\nnames (optional)\n\n\nType\nAn R vector has single data type. To find the data type of a vector I like to use the typeof() function\n\ntypeof(height_int)\n\n[1] \"integer\"\n\n\n\ntypeof(height)\n\n[1] \"double\"\n\n\nFor historical reasons that we won’t discuss, among useRs it is common to talk about the mode of a vector using the homonym function mode()\n\nmode(height_int)\n\n[1] \"numeric\"\n\n\n\nmode(height)\n\n[1] \"numeric\"\n\n\nFrom the mode perspective, it turns out that R considers both integers and doubles as numeric types.\n\nmode(name)\n\n[1] \"character\"\n\ntypeof(name)\n\n[1] \"character\"\n\n\n\n\nLength and Indices\nVectors can contain one or more elements. We refer to the size of a vector as its length, and we use the length() function:\n\nlength(name)\n\n[1] 3\n\nlength(c(2,4,6,8))\n\n[1] 4\n\n\nThe starting index or position in a vector is always 1. Other languages may start indexing positions at 0, but not R.\n\n\nNames of elements\nOptionally, elements in a vector can have associated names. For example, we have an unnamed vector height:\n\nheight\n\n[1] 150 175 185\n\n\nBut what if we want to give names to the elements in height. I’ll show you 2 options:\n\n# method 1: use a vector to give names\nnames(height) = name\nheight\n\nLeia Luke  Han \n 150  175  185 \n\n\n\n# method 2: assign names while creating a vector\nheight2 = c(\"leia\" = 150, \"luke\" = 170, \"han\" = 180)\nheight2\n\nleia luke  han \n 150  170  180"
  },
  {
    "objectID": "demos/demo-lec2-vectors1.html#special-values",
    "href": "demos/demo-lec2-vectors1.html#special-values",
    "title": "Lec-2: Vectors (part 1)",
    "section": "Special Values",
    "text": "Special Values\nThere are some special values. The following is not an exhaustive list:\n\n# null value (i.e. nothing)\nNULL\n\nNULL\n\n# missing value(s)\nNA # Not Available\n\n[1] NA\n\ntypeof(NA)\n\n[1] \"logical\"\n\n# there specific types of NAs\nNA_integer_\n\n[1] NA\n\nNA_real_\n\n[1] NA\n\nNA_character_\n\n[1] NA\n\nc(1L, 3L, NA)\n\n[1]  1  3 NA\n\n\nWe also have Not a Number as well as infinite values:\n\n# positive and negative infinite\nInf\n\n[1] Inf\n\n-Inf\n\n[1] -Inf\n\n10/0\n\n[1] Inf\n\n-10/0\n\n[1] -Inf\n\n# Not a Number\nNaN\n\n[1] NaN\n\nsqrt(-4)\n\nWarning in sqrt(-4): NaNs produced\n\n\n[1] NaN\n\nlog(-2)\n\nWarning in log(-2): NaNs produced\n\n\n[1] NaN"
  },
  {
    "objectID": "demos/demo-lec2-vectors1.html#more-operators-and-functions-to-create-vectors",
    "href": "demos/demo-lec2-vectors1.html#more-operators-and-functions-to-create-vectors",
    "title": "Lec-2: Vectors (part 1)",
    "section": "More operators and functions to create vectors",
    "text": "More operators and functions to create vectors\nOften, you’ll find yourself creating various kinds of numeric sequences. R has a couple of functions to create vectors of numeric sequences.\n\nColon Operator :\nSay I want the sequence 1, 2, 3, 4, 5\n\n1:5\n\n[1] 1 2 3 4 5\n\n\nThe : operator lets you create numeric sequences of 1-unit steps\n\n# examples\n5:1\n\n[1] 5 4 3 2 1\n\n-5:-1\n\n[1] -5 -4 -3 -2 -1\n\n2.5:8.5\n\n[1] 2.5 3.5 4.5 5.5 6.5 7.5 8.5\n\n\n\n\nFunction seq()\nTo create more complex sequences we can use seq()\n\n# basic usage\nseq(from, to, by)\n\nThe same sequence 1, 2, 3, 4, 5 can be created with seq() like so:\n\nseq(from = 1, to = 5, by = 1)\n\n[1] 1 2 3 4 5\n\n\nThe sequence 2, 4, 6, 8, 10 can be obtained with:\n\nseq(from = 2, to = 10, by = 2)\n\n[1]  2  4  6  8 10"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "We’ll use data from several real world situations in class."
  },
  {
    "objectID": "data.html#data-1",
    "href": "data.html#data-1",
    "title": "Data",
    "section": "Data 1",
    "text": "Data 1\nTBD"
  },
  {
    "objectID": "data.html#data-2",
    "href": "data.html#data-2",
    "title": "Data",
    "section": "Data 2",
    "text": "Data 2\nTBD"
  }
]